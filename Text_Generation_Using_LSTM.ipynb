{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation Using LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Piyush01Bhatt/Deep-Learning/blob/master/Text_Generation_Using_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSKpAVZWkcrc",
        "colab_type": "text"
      },
      "source": [
        "This is a notebook explaining text generation using LSTM(Long Short Term Memory) networks. I will be using famous poem of John Keats : A Thing of Beauty as my data. Lstm network will be implemented using Keras(Tensorflow)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP7AqY1Smnlp",
        "colab_type": "code",
        "outputId": "362f09cb-cbd7-4817-a3d6-e91e8e249f1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-beta1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0-beta1 in /usr/local/lib/python3.6/dist-packages (2.0.0b1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.1.7)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.14.0a20190603)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.11.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (3.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.33.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.16.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-beta1) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (0.15.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEg5HnvCmJWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhaEtrNzlJyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "poem = \"\"\"A THING of beauty is a joy forever:\t\n",
        "        Its loveliness increases; it will never\t\n",
        "        Pass into nothingness; but still will keep\t\n",
        "        A bower quiet for us, and a sleep\t\n",
        "        Full of sweet dreams, and health, and quiet breathing.\t        \n",
        "        Therefore, on every morrow, are we wreathing\t\n",
        "        A flowery band to bind us to the earth,\t\n",
        "        Spite of despondence, of the inhuman dearth\t\n",
        "        Of noble natures, of the gloomy days,\t\n",
        "        Of all the unhealthy and o’er-darkened ways\t        \n",
        "        Made for our searching: yes, in spite of all,\t\n",
        "        Some shape of beauty moves away the pall\t\n",
        "        From our dark spirits. Such the sun, the moon,\t\n",
        "        Trees old and young, sprouting a shady boon\t\n",
        "        For simple sheep; and such are daffodils\t        \n",
        "        With the green world they live in; and clear rills\t\n",
        "        That for themselves a cooling covert make\t\n",
        "        ’Gainst the hot season; the mid-forest brake,\t\n",
        "        Rich with a sprinkling of fair musk-rose blooms:\t\n",
        "        And such too is the grandeur of the dooms\t        \n",
        "        We have imagined for the mighty dead;\t\n",
        "        All lovely tales that we have heard or read:\t\n",
        "        An endless fountain of immortal drink,\t\n",
        "        Pouring unto us from the heaven’s brink.\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47mq8FQ2lkGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeHYOmr2nV4B",
        "colab_type": "code",
        "outputId": "01257fa6-1cb8-4819-a1a0-271d39635ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "corpus = poem.lower().split(\"\\n\")\n",
        "print(f'Corpus length = {len(corpus)}')\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "print(tokenizer.word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus length = 24\n",
            "{'the': 1, 'of': 2, 'a': 3, 'and': 4, 'for': 5, 'us': 6, 'we': 7, 'all': 8, 'such': 9, 'beauty': 10, 'is': 11, 'will': 12, 'quiet': 13, 'are': 14, 'to': 15, 'spite': 16, 'our': 17, 'in': 18, 'from': 19, 'with': 20, 'that': 21, 'have': 22, 'thing': 23, 'joy': 24, 'forever': 25, 'its': 26, 'loveliness': 27, 'increases': 28, 'it': 29, 'never': 30, 'pass': 31, 'into': 32, 'nothingness': 33, 'but': 34, 'still': 35, 'keep': 36, 'bower': 37, 'sleep': 38, 'full': 39, 'sweet': 40, 'dreams': 41, 'health': 42, 'breathing': 43, 'therefore': 44, 'on': 45, 'every': 46, 'morrow': 47, 'wreathing': 48, 'flowery': 49, 'band': 50, 'bind': 51, 'earth': 52, 'despondence': 53, 'inhuman': 54, 'dearth': 55, 'noble': 56, 'natures': 57, 'gloomy': 58, 'days': 59, 'unhealthy': 60, 'o’er': 61, 'darkened': 62, 'ways': 63, 'made': 64, 'searching': 65, 'yes': 66, 'some': 67, 'shape': 68, 'moves': 69, 'away': 70, 'pall': 71, 'dark': 72, 'spirits': 73, 'sun': 74, 'moon': 75, 'trees': 76, 'old': 77, 'young': 78, 'sprouting': 79, 'shady': 80, 'boon': 81, 'simple': 82, 'sheep': 83, 'daffodils': 84, 'green': 85, 'world': 86, 'they': 87, 'live': 88, 'clear': 89, 'rills': 90, 'themselves': 91, 'cooling': 92, 'covert': 93, 'make': 94, '’gainst': 95, 'hot': 96, 'season': 97, 'mid': 98, 'forest': 99, 'brake': 100, 'rich': 101, 'sprinkling': 102, 'fair': 103, 'musk': 104, 'rose': 105, 'blooms': 106, 'too': 107, 'grandeur': 108, 'dooms': 109, 'imagined': 110, 'mighty': 111, 'dead': 112, 'lovely': 113, 'tales': 114, 'heard': 115, 'or': 116, 'read': 117, 'an': 118, 'endless': 119, 'fountain': 120, 'immortal': 121, 'drink': 122, 'pouring': 123, 'unto': 124, 'heaven’s': 125, 'brink': 126}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDM-RSz4rXcu",
        "colab_type": "code",
        "outputId": "82afed53-28c7-4ce1-ede4-305d3eac3293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(tokenizer.word_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YecnqSXYrf-1",
        "colab_type": "code",
        "outputId": "10f3f22e-6a21-49cb-e7f6-126c04af4335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "sequences = np.array(tokenizer.texts_to_sequences(corpus))\n",
        "print(sequences[0])\n",
        "padded = pad_sequences(sequences,truncating='post',padding='post')\n",
        "print(padded[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 23, 2, 10, 11, 3, 24, 25]\n",
            "[ 3 23  2 10 11  3 24 25  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r0k_ba5sQNj",
        "colab_type": "code",
        "outputId": "5c323232-eb13-45c6-a822-30143da56ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "predictor = padded[:,:-1]\n",
        "labels = padded[:,1:]\n",
        "print(f'predictor sequence = {predictor[0]}')\n",
        "print(f'label sequence = {labels[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predictor sequence = [ 3 23  2 10 11  3 24 25  0]\n",
            "label sequence = [23  2 10 11  3 24 25  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ0RQNXk0_7g",
        "colab_type": "code",
        "outputId": "3bbf933f-7125-4750-b8cb-06f131d52a22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(predictor.shape)\n",
        "n_patterns = predictor.shape[0]\n",
        "seq_length = predictor.shape[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0rkKFxrvavm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = np.reshape(predictor, (n_patterns, seq_length))\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrrxjTsU5y8z",
        "colab_type": "code",
        "outputId": "cd02e18c-5421-449e-ad92-b894390be206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTfWwFXF6JCR",
        "colab_type": "code",
        "outputId": "9f27f737-41ea-4b8f-9cc6-fd0f91221cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 9, 127)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyLHyn346sdc",
        "colab_type": "code",
        "outputId": "1b3b7373-185c-43fa-c94f-0413f3e64361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(127,10))\n",
        "model.add(tf.keras.layers.LSTM(150,return_sequences=True))\n",
        "model.add(tf.keras.layers.Dropout(0.1))\n",
        "model.add(tf.keras.layers.Dense(127,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 10)          1270      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, None, 150)         96600     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, None, 150)         0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, None, 127)         19177     \n",
            "=================================================================\n",
            "Total params: 117,047\n",
            "Trainable params: 117,047\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AuC1lW4O9S0",
        "colab_type": "code",
        "outputId": "6a947972-5b33-4b92-9d4d-e1c0fa039fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X, y, epochs=1000, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0810 15:01:13.877632 140518828152704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 24 samples\n",
            "Epoch 1/1000\n",
            "24/24 [==============================] - 3s 129ms/sample - loss: 4.8443 - accuracy: 0.0139\n",
            "Epoch 2/1000\n",
            "24/24 [==============================] - 0s 469us/sample - loss: 4.8406 - accuracy: 0.2500\n",
            "Epoch 3/1000\n",
            "24/24 [==============================] - 0s 439us/sample - loss: 4.8366 - accuracy: 0.2361\n",
            "Epoch 4/1000\n",
            "24/24 [==============================] - 0s 418us/sample - loss: 4.8322 - accuracy: 0.2361\n",
            "Epoch 5/1000\n",
            "24/24 [==============================] - 0s 441us/sample - loss: 4.8267 - accuracy: 0.2361\n",
            "Epoch 6/1000\n",
            "24/24 [==============================] - 0s 426us/sample - loss: 4.8202 - accuracy: 0.2361\n",
            "Epoch 7/1000\n",
            "24/24 [==============================] - 0s 397us/sample - loss: 4.8124 - accuracy: 0.2361\n",
            "Epoch 8/1000\n",
            "24/24 [==============================] - 0s 472us/sample - loss: 4.8024 - accuracy: 0.2361\n",
            "Epoch 9/1000\n",
            "24/24 [==============================] - 0s 398us/sample - loss: 4.7902 - accuracy: 0.2361\n",
            "Epoch 10/1000\n",
            "24/24 [==============================] - 0s 429us/sample - loss: 4.7753 - accuracy: 0.2361\n",
            "Epoch 11/1000\n",
            "24/24 [==============================] - 0s 455us/sample - loss: 4.7558 - accuracy: 0.2361\n",
            "Epoch 12/1000\n",
            "24/24 [==============================] - 0s 490us/sample - loss: 4.7327 - accuracy: 0.2361\n",
            "Epoch 13/1000\n",
            "24/24 [==============================] - 0s 409us/sample - loss: 4.7018 - accuracy: 0.2361\n",
            "Epoch 14/1000\n",
            "24/24 [==============================] - 0s 405us/sample - loss: 4.6610 - accuracy: 0.2361\n",
            "Epoch 15/1000\n",
            "24/24 [==============================] - 0s 699us/sample - loss: 4.6093 - accuracy: 0.2361\n",
            "Epoch 16/1000\n",
            "24/24 [==============================] - 0s 613us/sample - loss: 4.5392 - accuracy: 0.2361\n",
            "Epoch 17/1000\n",
            "24/24 [==============================] - 0s 539us/sample - loss: 4.4545 - accuracy: 0.2361\n",
            "Epoch 18/1000\n",
            "24/24 [==============================] - 0s 643us/sample - loss: 4.3414 - accuracy: 0.2361\n",
            "Epoch 19/1000\n",
            "24/24 [==============================] - 0s 709us/sample - loss: 4.1994 - accuracy: 0.2361\n",
            "Epoch 20/1000\n",
            "24/24 [==============================] - 0s 603us/sample - loss: 4.0388 - accuracy: 0.2361\n",
            "Epoch 21/1000\n",
            "24/24 [==============================] - 0s 602us/sample - loss: 3.9036 - accuracy: 0.2361\n",
            "Epoch 22/1000\n",
            "24/24 [==============================] - 0s 466us/sample - loss: 3.8243 - accuracy: 0.2361\n",
            "Epoch 23/1000\n",
            "24/24 [==============================] - 0s 473us/sample - loss: 3.7935 - accuracy: 0.2361\n",
            "Epoch 24/1000\n",
            "24/24 [==============================] - 0s 470us/sample - loss: 3.8176 - accuracy: 0.2361\n",
            "Epoch 25/1000\n",
            "24/24 [==============================] - 0s 623us/sample - loss: 3.8471 - accuracy: 0.2361\n",
            "Epoch 26/1000\n",
            "24/24 [==============================] - 0s 664us/sample - loss: 3.8786 - accuracy: 0.2361\n",
            "Epoch 27/1000\n",
            "24/24 [==============================] - 0s 699us/sample - loss: 3.8716 - accuracy: 0.2361\n",
            "Epoch 28/1000\n",
            "24/24 [==============================] - 0s 442us/sample - loss: 3.8738 - accuracy: 0.2361\n",
            "Epoch 29/1000\n",
            "24/24 [==============================] - 0s 409us/sample - loss: 3.8433 - accuracy: 0.2361\n",
            "Epoch 30/1000\n",
            "24/24 [==============================] - 0s 536us/sample - loss: 3.8172 - accuracy: 0.2361\n",
            "Epoch 31/1000\n",
            "24/24 [==============================] - 0s 577us/sample - loss: 3.7821 - accuracy: 0.2361\n",
            "Epoch 32/1000\n",
            "24/24 [==============================] - 0s 691us/sample - loss: 3.7406 - accuracy: 0.2361\n",
            "Epoch 33/1000\n",
            "24/24 [==============================] - 0s 607us/sample - loss: 3.7168 - accuracy: 0.2361\n",
            "Epoch 34/1000\n",
            "24/24 [==============================] - 0s 681us/sample - loss: 3.6962 - accuracy: 0.2361\n",
            "Epoch 35/1000\n",
            "24/24 [==============================] - 0s 579us/sample - loss: 3.6876 - accuracy: 0.2361\n",
            "Epoch 36/1000\n",
            "24/24 [==============================] - 0s 530us/sample - loss: 3.6879 - accuracy: 0.2361\n",
            "Epoch 37/1000\n",
            "24/24 [==============================] - 0s 644us/sample - loss: 3.6926 - accuracy: 0.2361\n",
            "Epoch 38/1000\n",
            "24/24 [==============================] - 0s 650us/sample - loss: 3.6967 - accuracy: 0.2361\n",
            "Epoch 39/1000\n",
            "24/24 [==============================] - 0s 693us/sample - loss: 3.6943 - accuracy: 0.2361\n",
            "Epoch 40/1000\n",
            "24/24 [==============================] - 0s 579us/sample - loss: 3.6961 - accuracy: 0.2361\n",
            "Epoch 41/1000\n",
            "24/24 [==============================] - 0s 576us/sample - loss: 3.6966 - accuracy: 0.2361\n",
            "Epoch 42/1000\n",
            "24/24 [==============================] - 0s 462us/sample - loss: 3.6876 - accuracy: 0.2361\n",
            "Epoch 43/1000\n",
            "24/24 [==============================] - 0s 696us/sample - loss: 3.6697 - accuracy: 0.2361\n",
            "Epoch 44/1000\n",
            "24/24 [==============================] - 0s 653us/sample - loss: 3.6653 - accuracy: 0.2361\n",
            "Epoch 45/1000\n",
            "24/24 [==============================] - 0s 656us/sample - loss: 3.6549 - accuracy: 0.2361\n",
            "Epoch 46/1000\n",
            "24/24 [==============================] - 0s 571us/sample - loss: 3.6411 - accuracy: 0.2361\n",
            "Epoch 47/1000\n",
            "24/24 [==============================] - 0s 502us/sample - loss: 3.6333 - accuracy: 0.2361\n",
            "Epoch 48/1000\n",
            "24/24 [==============================] - 0s 421us/sample - loss: 3.6311 - accuracy: 0.2407\n",
            "Epoch 49/1000\n",
            "24/24 [==============================] - 0s 530us/sample - loss: 3.6229 - accuracy: 0.2361\n",
            "Epoch 50/1000\n",
            "24/24 [==============================] - 0s 1ms/sample - loss: 3.6290 - accuracy: 0.2361\n",
            "Epoch 51/1000\n",
            "24/24 [==============================] - 0s 576us/sample - loss: 3.6245 - accuracy: 0.2407\n",
            "Epoch 52/1000\n",
            "24/24 [==============================] - 0s 604us/sample - loss: 3.6169 - accuracy: 0.2454\n",
            "Epoch 53/1000\n",
            "24/24 [==============================] - 0s 598us/sample - loss: 3.6183 - accuracy: 0.2361\n",
            "Epoch 54/1000\n",
            "24/24 [==============================] - 0s 645us/sample - loss: 3.6179 - accuracy: 0.2454\n",
            "Epoch 55/1000\n",
            "24/24 [==============================] - 0s 520us/sample - loss: 3.6155 - accuracy: 0.2407\n",
            "Epoch 56/1000\n",
            "24/24 [==============================] - 0s 532us/sample - loss: 3.6131 - accuracy: 0.2454\n",
            "Epoch 57/1000\n",
            "24/24 [==============================] - 0s 503us/sample - loss: 3.6077 - accuracy: 0.2454\n",
            "Epoch 58/1000\n",
            "24/24 [==============================] - 0s 427us/sample - loss: 3.5923 - accuracy: 0.2454\n",
            "Epoch 59/1000\n",
            "24/24 [==============================] - 0s 450us/sample - loss: 3.5809 - accuracy: 0.2454\n",
            "Epoch 60/1000\n",
            "24/24 [==============================] - 0s 492us/sample - loss: 3.5825 - accuracy: 0.2454\n",
            "Epoch 61/1000\n",
            "24/24 [==============================] - 0s 631us/sample - loss: 3.5867 - accuracy: 0.2454\n",
            "Epoch 62/1000\n",
            "24/24 [==============================] - 0s 644us/sample - loss: 3.5793 - accuracy: 0.2454\n",
            "Epoch 63/1000\n",
            "24/24 [==============================] - 0s 615us/sample - loss: 3.5760 - accuracy: 0.2454\n",
            "Epoch 64/1000\n",
            "24/24 [==============================] - 0s 636us/sample - loss: 3.5762 - accuracy: 0.2454\n",
            "Epoch 65/1000\n",
            "24/24 [==============================] - 0s 567us/sample - loss: 3.5646 - accuracy: 0.2454\n",
            "Epoch 66/1000\n",
            "24/24 [==============================] - 0s 688us/sample - loss: 3.5673 - accuracy: 0.2454\n",
            "Epoch 67/1000\n",
            "24/24 [==============================] - 0s 511us/sample - loss: 3.5685 - accuracy: 0.2454\n",
            "Epoch 68/1000\n",
            "24/24 [==============================] - 0s 548us/sample - loss: 3.5573 - accuracy: 0.2454\n",
            "Epoch 69/1000\n",
            "24/24 [==============================] - 0s 567us/sample - loss: 3.5510 - accuracy: 0.2454\n",
            "Epoch 70/1000\n",
            "24/24 [==============================] - 0s 617us/sample - loss: 3.5498 - accuracy: 0.2454\n",
            "Epoch 71/1000\n",
            "24/24 [==============================] - 0s 593us/sample - loss: 3.5453 - accuracy: 0.2454\n",
            "Epoch 72/1000\n",
            "24/24 [==============================] - 0s 566us/sample - loss: 3.5391 - accuracy: 0.2454\n",
            "Epoch 73/1000\n",
            "24/24 [==============================] - 0s 567us/sample - loss: 3.5408 - accuracy: 0.2454\n",
            "Epoch 74/1000\n",
            "24/24 [==============================] - 0s 460us/sample - loss: 3.5340 - accuracy: 0.2500\n",
            "Epoch 75/1000\n",
            "24/24 [==============================] - 0s 535us/sample - loss: 3.5347 - accuracy: 0.2454\n",
            "Epoch 76/1000\n",
            "24/24 [==============================] - 0s 501us/sample - loss: 3.5282 - accuracy: 0.2454\n",
            "Epoch 77/1000\n",
            "24/24 [==============================] - 0s 799us/sample - loss: 3.5278 - accuracy: 0.2407\n",
            "Epoch 78/1000\n",
            "24/24 [==============================] - 0s 521us/sample - loss: 3.5193 - accuracy: 0.2454\n",
            "Epoch 79/1000\n",
            "24/24 [==============================] - 0s 577us/sample - loss: 3.5137 - accuracy: 0.2407\n",
            "Epoch 80/1000\n",
            "24/24 [==============================] - 0s 581us/sample - loss: 3.5159 - accuracy: 0.2407\n",
            "Epoch 81/1000\n",
            "24/24 [==============================] - 0s 539us/sample - loss: 3.5105 - accuracy: 0.2454\n",
            "Epoch 82/1000\n",
            "24/24 [==============================] - 0s 520us/sample - loss: 3.5094 - accuracy: 0.2454\n",
            "Epoch 83/1000\n",
            "24/24 [==============================] - 0s 653us/sample - loss: 3.5017 - accuracy: 0.2454\n",
            "Epoch 84/1000\n",
            "24/24 [==============================] - 0s 612us/sample - loss: 3.5055 - accuracy: 0.2454\n",
            "Epoch 85/1000\n",
            "24/24 [==============================] - 0s 617us/sample - loss: 3.4930 - accuracy: 0.2454\n",
            "Epoch 86/1000\n",
            "24/24 [==============================] - 0s 594us/sample - loss: 3.4869 - accuracy: 0.2454\n",
            "Epoch 87/1000\n",
            "24/24 [==============================] - 0s 654us/sample - loss: 3.4951 - accuracy: 0.2454\n",
            "Epoch 88/1000\n",
            "24/24 [==============================] - 0s 581us/sample - loss: 3.4856 - accuracy: 0.2546\n",
            "Epoch 89/1000\n",
            "24/24 [==============================] - 0s 563us/sample - loss: 3.4915 - accuracy: 0.2500\n",
            "Epoch 90/1000\n",
            "24/24 [==============================] - 0s 686us/sample - loss: 3.4838 - accuracy: 0.2454\n",
            "Epoch 91/1000\n",
            "24/24 [==============================] - 0s 698us/sample - loss: 3.4834 - accuracy: 0.2454\n",
            "Epoch 92/1000\n",
            "24/24 [==============================] - 0s 549us/sample - loss: 3.4763 - accuracy: 0.2454\n",
            "Epoch 93/1000\n",
            "24/24 [==============================] - 0s 623us/sample - loss: 3.4781 - accuracy: 0.2454\n",
            "Epoch 94/1000\n",
            "24/24 [==============================] - 0s 605us/sample - loss: 3.4674 - accuracy: 0.2546\n",
            "Epoch 95/1000\n",
            "24/24 [==============================] - 0s 593us/sample - loss: 3.4744 - accuracy: 0.2546\n",
            "Epoch 96/1000\n",
            "24/24 [==============================] - 0s 487us/sample - loss: 3.4724 - accuracy: 0.2593\n",
            "Epoch 97/1000\n",
            "24/24 [==============================] - 0s 526us/sample - loss: 3.4692 - accuracy: 0.2639\n",
            "Epoch 98/1000\n",
            "24/24 [==============================] - 0s 562us/sample - loss: 3.4627 - accuracy: 0.2639\n",
            "Epoch 99/1000\n",
            "24/24 [==============================] - 0s 380us/sample - loss: 3.4587 - accuracy: 0.2639\n",
            "Epoch 100/1000\n",
            "24/24 [==============================] - 0s 421us/sample - loss: 3.4573 - accuracy: 0.2593\n",
            "Epoch 101/1000\n",
            "24/24 [==============================] - 0s 490us/sample - loss: 3.4591 - accuracy: 0.2593\n",
            "Epoch 102/1000\n",
            "24/24 [==============================] - 0s 501us/sample - loss: 3.4557 - accuracy: 0.2593\n",
            "Epoch 103/1000\n",
            "24/24 [==============================] - 0s 559us/sample - loss: 3.4557 - accuracy: 0.2685\n",
            "Epoch 104/1000\n",
            "24/24 [==============================] - 0s 511us/sample - loss: 3.4482 - accuracy: 0.2593\n",
            "Epoch 105/1000\n",
            "24/24 [==============================] - 0s 532us/sample - loss: 3.4415 - accuracy: 0.2685\n",
            "Epoch 106/1000\n",
            "24/24 [==============================] - 0s 528us/sample - loss: 3.4411 - accuracy: 0.2639\n",
            "Epoch 107/1000\n",
            "24/24 [==============================] - 0s 668us/sample - loss: 3.4427 - accuracy: 0.2639\n",
            "Epoch 108/1000\n",
            "24/24 [==============================] - 0s 767us/sample - loss: 3.4374 - accuracy: 0.2731\n",
            "Epoch 109/1000\n",
            "24/24 [==============================] - 0s 380us/sample - loss: 3.4340 - accuracy: 0.2731\n",
            "Epoch 110/1000\n",
            "24/24 [==============================] - 0s 544us/sample - loss: 3.4331 - accuracy: 0.2870\n",
            "Epoch 111/1000\n",
            "24/24 [==============================] - 0s 592us/sample - loss: 3.4270 - accuracy: 0.2778\n",
            "Epoch 112/1000\n",
            "24/24 [==============================] - 0s 414us/sample - loss: 3.4287 - accuracy: 0.2824\n",
            "Epoch 113/1000\n",
            "24/24 [==============================] - 0s 533us/sample - loss: 3.4265 - accuracy: 0.2778\n",
            "Epoch 114/1000\n",
            "24/24 [==============================] - 0s 500us/sample - loss: 3.4180 - accuracy: 0.2870\n",
            "Epoch 115/1000\n",
            "24/24 [==============================] - 0s 532us/sample - loss: 3.4239 - accuracy: 0.2870\n",
            "Epoch 116/1000\n",
            "24/24 [==============================] - 0s 615us/sample - loss: 3.4187 - accuracy: 0.2870\n",
            "Epoch 117/1000\n",
            "24/24 [==============================] - 0s 561us/sample - loss: 3.4164 - accuracy: 0.2963\n",
            "Epoch 118/1000\n",
            "24/24 [==============================] - 0s 794us/sample - loss: 3.4232 - accuracy: 0.2870\n",
            "Epoch 119/1000\n",
            "24/24 [==============================] - 0s 499us/sample - loss: 3.4106 - accuracy: 0.2917\n",
            "Epoch 120/1000\n",
            "24/24 [==============================] - 0s 584us/sample - loss: 3.4123 - accuracy: 0.2917\n",
            "Epoch 121/1000\n",
            "24/24 [==============================] - 0s 695us/sample - loss: 3.3983 - accuracy: 0.2963\n",
            "Epoch 122/1000\n",
            "24/24 [==============================] - 0s 509us/sample - loss: 3.3998 - accuracy: 0.2963\n",
            "Epoch 123/1000\n",
            "24/24 [==============================] - 0s 716us/sample - loss: 3.3897 - accuracy: 0.2963\n",
            "Epoch 124/1000\n",
            "24/24 [==============================] - 0s 673us/sample - loss: 3.3841 - accuracy: 0.3009\n",
            "Epoch 125/1000\n",
            "24/24 [==============================] - 0s 598us/sample - loss: 3.4020 - accuracy: 0.2963\n",
            "Epoch 126/1000\n",
            "24/24 [==============================] - 0s 558us/sample - loss: 3.3948 - accuracy: 0.2963\n",
            "Epoch 127/1000\n",
            "24/24 [==============================] - 0s 709us/sample - loss: 3.3837 - accuracy: 0.3009\n",
            "Epoch 128/1000\n",
            "24/24 [==============================] - 0s 607us/sample - loss: 3.3793 - accuracy: 0.3009\n",
            "Epoch 129/1000\n",
            "24/24 [==============================] - 0s 441us/sample - loss: 3.3836 - accuracy: 0.3009\n",
            "Epoch 130/1000\n",
            "24/24 [==============================] - 0s 620us/sample - loss: 3.3714 - accuracy: 0.3009\n",
            "Epoch 131/1000\n",
            "24/24 [==============================] - 0s 419us/sample - loss: 3.3650 - accuracy: 0.3009\n",
            "Epoch 132/1000\n",
            "24/24 [==============================] - 0s 403us/sample - loss: 3.3684 - accuracy: 0.2963\n",
            "Epoch 133/1000\n",
            "24/24 [==============================] - 0s 562us/sample - loss: 3.3665 - accuracy: 0.3009\n",
            "Epoch 134/1000\n",
            "24/24 [==============================] - 0s 671us/sample - loss: 3.3570 - accuracy: 0.3009\n",
            "Epoch 135/1000\n",
            "24/24 [==============================] - 0s 529us/sample - loss: 3.3553 - accuracy: 0.3009\n",
            "Epoch 136/1000\n",
            "24/24 [==============================] - 0s 578us/sample - loss: 3.3477 - accuracy: 0.3009\n",
            "Epoch 137/1000\n",
            "24/24 [==============================] - 0s 481us/sample - loss: 3.3462 - accuracy: 0.3009\n",
            "Epoch 138/1000\n",
            "24/24 [==============================] - 0s 661us/sample - loss: 3.3468 - accuracy: 0.3009\n",
            "Epoch 139/1000\n",
            "24/24 [==============================] - 0s 588us/sample - loss: 3.3433 - accuracy: 0.3009\n",
            "Epoch 140/1000\n",
            "24/24 [==============================] - 0s 562us/sample - loss: 3.3396 - accuracy: 0.3009\n",
            "Epoch 141/1000\n",
            "24/24 [==============================] - 0s 627us/sample - loss: 3.3350 - accuracy: 0.3009\n",
            "Epoch 142/1000\n",
            "24/24 [==============================] - 0s 617us/sample - loss: 3.3139 - accuracy: 0.3009\n",
            "Epoch 143/1000\n",
            "24/24 [==============================] - 0s 508us/sample - loss: 3.3264 - accuracy: 0.3009\n",
            "Epoch 144/1000\n",
            "24/24 [==============================] - 0s 479us/sample - loss: 3.3078 - accuracy: 0.3009\n",
            "Epoch 145/1000\n",
            "24/24 [==============================] - 0s 463us/sample - loss: 3.3034 - accuracy: 0.3009\n",
            "Epoch 146/1000\n",
            "24/24 [==============================] - 0s 462us/sample - loss: 3.3033 - accuracy: 0.3009\n",
            "Epoch 147/1000\n",
            "24/24 [==============================] - 0s 491us/sample - loss: 3.3009 - accuracy: 0.3009\n",
            "Epoch 148/1000\n",
            "24/24 [==============================] - 0s 475us/sample - loss: 3.2989 - accuracy: 0.3009\n",
            "Epoch 149/1000\n",
            "24/24 [==============================] - 0s 582us/sample - loss: 3.2896 - accuracy: 0.3009\n",
            "Epoch 150/1000\n",
            "24/24 [==============================] - 0s 650us/sample - loss: 3.2834 - accuracy: 0.3009\n",
            "Epoch 151/1000\n",
            "24/24 [==============================] - 0s 586us/sample - loss: 3.2851 - accuracy: 0.3009\n",
            "Epoch 152/1000\n",
            "24/24 [==============================] - 0s 563us/sample - loss: 3.2714 - accuracy: 0.3009\n",
            "Epoch 153/1000\n",
            "24/24 [==============================] - 0s 560us/sample - loss: 3.2736 - accuracy: 0.3009\n",
            "Epoch 154/1000\n",
            "24/24 [==============================] - 0s 561us/sample - loss: 3.2554 - accuracy: 0.3009\n",
            "Epoch 155/1000\n",
            "24/24 [==============================] - 0s 510us/sample - loss: 3.2433 - accuracy: 0.3009\n",
            "Epoch 156/1000\n",
            "24/24 [==============================] - 0s 604us/sample - loss: 3.2395 - accuracy: 0.3056\n",
            "Epoch 157/1000\n",
            "24/24 [==============================] - 0s 617us/sample - loss: 3.2408 - accuracy: 0.3056\n",
            "Epoch 158/1000\n",
            "24/24 [==============================] - 0s 587us/sample - loss: 3.2325 - accuracy: 0.3056\n",
            "Epoch 159/1000\n",
            "24/24 [==============================] - 0s 525us/sample - loss: 3.2356 - accuracy: 0.3009\n",
            "Epoch 160/1000\n",
            "24/24 [==============================] - 0s 958us/sample - loss: 3.2186 - accuracy: 0.3009\n",
            "Epoch 161/1000\n",
            "24/24 [==============================] - 0s 449us/sample - loss: 3.2213 - accuracy: 0.3009\n",
            "Epoch 162/1000\n",
            "24/24 [==============================] - 0s 553us/sample - loss: 3.2047 - accuracy: 0.3056\n",
            "Epoch 163/1000\n",
            "24/24 [==============================] - 0s 882us/sample - loss: 3.1993 - accuracy: 0.3056\n",
            "Epoch 164/1000\n",
            "24/24 [==============================] - 0s 409us/sample - loss: 3.1891 - accuracy: 0.3056\n",
            "Epoch 165/1000\n",
            "24/24 [==============================] - 0s 831us/sample - loss: 3.1709 - accuracy: 0.3056\n",
            "Epoch 166/1000\n",
            "24/24 [==============================] - 0s 586us/sample - loss: 3.1853 - accuracy: 0.3056\n",
            "Epoch 167/1000\n",
            "24/24 [==============================] - 0s 598us/sample - loss: 3.1675 - accuracy: 0.3056\n",
            "Epoch 168/1000\n",
            "24/24 [==============================] - 0s 647us/sample - loss: 3.1666 - accuracy: 0.3056\n",
            "Epoch 169/1000\n",
            "24/24 [==============================] - 0s 508us/sample - loss: 3.1586 - accuracy: 0.3056\n",
            "Epoch 170/1000\n",
            "24/24 [==============================] - 0s 640us/sample - loss: 3.1609 - accuracy: 0.3056\n",
            "Epoch 171/1000\n",
            "24/24 [==============================] - 0s 502us/sample - loss: 3.1365 - accuracy: 0.3056\n",
            "Epoch 172/1000\n",
            "24/24 [==============================] - 0s 623us/sample - loss: 3.1231 - accuracy: 0.3056\n",
            "Epoch 173/1000\n",
            "24/24 [==============================] - 0s 669us/sample - loss: 3.1332 - accuracy: 0.3056\n",
            "Epoch 174/1000\n",
            "24/24 [==============================] - 0s 487us/sample - loss: 3.1044 - accuracy: 0.3056\n",
            "Epoch 175/1000\n",
            "24/24 [==============================] - 0s 635us/sample - loss: 3.1046 - accuracy: 0.3056\n",
            "Epoch 176/1000\n",
            "24/24 [==============================] - 0s 523us/sample - loss: 3.0971 - accuracy: 0.3056\n",
            "Epoch 177/1000\n",
            "24/24 [==============================] - 0s 623us/sample - loss: 3.0800 - accuracy: 0.3102\n",
            "Epoch 178/1000\n",
            "24/24 [==============================] - 0s 582us/sample - loss: 3.0758 - accuracy: 0.3056\n",
            "Epoch 179/1000\n",
            "24/24 [==============================] - 0s 645us/sample - loss: 3.0659 - accuracy: 0.3102\n",
            "Epoch 180/1000\n",
            "24/24 [==============================] - 0s 597us/sample - loss: 3.0536 - accuracy: 0.3056\n",
            "Epoch 181/1000\n",
            "24/24 [==============================] - 0s 539us/sample - loss: 3.0483 - accuracy: 0.3056\n",
            "Epoch 182/1000\n",
            "24/24 [==============================] - 0s 627us/sample - loss: 3.0465 - accuracy: 0.3056\n",
            "Epoch 183/1000\n",
            "24/24 [==============================] - 0s 558us/sample - loss: 3.0360 - accuracy: 0.3102\n",
            "Epoch 184/1000\n",
            "24/24 [==============================] - 0s 540us/sample - loss: 2.9929 - accuracy: 0.3102\n",
            "Epoch 185/1000\n",
            "24/24 [==============================] - 0s 543us/sample - loss: 3.0060 - accuracy: 0.3148\n",
            "Epoch 186/1000\n",
            "24/24 [==============================] - 0s 591us/sample - loss: 3.0109 - accuracy: 0.3056\n",
            "Epoch 187/1000\n",
            "24/24 [==============================] - 0s 638us/sample - loss: 2.9974 - accuracy: 0.3148\n",
            "Epoch 188/1000\n",
            "24/24 [==============================] - 0s 408us/sample - loss: 2.9771 - accuracy: 0.3148\n",
            "Epoch 189/1000\n",
            "24/24 [==============================] - 0s 677us/sample - loss: 2.9692 - accuracy: 0.3194\n",
            "Epoch 190/1000\n",
            "24/24 [==============================] - 0s 464us/sample - loss: 2.9504 - accuracy: 0.3194\n",
            "Epoch 191/1000\n",
            "24/24 [==============================] - 0s 524us/sample - loss: 2.9389 - accuracy: 0.3148\n",
            "Epoch 192/1000\n",
            "24/24 [==============================] - 0s 578us/sample - loss: 2.9392 - accuracy: 0.3287\n",
            "Epoch 193/1000\n",
            "24/24 [==============================] - 0s 507us/sample - loss: 2.9401 - accuracy: 0.3241\n",
            "Epoch 194/1000\n",
            "24/24 [==============================] - 0s 522us/sample - loss: 2.9028 - accuracy: 0.3333\n",
            "Epoch 195/1000\n",
            "24/24 [==============================] - 0s 567us/sample - loss: 2.8846 - accuracy: 0.3333\n",
            "Epoch 196/1000\n",
            "24/24 [==============================] - 0s 601us/sample - loss: 2.8847 - accuracy: 0.3333\n",
            "Epoch 197/1000\n",
            "24/24 [==============================] - 0s 518us/sample - loss: 2.8741 - accuracy: 0.3333\n",
            "Epoch 198/1000\n",
            "24/24 [==============================] - 0s 543us/sample - loss: 2.8724 - accuracy: 0.3241\n",
            "Epoch 199/1000\n",
            "24/24 [==============================] - 0s 580us/sample - loss: 2.8449 - accuracy: 0.3380\n",
            "Epoch 200/1000\n",
            "24/24 [==============================] - 0s 583us/sample - loss: 2.8488 - accuracy: 0.3380\n",
            "Epoch 201/1000\n",
            "24/24 [==============================] - 0s 568us/sample - loss: 2.8361 - accuracy: 0.3380\n",
            "Epoch 202/1000\n",
            "24/24 [==============================] - 0s 545us/sample - loss: 2.8196 - accuracy: 0.3472\n",
            "Epoch 203/1000\n",
            "24/24 [==============================] - 0s 646us/sample - loss: 2.8072 - accuracy: 0.3380\n",
            "Epoch 204/1000\n",
            "24/24 [==============================] - 0s 609us/sample - loss: 2.7836 - accuracy: 0.3519\n",
            "Epoch 205/1000\n",
            "24/24 [==============================] - 0s 588us/sample - loss: 2.7871 - accuracy: 0.3519\n",
            "Epoch 206/1000\n",
            "24/24 [==============================] - 0s 720us/sample - loss: 2.7859 - accuracy: 0.3426\n",
            "Epoch 207/1000\n",
            "24/24 [==============================] - 0s 610us/sample - loss: 2.7546 - accuracy: 0.3426\n",
            "Epoch 208/1000\n",
            "24/24 [==============================] - 0s 422us/sample - loss: 2.7429 - accuracy: 0.3426\n",
            "Epoch 209/1000\n",
            "24/24 [==============================] - 0s 585us/sample - loss: 2.7282 - accuracy: 0.3426\n",
            "Epoch 210/1000\n",
            "24/24 [==============================] - 0s 806us/sample - loss: 2.7114 - accuracy: 0.3472\n",
            "Epoch 211/1000\n",
            "24/24 [==============================] - 0s 452us/sample - loss: 2.7061 - accuracy: 0.3519\n",
            "Epoch 212/1000\n",
            "24/24 [==============================] - 0s 648us/sample - loss: 2.6831 - accuracy: 0.3611\n",
            "Epoch 213/1000\n",
            "24/24 [==============================] - 0s 475us/sample - loss: 2.6828 - accuracy: 0.3565\n",
            "Epoch 214/1000\n",
            "24/24 [==============================] - 0s 482us/sample - loss: 2.6618 - accuracy: 0.3611\n",
            "Epoch 215/1000\n",
            "24/24 [==============================] - 0s 500us/sample - loss: 2.6453 - accuracy: 0.3519\n",
            "Epoch 216/1000\n",
            "24/24 [==============================] - 0s 833us/sample - loss: 2.6264 - accuracy: 0.3472\n",
            "Epoch 217/1000\n",
            "24/24 [==============================] - 0s 606us/sample - loss: 2.6251 - accuracy: 0.3519\n",
            "Epoch 218/1000\n",
            "24/24 [==============================] - 0s 540us/sample - loss: 2.6116 - accuracy: 0.3611\n",
            "Epoch 219/1000\n",
            "24/24 [==============================] - 0s 524us/sample - loss: 2.5702 - accuracy: 0.3889\n",
            "Epoch 220/1000\n",
            "24/24 [==============================] - 0s 705us/sample - loss: 2.5916 - accuracy: 0.3657\n",
            "Epoch 221/1000\n",
            "24/24 [==============================] - 0s 446us/sample - loss: 2.5630 - accuracy: 0.3796\n",
            "Epoch 222/1000\n",
            "24/24 [==============================] - 0s 613us/sample - loss: 2.5472 - accuracy: 0.3750\n",
            "Epoch 223/1000\n",
            "24/24 [==============================] - 0s 660us/sample - loss: 2.5430 - accuracy: 0.3843\n",
            "Epoch 224/1000\n",
            "24/24 [==============================] - 0s 565us/sample - loss: 2.5229 - accuracy: 0.3796\n",
            "Epoch 225/1000\n",
            "24/24 [==============================] - 0s 625us/sample - loss: 2.5348 - accuracy: 0.3611\n",
            "Epoch 226/1000\n",
            "24/24 [==============================] - 0s 565us/sample - loss: 2.4864 - accuracy: 0.3750\n",
            "Epoch 227/1000\n",
            "24/24 [==============================] - 0s 460us/sample - loss: 2.4776 - accuracy: 0.3889\n",
            "Epoch 228/1000\n",
            "24/24 [==============================] - 0s 639us/sample - loss: 2.4629 - accuracy: 0.3889\n",
            "Epoch 229/1000\n",
            "24/24 [==============================] - 0s 584us/sample - loss: 2.4569 - accuracy: 0.3704\n",
            "Epoch 230/1000\n",
            "24/24 [==============================] - 0s 636us/sample - loss: 2.4359 - accuracy: 0.3843\n",
            "Epoch 231/1000\n",
            "24/24 [==============================] - 0s 531us/sample - loss: 2.4304 - accuracy: 0.3981\n",
            "Epoch 232/1000\n",
            "24/24 [==============================] - 0s 597us/sample - loss: 2.4108 - accuracy: 0.3981\n",
            "Epoch 233/1000\n",
            "24/24 [==============================] - 0s 605us/sample - loss: 2.3966 - accuracy: 0.4120\n",
            "Epoch 234/1000\n",
            "24/24 [==============================] - 0s 696us/sample - loss: 2.3698 - accuracy: 0.4259\n",
            "Epoch 235/1000\n",
            "24/24 [==============================] - 0s 537us/sample - loss: 2.3615 - accuracy: 0.4306\n",
            "Epoch 236/1000\n",
            "24/24 [==============================] - 0s 588us/sample - loss: 2.3499 - accuracy: 0.4028\n",
            "Epoch 237/1000\n",
            "24/24 [==============================] - 0s 717us/sample - loss: 2.3252 - accuracy: 0.4398\n",
            "Epoch 238/1000\n",
            "24/24 [==============================] - 0s 610us/sample - loss: 2.3022 - accuracy: 0.4306\n",
            "Epoch 239/1000\n",
            "24/24 [==============================] - 0s 471us/sample - loss: 2.3151 - accuracy: 0.4120\n",
            "Epoch 240/1000\n",
            "24/24 [==============================] - 0s 571us/sample - loss: 2.2753 - accuracy: 0.4306\n",
            "Epoch 241/1000\n",
            "24/24 [==============================] - 0s 614us/sample - loss: 2.2737 - accuracy: 0.4583\n",
            "Epoch 242/1000\n",
            "24/24 [==============================] - 0s 566us/sample - loss: 2.2587 - accuracy: 0.4444\n",
            "Epoch 243/1000\n",
            "24/24 [==============================] - 0s 650us/sample - loss: 2.2512 - accuracy: 0.4630\n",
            "Epoch 244/1000\n",
            "24/24 [==============================] - 0s 704us/sample - loss: 2.2376 - accuracy: 0.4398\n",
            "Epoch 245/1000\n",
            "24/24 [==============================] - 0s 592us/sample - loss: 2.2037 - accuracy: 0.4583\n",
            "Epoch 246/1000\n",
            "24/24 [==============================] - 0s 652us/sample - loss: 2.1955 - accuracy: 0.4583\n",
            "Epoch 247/1000\n",
            "24/24 [==============================] - 0s 486us/sample - loss: 2.1825 - accuracy: 0.4630\n",
            "Epoch 248/1000\n",
            "24/24 [==============================] - 0s 640us/sample - loss: 2.1682 - accuracy: 0.4769\n",
            "Epoch 249/1000\n",
            "24/24 [==============================] - 0s 632us/sample - loss: 2.1573 - accuracy: 0.4491\n",
            "Epoch 250/1000\n",
            "24/24 [==============================] - 0s 628us/sample - loss: 2.1384 - accuracy: 0.4815\n",
            "Epoch 251/1000\n",
            "24/24 [==============================] - 0s 639us/sample - loss: 2.1282 - accuracy: 0.4861\n",
            "Epoch 252/1000\n",
            "24/24 [==============================] - 0s 792us/sample - loss: 2.1184 - accuracy: 0.4861\n",
            "Epoch 253/1000\n",
            "24/24 [==============================] - 0s 747us/sample - loss: 2.0879 - accuracy: 0.5046\n",
            "Epoch 254/1000\n",
            "24/24 [==============================] - 0s 643us/sample - loss: 2.0916 - accuracy: 0.4907\n",
            "Epoch 255/1000\n",
            "24/24 [==============================] - 0s 617us/sample - loss: 2.0726 - accuracy: 0.5185\n",
            "Epoch 256/1000\n",
            "24/24 [==============================] - 0s 457us/sample - loss: 2.0533 - accuracy: 0.5046\n",
            "Epoch 257/1000\n",
            "24/24 [==============================] - 0s 485us/sample - loss: 2.0283 - accuracy: 0.5324\n",
            "Epoch 258/1000\n",
            "24/24 [==============================] - 0s 444us/sample - loss: 2.0371 - accuracy: 0.5185\n",
            "Epoch 259/1000\n",
            "24/24 [==============================] - 0s 496us/sample - loss: 1.9992 - accuracy: 0.5324\n",
            "Epoch 260/1000\n",
            "24/24 [==============================] - 0s 425us/sample - loss: 1.9933 - accuracy: 0.5000\n",
            "Epoch 261/1000\n",
            "24/24 [==============================] - 0s 427us/sample - loss: 1.9853 - accuracy: 0.5278\n",
            "Epoch 262/1000\n",
            "24/24 [==============================] - 0s 597us/sample - loss: 1.9881 - accuracy: 0.5139\n",
            "Epoch 263/1000\n",
            "24/24 [==============================] - 0s 549us/sample - loss: 1.9566 - accuracy: 0.5278\n",
            "Epoch 264/1000\n",
            "24/24 [==============================] - 0s 548us/sample - loss: 1.9484 - accuracy: 0.5463\n",
            "Epoch 265/1000\n",
            "24/24 [==============================] - 0s 427us/sample - loss: 1.9443 - accuracy: 0.5417\n",
            "Epoch 266/1000\n",
            "24/24 [==============================] - 0s 598us/sample - loss: 1.9363 - accuracy: 0.5417\n",
            "Epoch 267/1000\n",
            "24/24 [==============================] - 0s 538us/sample - loss: 1.9228 - accuracy: 0.5231\n",
            "Epoch 268/1000\n",
            "24/24 [==============================] - 0s 593us/sample - loss: 1.8800 - accuracy: 0.5741\n",
            "Epoch 269/1000\n",
            "24/24 [==============================] - 0s 466us/sample - loss: 1.8767 - accuracy: 0.5509\n",
            "Epoch 270/1000\n",
            "24/24 [==============================] - 0s 472us/sample - loss: 1.8705 - accuracy: 0.5370\n",
            "Epoch 271/1000\n",
            "24/24 [==============================] - 0s 470us/sample - loss: 1.8694 - accuracy: 0.5694\n",
            "Epoch 272/1000\n",
            "24/24 [==============================] - 0s 584us/sample - loss: 1.8683 - accuracy: 0.5370\n",
            "Epoch 273/1000\n",
            "24/24 [==============================] - 0s 638us/sample - loss: 1.8394 - accuracy: 0.5694\n",
            "Epoch 274/1000\n",
            "24/24 [==============================] - 0s 786us/sample - loss: 1.8327 - accuracy: 0.5463\n",
            "Epoch 275/1000\n",
            "24/24 [==============================] - 0s 609us/sample - loss: 1.8179 - accuracy: 0.5648\n",
            "Epoch 276/1000\n",
            "24/24 [==============================] - 0s 631us/sample - loss: 1.8071 - accuracy: 0.5648\n",
            "Epoch 277/1000\n",
            "24/24 [==============================] - 0s 625us/sample - loss: 1.8019 - accuracy: 0.5741\n",
            "Epoch 278/1000\n",
            "24/24 [==============================] - 0s 742us/sample - loss: 1.7768 - accuracy: 0.5694\n",
            "Epoch 279/1000\n",
            "24/24 [==============================] - 0s 484us/sample - loss: 1.7763 - accuracy: 0.5880\n",
            "Epoch 280/1000\n",
            "24/24 [==============================] - 0s 610us/sample - loss: 1.7585 - accuracy: 0.5602\n",
            "Epoch 281/1000\n",
            "24/24 [==============================] - 0s 610us/sample - loss: 1.7263 - accuracy: 0.6204\n",
            "Epoch 282/1000\n",
            "24/24 [==============================] - 0s 610us/sample - loss: 1.7348 - accuracy: 0.5926\n",
            "Epoch 283/1000\n",
            "24/24 [==============================] - 0s 559us/sample - loss: 1.7068 - accuracy: 0.6019\n",
            "Epoch 284/1000\n",
            "24/24 [==============================] - 0s 594us/sample - loss: 1.7147 - accuracy: 0.5926\n",
            "Epoch 285/1000\n",
            "24/24 [==============================] - 0s 531us/sample - loss: 1.6732 - accuracy: 0.6157\n",
            "Epoch 286/1000\n",
            "24/24 [==============================] - 0s 529us/sample - loss: 1.6892 - accuracy: 0.6111\n",
            "Epoch 287/1000\n",
            "24/24 [==============================] - 0s 734us/sample - loss: 1.6801 - accuracy: 0.6019\n",
            "Epoch 288/1000\n",
            "24/24 [==============================] - 0s 663us/sample - loss: 1.6380 - accuracy: 0.6111\n",
            "Epoch 289/1000\n",
            "24/24 [==============================] - 0s 528us/sample - loss: 1.6360 - accuracy: 0.6204\n",
            "Epoch 290/1000\n",
            "24/24 [==============================] - 0s 545us/sample - loss: 1.6299 - accuracy: 0.6157\n",
            "Epoch 291/1000\n",
            "24/24 [==============================] - 0s 616us/sample - loss: 1.6314 - accuracy: 0.6111\n",
            "Epoch 292/1000\n",
            "24/24 [==============================] - 0s 749us/sample - loss: 1.6085 - accuracy: 0.6296\n",
            "Epoch 293/1000\n",
            "24/24 [==============================] - 0s 699us/sample - loss: 1.6148 - accuracy: 0.6204\n",
            "Epoch 294/1000\n",
            "24/24 [==============================] - 0s 666us/sample - loss: 1.5953 - accuracy: 0.6343\n",
            "Epoch 295/1000\n",
            "24/24 [==============================] - 0s 631us/sample - loss: 1.5701 - accuracy: 0.6481\n",
            "Epoch 296/1000\n",
            "24/24 [==============================] - 0s 490us/sample - loss: 1.5716 - accuracy: 0.6204\n",
            "Epoch 297/1000\n",
            "24/24 [==============================] - 0s 916us/sample - loss: 1.5629 - accuracy: 0.6250\n",
            "Epoch 298/1000\n",
            "24/24 [==============================] - 0s 676us/sample - loss: 1.5634 - accuracy: 0.6157\n",
            "Epoch 299/1000\n",
            "24/24 [==============================] - 0s 510us/sample - loss: 1.5403 - accuracy: 0.6343\n",
            "Epoch 300/1000\n",
            "24/24 [==============================] - 0s 639us/sample - loss: 1.5084 - accuracy: 0.6574\n",
            "Epoch 301/1000\n",
            "24/24 [==============================] - 0s 538us/sample - loss: 1.5207 - accuracy: 0.6296\n",
            "Epoch 302/1000\n",
            "24/24 [==============================] - 0s 643us/sample - loss: 1.4916 - accuracy: 0.6620\n",
            "Epoch 303/1000\n",
            "24/24 [==============================] - 0s 562us/sample - loss: 1.5140 - accuracy: 0.6389\n",
            "Epoch 304/1000\n",
            "24/24 [==============================] - 0s 605us/sample - loss: 1.4741 - accuracy: 0.6574\n",
            "Epoch 305/1000\n",
            "24/24 [==============================] - 0s 492us/sample - loss: 1.4812 - accuracy: 0.6528\n",
            "Epoch 306/1000\n",
            "24/24 [==============================] - 0s 405us/sample - loss: 1.4551 - accuracy: 0.6852\n",
            "Epoch 307/1000\n",
            "24/24 [==============================] - 0s 436us/sample - loss: 1.4461 - accuracy: 0.6435\n",
            "Epoch 308/1000\n",
            "24/24 [==============================] - 0s 512us/sample - loss: 1.4629 - accuracy: 0.6620\n",
            "Epoch 309/1000\n",
            "24/24 [==============================] - 0s 575us/sample - loss: 1.4503 - accuracy: 0.6852\n",
            "Epoch 310/1000\n",
            "24/24 [==============================] - 0s 513us/sample - loss: 1.4109 - accuracy: 0.6806\n",
            "Epoch 311/1000\n",
            "24/24 [==============================] - 0s 629us/sample - loss: 1.4328 - accuracy: 0.6759\n",
            "Epoch 312/1000\n",
            "24/24 [==============================] - 0s 690us/sample - loss: 1.4052 - accuracy: 0.6898\n",
            "Epoch 313/1000\n",
            "24/24 [==============================] - 0s 504us/sample - loss: 1.3939 - accuracy: 0.6898\n",
            "Epoch 314/1000\n",
            "24/24 [==============================] - 0s 617us/sample - loss: 1.3725 - accuracy: 0.6944\n",
            "Epoch 315/1000\n",
            "24/24 [==============================] - 0s 610us/sample - loss: 1.3895 - accuracy: 0.6852\n",
            "Epoch 316/1000\n",
            "24/24 [==============================] - 0s 612us/sample - loss: 1.3798 - accuracy: 0.7083\n",
            "Epoch 317/1000\n",
            "24/24 [==============================] - 0s 586us/sample - loss: 1.3700 - accuracy: 0.6898\n",
            "Epoch 318/1000\n",
            "24/24 [==============================] - 0s 591us/sample - loss: 1.3503 - accuracy: 0.6944\n",
            "Epoch 319/1000\n",
            "24/24 [==============================] - 0s 525us/sample - loss: 1.3309 - accuracy: 0.6852\n",
            "Epoch 320/1000\n",
            "24/24 [==============================] - 0s 530us/sample - loss: 1.3382 - accuracy: 0.7176\n",
            "Epoch 321/1000\n",
            "24/24 [==============================] - 0s 593us/sample - loss: 1.3331 - accuracy: 0.7176\n",
            "Epoch 322/1000\n",
            "24/24 [==============================] - 0s 694us/sample - loss: 1.3228 - accuracy: 0.6991\n",
            "Epoch 323/1000\n",
            "24/24 [==============================] - 0s 647us/sample - loss: 1.3122 - accuracy: 0.7130\n",
            "Epoch 324/1000\n",
            "24/24 [==============================] - 0s 564us/sample - loss: 1.3172 - accuracy: 0.7130\n",
            "Epoch 325/1000\n",
            "24/24 [==============================] - 0s 576us/sample - loss: 1.3127 - accuracy: 0.6991\n",
            "Epoch 326/1000\n",
            "24/24 [==============================] - 0s 601us/sample - loss: 1.2858 - accuracy: 0.6944\n",
            "Epoch 327/1000\n",
            "24/24 [==============================] - 0s 533us/sample - loss: 1.2737 - accuracy: 0.7130\n",
            "Epoch 328/1000\n",
            "24/24 [==============================] - 0s 634us/sample - loss: 1.2644 - accuracy: 0.7407\n",
            "Epoch 329/1000\n",
            "24/24 [==============================] - 0s 779us/sample - loss: 1.2626 - accuracy: 0.7176\n",
            "Epoch 330/1000\n",
            "24/24 [==============================] - 0s 917us/sample - loss: 1.2606 - accuracy: 0.7222\n",
            "Epoch 331/1000\n",
            "24/24 [==============================] - 0s 476us/sample - loss: 1.2316 - accuracy: 0.7269\n",
            "Epoch 332/1000\n",
            "24/24 [==============================] - 0s 597us/sample - loss: 1.2350 - accuracy: 0.7315\n",
            "Epoch 333/1000\n",
            "24/24 [==============================] - 0s 526us/sample - loss: 1.2423 - accuracy: 0.7037\n",
            "Epoch 334/1000\n",
            "24/24 [==============================] - 0s 602us/sample - loss: 1.2173 - accuracy: 0.7454\n",
            "Epoch 335/1000\n",
            "24/24 [==============================] - 0s 572us/sample - loss: 1.2092 - accuracy: 0.7315\n",
            "Epoch 336/1000\n",
            "24/24 [==============================] - 0s 484us/sample - loss: 1.1959 - accuracy: 0.7407\n",
            "Epoch 337/1000\n",
            "24/24 [==============================] - 0s 569us/sample - loss: 1.2097 - accuracy: 0.7222\n",
            "Epoch 338/1000\n",
            "24/24 [==============================] - 0s 581us/sample - loss: 1.1847 - accuracy: 0.7269\n",
            "Epoch 339/1000\n",
            "24/24 [==============================] - 0s 605us/sample - loss: 1.1769 - accuracy: 0.7454\n",
            "Epoch 340/1000\n",
            "24/24 [==============================] - 0s 473us/sample - loss: 1.1782 - accuracy: 0.7500\n",
            "Epoch 341/1000\n",
            "24/24 [==============================] - 0s 718us/sample - loss: 1.1603 - accuracy: 0.7500\n",
            "Epoch 342/1000\n",
            "24/24 [==============================] - 0s 567us/sample - loss: 1.1634 - accuracy: 0.7500\n",
            "Epoch 343/1000\n",
            "24/24 [==============================] - 0s 610us/sample - loss: 1.1510 - accuracy: 0.7407\n",
            "Epoch 344/1000\n",
            "24/24 [==============================] - 0s 533us/sample - loss: 1.1425 - accuracy: 0.7454\n",
            "Epoch 345/1000\n",
            "24/24 [==============================] - 0s 617us/sample - loss: 1.1348 - accuracy: 0.7315\n",
            "Epoch 346/1000\n",
            "24/24 [==============================] - 0s 510us/sample - loss: 1.1317 - accuracy: 0.7454\n",
            "Epoch 347/1000\n",
            "24/24 [==============================] - 0s 489us/sample - loss: 1.1278 - accuracy: 0.7500\n",
            "Epoch 348/1000\n",
            "24/24 [==============================] - 0s 536us/sample - loss: 1.1128 - accuracy: 0.7500\n",
            "Epoch 349/1000\n",
            "24/24 [==============================] - 0s 417us/sample - loss: 1.0939 - accuracy: 0.7593\n",
            "Epoch 350/1000\n",
            "24/24 [==============================] - 0s 625us/sample - loss: 1.0920 - accuracy: 0.7593\n",
            "Epoch 351/1000\n",
            "24/24 [==============================] - 0s 763us/sample - loss: 1.1015 - accuracy: 0.7685\n",
            "Epoch 352/1000\n",
            "24/24 [==============================] - 0s 595us/sample - loss: 1.0754 - accuracy: 0.7639\n",
            "Epoch 353/1000\n",
            "24/24 [==============================] - 0s 547us/sample - loss: 1.0714 - accuracy: 0.7731\n",
            "Epoch 354/1000\n",
            "24/24 [==============================] - 0s 580us/sample - loss: 1.0693 - accuracy: 0.7685\n",
            "Epoch 355/1000\n",
            "24/24 [==============================] - 0s 569us/sample - loss: 1.0661 - accuracy: 0.7639\n",
            "Epoch 356/1000\n",
            "24/24 [==============================] - 0s 506us/sample - loss: 1.0624 - accuracy: 0.7546\n",
            "Epoch 357/1000\n",
            "24/24 [==============================] - 0s 545us/sample - loss: 1.0554 - accuracy: 0.7778\n",
            "Epoch 358/1000\n",
            "24/24 [==============================] - 0s 519us/sample - loss: 1.0449 - accuracy: 0.7731\n",
            "Epoch 359/1000\n",
            "24/24 [==============================] - 0s 624us/sample - loss: 1.0493 - accuracy: 0.7685\n",
            "Epoch 360/1000\n",
            "24/24 [==============================] - 0s 526us/sample - loss: 1.0275 - accuracy: 0.7685\n",
            "Epoch 361/1000\n",
            "24/24 [==============================] - 0s 572us/sample - loss: 1.0149 - accuracy: 0.7824\n",
            "Epoch 362/1000\n",
            "24/24 [==============================] - 0s 544us/sample - loss: 1.0202 - accuracy: 0.7870\n",
            "Epoch 363/1000\n",
            "24/24 [==============================] - 0s 590us/sample - loss: 1.0051 - accuracy: 0.7963\n",
            "Epoch 364/1000\n",
            "24/24 [==============================] - 0s 604us/sample - loss: 0.9975 - accuracy: 0.7870\n",
            "Epoch 365/1000\n",
            "24/24 [==============================] - 0s 518us/sample - loss: 0.9996 - accuracy: 0.7824\n",
            "Epoch 366/1000\n",
            "24/24 [==============================] - 0s 668us/sample - loss: 0.9944 - accuracy: 0.7778\n",
            "Epoch 367/1000\n",
            "24/24 [==============================] - 0s 606us/sample - loss: 0.9842 - accuracy: 0.7870\n",
            "Epoch 368/1000\n",
            "24/24 [==============================] - 0s 686us/sample - loss: 0.9844 - accuracy: 0.7824\n",
            "Epoch 369/1000\n",
            "24/24 [==============================] - 0s 625us/sample - loss: 0.9733 - accuracy: 0.8009\n",
            "Epoch 370/1000\n",
            "24/24 [==============================] - 0s 752us/sample - loss: 0.9637 - accuracy: 0.8009\n",
            "Epoch 371/1000\n",
            "24/24 [==============================] - 0s 616us/sample - loss: 0.9630 - accuracy: 0.7870\n",
            "Epoch 372/1000\n",
            "24/24 [==============================] - 0s 612us/sample - loss: 0.9491 - accuracy: 0.7963\n",
            "Epoch 373/1000\n",
            "24/24 [==============================] - 0s 577us/sample - loss: 0.9434 - accuracy: 0.8148\n",
            "Epoch 374/1000\n",
            "24/24 [==============================] - 0s 620us/sample - loss: 0.9505 - accuracy: 0.7963\n",
            "Epoch 375/1000\n",
            "24/24 [==============================] - 0s 560us/sample - loss: 0.9264 - accuracy: 0.8102\n",
            "Epoch 376/1000\n",
            "24/24 [==============================] - 0s 473us/sample - loss: 0.9290 - accuracy: 0.7963\n",
            "Epoch 377/1000\n",
            "24/24 [==============================] - 0s 512us/sample - loss: 0.9234 - accuracy: 0.8102\n",
            "Epoch 378/1000\n",
            "24/24 [==============================] - 0s 750us/sample - loss: 0.9380 - accuracy: 0.8056\n",
            "Epoch 379/1000\n",
            "24/24 [==============================] - 0s 435us/sample - loss: 0.9012 - accuracy: 0.8194\n",
            "Epoch 380/1000\n",
            "24/24 [==============================] - 0s 769us/sample - loss: 0.8945 - accuracy: 0.8148\n",
            "Epoch 381/1000\n",
            "24/24 [==============================] - 0s 619us/sample - loss: 0.9100 - accuracy: 0.7963\n",
            "Epoch 382/1000\n",
            "24/24 [==============================] - 0s 708us/sample - loss: 0.8864 - accuracy: 0.8194\n",
            "Epoch 383/1000\n",
            "24/24 [==============================] - 0s 593us/sample - loss: 0.8910 - accuracy: 0.8194\n",
            "Epoch 384/1000\n",
            "24/24 [==============================] - 0s 752us/sample - loss: 0.8912 - accuracy: 0.8287\n",
            "Epoch 385/1000\n",
            "24/24 [==============================] - 0s 506us/sample - loss: 0.8810 - accuracy: 0.8287\n",
            "Epoch 386/1000\n",
            "24/24 [==============================] - 0s 911us/sample - loss: 0.8684 - accuracy: 0.8241\n",
            "Epoch 387/1000\n",
            "24/24 [==============================] - 0s 572us/sample - loss: 0.8690 - accuracy: 0.8333\n",
            "Epoch 388/1000\n",
            "24/24 [==============================] - 0s 564us/sample - loss: 0.8625 - accuracy: 0.8287\n",
            "Epoch 389/1000\n",
            "24/24 [==============================] - 0s 511us/sample - loss: 0.8520 - accuracy: 0.8380\n",
            "Epoch 390/1000\n",
            "24/24 [==============================] - 0s 489us/sample - loss: 0.8418 - accuracy: 0.8241\n",
            "Epoch 391/1000\n",
            "24/24 [==============================] - 0s 583us/sample - loss: 0.8358 - accuracy: 0.8241\n",
            "Epoch 392/1000\n",
            "24/24 [==============================] - 0s 559us/sample - loss: 0.8361 - accuracy: 0.8287\n",
            "Epoch 393/1000\n",
            "24/24 [==============================] - 0s 475us/sample - loss: 0.8392 - accuracy: 0.8194\n",
            "Epoch 394/1000\n",
            "24/24 [==============================] - 0s 603us/sample - loss: 0.8299 - accuracy: 0.8380\n",
            "Epoch 395/1000\n",
            "24/24 [==============================] - 0s 494us/sample - loss: 0.8343 - accuracy: 0.8194\n",
            "Epoch 396/1000\n",
            "24/24 [==============================] - 0s 720us/sample - loss: 0.8139 - accuracy: 0.8333\n",
            "Epoch 397/1000\n",
            "24/24 [==============================] - 0s 479us/sample - loss: 0.8157 - accuracy: 0.8241\n",
            "Epoch 398/1000\n",
            "24/24 [==============================] - 0s 541us/sample - loss: 0.8136 - accuracy: 0.8380\n",
            "Epoch 399/1000\n",
            "24/24 [==============================] - 0s 533us/sample - loss: 0.7993 - accuracy: 0.8333\n",
            "Epoch 400/1000\n",
            "24/24 [==============================] - 0s 574us/sample - loss: 0.7937 - accuracy: 0.8472\n",
            "Epoch 401/1000\n",
            "24/24 [==============================] - 0s 467us/sample - loss: 0.7867 - accuracy: 0.8380\n",
            "Epoch 402/1000\n",
            "24/24 [==============================] - 0s 524us/sample - loss: 0.7859 - accuracy: 0.8472\n",
            "Epoch 403/1000\n",
            "24/24 [==============================] - 0s 584us/sample - loss: 0.7871 - accuracy: 0.8380\n",
            "Epoch 404/1000\n",
            "24/24 [==============================] - 0s 669us/sample - loss: 0.7745 - accuracy: 0.8333\n",
            "Epoch 405/1000\n",
            "24/24 [==============================] - 0s 633us/sample - loss: 0.7821 - accuracy: 0.8426\n",
            "Epoch 406/1000\n",
            "24/24 [==============================] - 0s 737us/sample - loss: 0.7688 - accuracy: 0.8426\n",
            "Epoch 407/1000\n",
            "24/24 [==============================] - 0s 519us/sample - loss: 0.7580 - accuracy: 0.8472\n",
            "Epoch 408/1000\n",
            "24/24 [==============================] - 0s 514us/sample - loss: 0.7523 - accuracy: 0.8426\n",
            "Epoch 409/1000\n",
            "24/24 [==============================] - 0s 598us/sample - loss: 0.7578 - accuracy: 0.8426\n",
            "Epoch 410/1000\n",
            "24/24 [==============================] - 0s 577us/sample - loss: 0.7645 - accuracy: 0.8333\n",
            "Epoch 411/1000\n",
            "24/24 [==============================] - 0s 618us/sample - loss: 0.7432 - accuracy: 0.8519\n",
            "Epoch 412/1000\n",
            "24/24 [==============================] - 0s 589us/sample - loss: 0.7330 - accuracy: 0.8426\n",
            "Epoch 413/1000\n",
            "24/24 [==============================] - 0s 565us/sample - loss: 0.7352 - accuracy: 0.8519\n",
            "Epoch 414/1000\n",
            "24/24 [==============================] - 0s 617us/sample - loss: 0.7336 - accuracy: 0.8565\n",
            "Epoch 415/1000\n",
            "24/24 [==============================] - 0s 617us/sample - loss: 0.7224 - accuracy: 0.8472\n",
            "Epoch 416/1000\n",
            "24/24 [==============================] - 0s 608us/sample - loss: 0.7267 - accuracy: 0.8565\n",
            "Epoch 417/1000\n",
            "24/24 [==============================] - 0s 510us/sample - loss: 0.7093 - accuracy: 0.8565\n",
            "Epoch 418/1000\n",
            "24/24 [==============================] - 0s 540us/sample - loss: 0.7116 - accuracy: 0.8611\n",
            "Epoch 419/1000\n",
            "24/24 [==============================] - 0s 400us/sample - loss: 0.7161 - accuracy: 0.8611\n",
            "Epoch 420/1000\n",
            "24/24 [==============================] - 0s 562us/sample - loss: 0.7002 - accuracy: 0.8519\n",
            "Epoch 421/1000\n",
            "24/24 [==============================] - 0s 672us/sample - loss: 0.7011 - accuracy: 0.8657\n",
            "Epoch 422/1000\n",
            "24/24 [==============================] - 0s 535us/sample - loss: 0.7025 - accuracy: 0.8611\n",
            "Epoch 423/1000\n",
            "24/24 [==============================] - 0s 787us/sample - loss: 0.7014 - accuracy: 0.8657\n",
            "Epoch 424/1000\n",
            "24/24 [==============================] - 0s 663us/sample - loss: 0.6828 - accuracy: 0.8611\n",
            "Epoch 425/1000\n",
            "24/24 [==============================] - 0s 425us/sample - loss: 0.6840 - accuracy: 0.8611\n",
            "Epoch 426/1000\n",
            "24/24 [==============================] - 0s 819us/sample - loss: 0.6745 - accuracy: 0.8657\n",
            "Epoch 427/1000\n",
            "24/24 [==============================] - 0s 496us/sample - loss: 0.6754 - accuracy: 0.8611\n",
            "Epoch 428/1000\n",
            "24/24 [==============================] - 0s 773us/sample - loss: 0.6705 - accuracy: 0.8704\n",
            "Epoch 429/1000\n",
            "24/24 [==============================] - 0s 463us/sample - loss: 0.6695 - accuracy: 0.8704\n",
            "Epoch 430/1000\n",
            "24/24 [==============================] - 0s 470us/sample - loss: 0.6572 - accuracy: 0.8796\n",
            "Epoch 431/1000\n",
            "24/24 [==============================] - 0s 654us/sample - loss: 0.6581 - accuracy: 0.8750\n",
            "Epoch 432/1000\n",
            "24/24 [==============================] - 0s 516us/sample - loss: 0.6596 - accuracy: 0.8796\n",
            "Epoch 433/1000\n",
            "24/24 [==============================] - 0s 725us/sample - loss: 0.6426 - accuracy: 0.8704\n",
            "Epoch 434/1000\n",
            "24/24 [==============================] - 0s 481us/sample - loss: 0.6529 - accuracy: 0.8704\n",
            "Epoch 435/1000\n",
            "24/24 [==============================] - 0s 589us/sample - loss: 0.6369 - accuracy: 0.8750\n",
            "Epoch 436/1000\n",
            "24/24 [==============================] - 0s 686us/sample - loss: 0.6366 - accuracy: 0.8750\n",
            "Epoch 437/1000\n",
            "24/24 [==============================] - 0s 460us/sample - loss: 0.6293 - accuracy: 0.8843\n",
            "Epoch 438/1000\n",
            "24/24 [==============================] - 0s 669us/sample - loss: 0.6236 - accuracy: 0.8843\n",
            "Epoch 439/1000\n",
            "24/24 [==============================] - 0s 658us/sample - loss: 0.6306 - accuracy: 0.8704\n",
            "Epoch 440/1000\n",
            "24/24 [==============================] - 0s 531us/sample - loss: 0.6276 - accuracy: 0.8843\n",
            "Epoch 441/1000\n",
            "24/24 [==============================] - 0s 512us/sample - loss: 0.6235 - accuracy: 0.8796\n",
            "Epoch 442/1000\n",
            "24/24 [==============================] - 0s 858us/sample - loss: 0.6191 - accuracy: 0.8796\n",
            "Epoch 443/1000\n",
            "24/24 [==============================] - 0s 478us/sample - loss: 0.6098 - accuracy: 0.8796\n",
            "Epoch 444/1000\n",
            "24/24 [==============================] - 0s 575us/sample - loss: 0.6111 - accuracy: 0.8843\n",
            "Epoch 445/1000\n",
            "24/24 [==============================] - 0s 565us/sample - loss: 0.5999 - accuracy: 0.8796\n",
            "Epoch 446/1000\n",
            "24/24 [==============================] - 0s 415us/sample - loss: 0.5960 - accuracy: 0.8843\n",
            "Epoch 447/1000\n",
            "24/24 [==============================] - 0s 549us/sample - loss: 0.5989 - accuracy: 0.8796\n",
            "Epoch 448/1000\n",
            "24/24 [==============================] - 0s 564us/sample - loss: 0.5998 - accuracy: 0.8843\n",
            "Epoch 449/1000\n",
            "24/24 [==============================] - 0s 418us/sample - loss: 0.5942 - accuracy: 0.8889\n",
            "Epoch 450/1000\n",
            "24/24 [==============================] - 0s 719us/sample - loss: 0.5927 - accuracy: 0.8843\n",
            "Epoch 451/1000\n",
            "24/24 [==============================] - 0s 583us/sample - loss: 0.5873 - accuracy: 0.8843\n",
            "Epoch 452/1000\n",
            "24/24 [==============================] - 0s 600us/sample - loss: 0.5905 - accuracy: 0.8843\n",
            "Epoch 453/1000\n",
            "24/24 [==============================] - 0s 676us/sample - loss: 0.5784 - accuracy: 0.8889\n",
            "Epoch 454/1000\n",
            "24/24 [==============================] - 0s 471us/sample - loss: 0.5903 - accuracy: 0.8843\n",
            "Epoch 455/1000\n",
            "24/24 [==============================] - 0s 474us/sample - loss: 0.5715 - accuracy: 0.8889\n",
            "Epoch 456/1000\n",
            "24/24 [==============================] - 0s 468us/sample - loss: 0.5689 - accuracy: 0.8889\n",
            "Epoch 457/1000\n",
            "24/24 [==============================] - 0s 558us/sample - loss: 0.5605 - accuracy: 0.8889\n",
            "Epoch 458/1000\n",
            "24/24 [==============================] - 0s 409us/sample - loss: 0.5593 - accuracy: 0.8935\n",
            "Epoch 459/1000\n",
            "24/24 [==============================] - 0s 523us/sample - loss: 0.5649 - accuracy: 0.8889\n",
            "Epoch 460/1000\n",
            "24/24 [==============================] - 0s 519us/sample - loss: 0.5487 - accuracy: 0.8889\n",
            "Epoch 461/1000\n",
            "24/24 [==============================] - 0s 665us/sample - loss: 0.5579 - accuracy: 0.8981\n",
            "Epoch 462/1000\n",
            "24/24 [==============================] - 0s 556us/sample - loss: 0.5436 - accuracy: 0.8981\n",
            "Epoch 463/1000\n",
            "24/24 [==============================] - 0s 613us/sample - loss: 0.5441 - accuracy: 0.8981\n",
            "Epoch 464/1000\n",
            "24/24 [==============================] - 0s 535us/sample - loss: 0.5431 - accuracy: 0.8981\n",
            "Epoch 465/1000\n",
            "24/24 [==============================] - 0s 790us/sample - loss: 0.5407 - accuracy: 0.8889\n",
            "Epoch 466/1000\n",
            "24/24 [==============================] - 0s 737us/sample - loss: 0.5344 - accuracy: 0.8981\n",
            "Epoch 467/1000\n",
            "24/24 [==============================] - 0s 802us/sample - loss: 0.5317 - accuracy: 0.8981\n",
            "Epoch 468/1000\n",
            "24/24 [==============================] - 0s 783us/sample - loss: 0.5387 - accuracy: 0.8796\n",
            "Epoch 469/1000\n",
            "24/24 [==============================] - 0s 594us/sample - loss: 0.5281 - accuracy: 0.8981\n",
            "Epoch 470/1000\n",
            "24/24 [==============================] - 0s 726us/sample - loss: 0.5222 - accuracy: 0.8981\n",
            "Epoch 471/1000\n",
            "24/24 [==============================] - 0s 614us/sample - loss: 0.5153 - accuracy: 0.8981\n",
            "Epoch 472/1000\n",
            "24/24 [==============================] - 0s 703us/sample - loss: 0.5157 - accuracy: 0.9028\n",
            "Epoch 473/1000\n",
            "24/24 [==============================] - 0s 437us/sample - loss: 0.5094 - accuracy: 0.9028\n",
            "Epoch 474/1000\n",
            "24/24 [==============================] - 0s 712us/sample - loss: 0.5056 - accuracy: 0.9028\n",
            "Epoch 475/1000\n",
            "24/24 [==============================] - 0s 649us/sample - loss: 0.5097 - accuracy: 0.9028\n",
            "Epoch 476/1000\n",
            "24/24 [==============================] - 0s 640us/sample - loss: 0.5149 - accuracy: 0.8981\n",
            "Epoch 477/1000\n",
            "24/24 [==============================] - 0s 601us/sample - loss: 0.4931 - accuracy: 0.9028\n",
            "Epoch 478/1000\n",
            "24/24 [==============================] - 0s 601us/sample - loss: 0.4884 - accuracy: 0.9028\n",
            "Epoch 479/1000\n",
            "24/24 [==============================] - 0s 581us/sample - loss: 0.4978 - accuracy: 0.9028\n",
            "Epoch 480/1000\n",
            "24/24 [==============================] - 0s 500us/sample - loss: 0.4981 - accuracy: 0.9028\n",
            "Epoch 481/1000\n",
            "24/24 [==============================] - 0s 503us/sample - loss: 0.5044 - accuracy: 0.8981\n",
            "Epoch 482/1000\n",
            "24/24 [==============================] - 0s 707us/sample - loss: 0.4946 - accuracy: 0.9028\n",
            "Epoch 483/1000\n",
            "24/24 [==============================] - 0s 557us/sample - loss: 0.4837 - accuracy: 0.8981\n",
            "Epoch 484/1000\n",
            "24/24 [==============================] - 0s 612us/sample - loss: 0.4855 - accuracy: 0.9074\n",
            "Epoch 485/1000\n",
            "24/24 [==============================] - 0s 429us/sample - loss: 0.4761 - accuracy: 0.9028\n",
            "Epoch 486/1000\n",
            "24/24 [==============================] - 0s 419us/sample - loss: 0.4713 - accuracy: 0.9028\n",
            "Epoch 487/1000\n",
            "24/24 [==============================] - 0s 397us/sample - loss: 0.4697 - accuracy: 0.9074\n",
            "Epoch 488/1000\n",
            "24/24 [==============================] - 0s 646us/sample - loss: 0.4720 - accuracy: 0.9028\n",
            "Epoch 489/1000\n",
            "24/24 [==============================] - 0s 533us/sample - loss: 0.4704 - accuracy: 0.9028\n",
            "Epoch 490/1000\n",
            "24/24 [==============================] - 0s 646us/sample - loss: 0.4637 - accuracy: 0.9028\n",
            "Epoch 491/1000\n",
            "24/24 [==============================] - 0s 632us/sample - loss: 0.4677 - accuracy: 0.9074\n",
            "Epoch 492/1000\n",
            "24/24 [==============================] - 0s 551us/sample - loss: 0.4571 - accuracy: 0.9028\n",
            "Epoch 493/1000\n",
            "24/24 [==============================] - 0s 526us/sample - loss: 0.4620 - accuracy: 0.9028\n",
            "Epoch 494/1000\n",
            "24/24 [==============================] - 0s 527us/sample - loss: 0.4575 - accuracy: 0.9074\n",
            "Epoch 495/1000\n",
            "24/24 [==============================] - 0s 587us/sample - loss: 0.4532 - accuracy: 0.9028\n",
            "Epoch 496/1000\n",
            "24/24 [==============================] - 0s 572us/sample - loss: 0.4470 - accuracy: 0.9120\n",
            "Epoch 497/1000\n",
            "24/24 [==============================] - 0s 511us/sample - loss: 0.4453 - accuracy: 0.9074\n",
            "Epoch 498/1000\n",
            "24/24 [==============================] - 0s 643us/sample - loss: 0.4525 - accuracy: 0.9120\n",
            "Epoch 499/1000\n",
            "24/24 [==============================] - 0s 915us/sample - loss: 0.4326 - accuracy: 0.9120\n",
            "Epoch 500/1000\n",
            "24/24 [==============================] - 0s 613us/sample - loss: 0.4450 - accuracy: 0.9028\n",
            "Epoch 501/1000\n",
            "24/24 [==============================] - 0s 628us/sample - loss: 0.4335 - accuracy: 0.9167\n",
            "Epoch 502/1000\n",
            "24/24 [==============================] - 0s 517us/sample - loss: 0.4442 - accuracy: 0.9120\n",
            "Epoch 503/1000\n",
            "24/24 [==============================] - 0s 469us/sample - loss: 0.4376 - accuracy: 0.9213\n",
            "Epoch 504/1000\n",
            "24/24 [==============================] - 0s 539us/sample - loss: 0.4258 - accuracy: 0.9074\n",
            "Epoch 505/1000\n",
            "24/24 [==============================] - 0s 460us/sample - loss: 0.4268 - accuracy: 0.9120\n",
            "Epoch 506/1000\n",
            "24/24 [==============================] - 0s 1ms/sample - loss: 0.4213 - accuracy: 0.9120\n",
            "Epoch 507/1000\n",
            "24/24 [==============================] - 0s 632us/sample - loss: 0.4264 - accuracy: 0.9120\n",
            "Epoch 508/1000\n",
            "24/24 [==============================] - 0s 550us/sample - loss: 0.4079 - accuracy: 0.9213\n",
            "Epoch 509/1000\n",
            "24/24 [==============================] - 0s 527us/sample - loss: 0.4149 - accuracy: 0.9120\n",
            "Epoch 510/1000\n",
            "24/24 [==============================] - 0s 521us/sample - loss: 0.4204 - accuracy: 0.9167\n",
            "Epoch 511/1000\n",
            "24/24 [==============================] - 0s 539us/sample - loss: 0.4053 - accuracy: 0.9167\n",
            "Epoch 512/1000\n",
            "24/24 [==============================] - 0s 573us/sample - loss: 0.4210 - accuracy: 0.9120\n",
            "Epoch 513/1000\n",
            "24/24 [==============================] - 0s 415us/sample - loss: 0.4018 - accuracy: 0.9213\n",
            "Epoch 514/1000\n",
            "24/24 [==============================] - 0s 627us/sample - loss: 0.4106 - accuracy: 0.9167\n",
            "Epoch 515/1000\n",
            "24/24 [==============================] - 0s 442us/sample - loss: 0.3964 - accuracy: 0.9213\n",
            "Epoch 516/1000\n",
            "24/24 [==============================] - 0s 556us/sample - loss: 0.4019 - accuracy: 0.9167\n",
            "Epoch 517/1000\n",
            "24/24 [==============================] - 0s 584us/sample - loss: 0.4079 - accuracy: 0.9120\n",
            "Epoch 518/1000\n",
            "24/24 [==============================] - 0s 628us/sample - loss: 0.3949 - accuracy: 0.9120\n",
            "Epoch 519/1000\n",
            "24/24 [==============================] - 0s 537us/sample - loss: 0.3949 - accuracy: 0.9167\n",
            "Epoch 520/1000\n",
            "24/24 [==============================] - 0s 509us/sample - loss: 0.3902 - accuracy: 0.9306\n",
            "Epoch 521/1000\n",
            "24/24 [==============================] - 0s 535us/sample - loss: 0.3879 - accuracy: 0.9167\n",
            "Epoch 522/1000\n",
            "24/24 [==============================] - 0s 565us/sample - loss: 0.3890 - accuracy: 0.9120\n",
            "Epoch 523/1000\n",
            "24/24 [==============================] - 0s 674us/sample - loss: 0.3851 - accuracy: 0.9213\n",
            "Epoch 524/1000\n",
            "24/24 [==============================] - 0s 539us/sample - loss: 0.3812 - accuracy: 0.9167\n",
            "Epoch 525/1000\n",
            "24/24 [==============================] - 0s 560us/sample - loss: 0.3880 - accuracy: 0.9167\n",
            "Epoch 526/1000\n",
            "24/24 [==============================] - 0s 608us/sample - loss: 0.3798 - accuracy: 0.9259\n",
            "Epoch 527/1000\n",
            "24/24 [==============================] - 0s 520us/sample - loss: 0.3722 - accuracy: 0.9259\n",
            "Epoch 528/1000\n",
            "24/24 [==============================] - 0s 621us/sample - loss: 0.3730 - accuracy: 0.9213\n",
            "Epoch 529/1000\n",
            "24/24 [==============================] - 0s 605us/sample - loss: 0.3651 - accuracy: 0.9213\n",
            "Epoch 530/1000\n",
            "24/24 [==============================] - 0s 571us/sample - loss: 0.3682 - accuracy: 0.9167\n",
            "Epoch 531/1000\n",
            "24/24 [==============================] - 0s 910us/sample - loss: 0.3769 - accuracy: 0.9259\n",
            "Epoch 532/1000\n",
            "24/24 [==============================] - 0s 565us/sample - loss: 0.3623 - accuracy: 0.9213\n",
            "Epoch 533/1000\n",
            "24/24 [==============================] - 0s 562us/sample - loss: 0.3650 - accuracy: 0.9259\n",
            "Epoch 534/1000\n",
            "24/24 [==============================] - 0s 524us/sample - loss: 0.3659 - accuracy: 0.9213\n",
            "Epoch 535/1000\n",
            "24/24 [==============================] - 0s 498us/sample - loss: 0.3627 - accuracy: 0.9352\n",
            "Epoch 536/1000\n",
            "24/24 [==============================] - 0s 701us/sample - loss: 0.3578 - accuracy: 0.9306\n",
            "Epoch 537/1000\n",
            "24/24 [==============================] - 0s 585us/sample - loss: 0.3505 - accuracy: 0.9352\n",
            "Epoch 538/1000\n",
            "24/24 [==============================] - 0s 555us/sample - loss: 0.3561 - accuracy: 0.9306\n",
            "Epoch 539/1000\n",
            "24/24 [==============================] - 0s 537us/sample - loss: 0.3463 - accuracy: 0.9259\n",
            "Epoch 540/1000\n",
            "24/24 [==============================] - 0s 542us/sample - loss: 0.3526 - accuracy: 0.9259\n",
            "Epoch 541/1000\n",
            "24/24 [==============================] - 0s 545us/sample - loss: 0.3490 - accuracy: 0.9306\n",
            "Epoch 542/1000\n",
            "24/24 [==============================] - 0s 531us/sample - loss: 0.3458 - accuracy: 0.9306\n",
            "Epoch 543/1000\n",
            "24/24 [==============================] - 0s 594us/sample - loss: 0.3517 - accuracy: 0.9352\n",
            "Epoch 544/1000\n",
            "24/24 [==============================] - 0s 678us/sample - loss: 0.3389 - accuracy: 0.9444\n",
            "Epoch 545/1000\n",
            "24/24 [==============================] - 0s 493us/sample - loss: 0.3448 - accuracy: 0.9444\n",
            "Epoch 546/1000\n",
            "24/24 [==============================] - 0s 663us/sample - loss: 0.3424 - accuracy: 0.9306\n",
            "Epoch 547/1000\n",
            "24/24 [==============================] - 0s 390us/sample - loss: 0.3341 - accuracy: 0.9398\n",
            "Epoch 548/1000\n",
            "24/24 [==============================] - 0s 573us/sample - loss: 0.3310 - accuracy: 0.9537\n",
            "Epoch 549/1000\n",
            "24/24 [==============================] - 0s 590us/sample - loss: 0.3256 - accuracy: 0.9352\n",
            "Epoch 550/1000\n",
            "24/24 [==============================] - 0s 611us/sample - loss: 0.3329 - accuracy: 0.9444\n",
            "Epoch 551/1000\n",
            "24/24 [==============================] - 0s 449us/sample - loss: 0.3235 - accuracy: 0.9444\n",
            "Epoch 552/1000\n",
            "24/24 [==============================] - 0s 674us/sample - loss: 0.3316 - accuracy: 0.9398\n",
            "Epoch 553/1000\n",
            "24/24 [==============================] - 0s 620us/sample - loss: 0.3339 - accuracy: 0.9352\n",
            "Epoch 554/1000\n",
            "24/24 [==============================] - 0s 827us/sample - loss: 0.3249 - accuracy: 0.9444\n",
            "Epoch 555/1000\n",
            "24/24 [==============================] - 0s 600us/sample - loss: 0.3165 - accuracy: 0.9398\n",
            "Epoch 556/1000\n",
            "24/24 [==============================] - 0s 622us/sample - loss: 0.3225 - accuracy: 0.9491\n",
            "Epoch 557/1000\n",
            "24/24 [==============================] - 0s 650us/sample - loss: 0.3090 - accuracy: 0.9537\n",
            "Epoch 558/1000\n",
            "24/24 [==============================] - 0s 485us/sample - loss: 0.3120 - accuracy: 0.9537\n",
            "Epoch 559/1000\n",
            "24/24 [==============================] - 0s 565us/sample - loss: 0.3151 - accuracy: 0.9398\n",
            "Epoch 560/1000\n",
            "24/24 [==============================] - 0s 512us/sample - loss: 0.3137 - accuracy: 0.9537\n",
            "Epoch 561/1000\n",
            "24/24 [==============================] - 0s 515us/sample - loss: 0.3100 - accuracy: 0.9398\n",
            "Epoch 562/1000\n",
            "24/24 [==============================] - 0s 502us/sample - loss: 0.3068 - accuracy: 0.9491\n",
            "Epoch 563/1000\n",
            "24/24 [==============================] - 0s 530us/sample - loss: 0.3059 - accuracy: 0.9491\n",
            "Epoch 564/1000\n",
            "24/24 [==============================] - 0s 491us/sample - loss: 0.2959 - accuracy: 0.9537\n",
            "Epoch 565/1000\n",
            "24/24 [==============================] - 0s 475us/sample - loss: 0.3008 - accuracy: 0.9444\n",
            "Epoch 566/1000\n",
            "24/24 [==============================] - 0s 523us/sample - loss: 0.2992 - accuracy: 0.9537\n",
            "Epoch 567/1000\n",
            "24/24 [==============================] - 0s 505us/sample - loss: 0.2974 - accuracy: 0.9583\n",
            "Epoch 568/1000\n",
            "24/24 [==============================] - 0s 651us/sample - loss: 0.2984 - accuracy: 0.9676\n",
            "Epoch 569/1000\n",
            "24/24 [==============================] - 0s 466us/sample - loss: 0.2940 - accuracy: 0.9491\n",
            "Epoch 570/1000\n",
            "24/24 [==============================] - 0s 524us/sample - loss: 0.2906 - accuracy: 0.9630\n",
            "Epoch 571/1000\n",
            "24/24 [==============================] - 0s 467us/sample - loss: 0.2935 - accuracy: 0.9444\n",
            "Epoch 572/1000\n",
            "24/24 [==============================] - 0s 640us/sample - loss: 0.2828 - accuracy: 0.9583\n",
            "Epoch 573/1000\n",
            "24/24 [==============================] - 0s 627us/sample - loss: 0.2824 - accuracy: 0.9583\n",
            "Epoch 574/1000\n",
            "24/24 [==============================] - 0s 585us/sample - loss: 0.2837 - accuracy: 0.9537\n",
            "Epoch 575/1000\n",
            "24/24 [==============================] - 0s 586us/sample - loss: 0.2844 - accuracy: 0.9630\n",
            "Epoch 576/1000\n",
            "24/24 [==============================] - 0s 643us/sample - loss: 0.2851 - accuracy: 0.9444\n",
            "Epoch 577/1000\n",
            "24/24 [==============================] - 0s 466us/sample - loss: 0.2853 - accuracy: 0.9583\n",
            "Epoch 578/1000\n",
            "24/24 [==============================] - 0s 471us/sample - loss: 0.2748 - accuracy: 0.9630\n",
            "Epoch 579/1000\n",
            "24/24 [==============================] - 0s 534us/sample - loss: 0.2800 - accuracy: 0.9676\n",
            "Epoch 580/1000\n",
            "24/24 [==============================] - 0s 584us/sample - loss: 0.2760 - accuracy: 0.9630\n",
            "Epoch 581/1000\n",
            "24/24 [==============================] - 0s 553us/sample - loss: 0.2738 - accuracy: 0.9676\n",
            "Epoch 582/1000\n",
            "24/24 [==============================] - 0s 561us/sample - loss: 0.2706 - accuracy: 0.9676\n",
            "Epoch 583/1000\n",
            "24/24 [==============================] - 0s 640us/sample - loss: 0.2788 - accuracy: 0.9537\n",
            "Epoch 584/1000\n",
            "24/24 [==============================] - 0s 600us/sample - loss: 0.2664 - accuracy: 0.9676\n",
            "Epoch 585/1000\n",
            "24/24 [==============================] - 0s 620us/sample - loss: 0.2660 - accuracy: 0.9630\n",
            "Epoch 586/1000\n",
            "24/24 [==============================] - 0s 590us/sample - loss: 0.2640 - accuracy: 0.9722\n",
            "Epoch 587/1000\n",
            "24/24 [==============================] - 0s 658us/sample - loss: 0.2702 - accuracy: 0.9630\n",
            "Epoch 588/1000\n",
            "24/24 [==============================] - 0s 513us/sample - loss: 0.2575 - accuracy: 0.9676\n",
            "Epoch 589/1000\n",
            "24/24 [==============================] - 0s 800us/sample - loss: 0.2620 - accuracy: 0.9769\n",
            "Epoch 590/1000\n",
            "24/24 [==============================] - 0s 613us/sample - loss: 0.2630 - accuracy: 0.9630\n",
            "Epoch 591/1000\n",
            "24/24 [==============================] - 0s 579us/sample - loss: 0.2619 - accuracy: 0.9676\n",
            "Epoch 592/1000\n",
            "24/24 [==============================] - 0s 590us/sample - loss: 0.2610 - accuracy: 0.9630\n",
            "Epoch 593/1000\n",
            "24/24 [==============================] - 0s 583us/sample - loss: 0.2580 - accuracy: 0.9676\n",
            "Epoch 594/1000\n",
            "24/24 [==============================] - 0s 493us/sample - loss: 0.2548 - accuracy: 0.9722\n",
            "Epoch 595/1000\n",
            "24/24 [==============================] - 0s 429us/sample - loss: 0.2485 - accuracy: 0.9769\n",
            "Epoch 596/1000\n",
            "24/24 [==============================] - 0s 444us/sample - loss: 0.2498 - accuracy: 0.9630\n",
            "Epoch 597/1000\n",
            "24/24 [==============================] - 0s 547us/sample - loss: 0.2491 - accuracy: 0.9722\n",
            "Epoch 598/1000\n",
            "24/24 [==============================] - 0s 538us/sample - loss: 0.2452 - accuracy: 0.9722\n",
            "Epoch 599/1000\n",
            "24/24 [==============================] - 0s 649us/sample - loss: 0.2447 - accuracy: 0.9630\n",
            "Epoch 600/1000\n",
            "24/24 [==============================] - 0s 557us/sample - loss: 0.2418 - accuracy: 0.9722\n",
            "Epoch 601/1000\n",
            "24/24 [==============================] - 0s 586us/sample - loss: 0.2442 - accuracy: 0.9630\n",
            "Epoch 602/1000\n",
            "24/24 [==============================] - 0s 551us/sample - loss: 0.2376 - accuracy: 0.9722\n",
            "Epoch 603/1000\n",
            "24/24 [==============================] - 0s 548us/sample - loss: 0.2341 - accuracy: 0.9722\n",
            "Epoch 604/1000\n",
            "24/24 [==============================] - 0s 603us/sample - loss: 0.2403 - accuracy: 0.9676\n",
            "Epoch 605/1000\n",
            "24/24 [==============================] - 0s 570us/sample - loss: 0.2371 - accuracy: 0.9769\n",
            "Epoch 606/1000\n",
            "24/24 [==============================] - 0s 689us/sample - loss: 0.2423 - accuracy: 0.9722\n",
            "Epoch 607/1000\n",
            "24/24 [==============================] - 0s 602us/sample - loss: 0.2279 - accuracy: 0.9769\n",
            "Epoch 608/1000\n",
            "24/24 [==============================] - 0s 631us/sample - loss: 0.2343 - accuracy: 0.9769\n",
            "Epoch 609/1000\n",
            "24/24 [==============================] - 0s 557us/sample - loss: 0.2278 - accuracy: 0.9769\n",
            "Epoch 610/1000\n",
            "24/24 [==============================] - 0s 642us/sample - loss: 0.2289 - accuracy: 0.9722\n",
            "Epoch 611/1000\n",
            "24/24 [==============================] - 0s 840us/sample - loss: 0.2302 - accuracy: 0.9722\n",
            "Epoch 612/1000\n",
            "24/24 [==============================] - 0s 738us/sample - loss: 0.2248 - accuracy: 0.9722\n",
            "Epoch 613/1000\n",
            "24/24 [==============================] - 0s 508us/sample - loss: 0.2262 - accuracy: 0.9630\n",
            "Epoch 614/1000\n",
            "24/24 [==============================] - 0s 614us/sample - loss: 0.2269 - accuracy: 0.9769\n",
            "Epoch 615/1000\n",
            "24/24 [==============================] - 0s 520us/sample - loss: 0.2195 - accuracy: 0.9769\n",
            "Epoch 616/1000\n",
            "24/24 [==============================] - 0s 529us/sample - loss: 0.2214 - accuracy: 0.9815\n",
            "Epoch 617/1000\n",
            "24/24 [==============================] - 0s 561us/sample - loss: 0.2229 - accuracy: 0.9769\n",
            "Epoch 618/1000\n",
            "24/24 [==============================] - 0s 581us/sample - loss: 0.2226 - accuracy: 0.9722\n",
            "Epoch 619/1000\n",
            "24/24 [==============================] - 0s 562us/sample - loss: 0.2167 - accuracy: 0.9722\n",
            "Epoch 620/1000\n",
            "24/24 [==============================] - 0s 651us/sample - loss: 0.2188 - accuracy: 0.9722\n",
            "Epoch 621/1000\n",
            "24/24 [==============================] - 0s 628us/sample - loss: 0.2162 - accuracy: 0.9722\n",
            "Epoch 622/1000\n",
            "24/24 [==============================] - 0s 628us/sample - loss: 0.2137 - accuracy: 0.9815\n",
            "Epoch 623/1000\n",
            "24/24 [==============================] - 0s 502us/sample - loss: 0.2100 - accuracy: 0.9815\n",
            "Epoch 624/1000\n",
            "24/24 [==============================] - 0s 708us/sample - loss: 0.2121 - accuracy: 0.9815\n",
            "Epoch 625/1000\n",
            "24/24 [==============================] - 0s 616us/sample - loss: 0.2102 - accuracy: 0.9722\n",
            "Epoch 626/1000\n",
            "24/24 [==============================] - 0s 571us/sample - loss: 0.2106 - accuracy: 0.9769\n",
            "Epoch 627/1000\n",
            "24/24 [==============================] - 0s 501us/sample - loss: 0.2092 - accuracy: 0.9769\n",
            "Epoch 628/1000\n",
            "24/24 [==============================] - 0s 764us/sample - loss: 0.2053 - accuracy: 0.9815\n",
            "Epoch 629/1000\n",
            "24/24 [==============================] - 0s 633us/sample - loss: 0.2074 - accuracy: 0.9769\n",
            "Epoch 630/1000\n",
            "24/24 [==============================] - 0s 528us/sample - loss: 0.2014 - accuracy: 0.9815\n",
            "Epoch 631/1000\n",
            "24/24 [==============================] - 0s 511us/sample - loss: 0.2005 - accuracy: 0.9769\n",
            "Epoch 632/1000\n",
            "24/24 [==============================] - 0s 617us/sample - loss: 0.1975 - accuracy: 0.9769\n",
            "Epoch 633/1000\n",
            "24/24 [==============================] - 0s 744us/sample - loss: 0.2021 - accuracy: 0.9722\n",
            "Epoch 634/1000\n",
            "24/24 [==============================] - 0s 497us/sample - loss: 0.1955 - accuracy: 0.9815\n",
            "Epoch 635/1000\n",
            "24/24 [==============================] - 0s 424us/sample - loss: 0.1927 - accuracy: 0.9815\n",
            "Epoch 636/1000\n",
            "24/24 [==============================] - 0s 663us/sample - loss: 0.1954 - accuracy: 0.9815\n",
            "Epoch 637/1000\n",
            "24/24 [==============================] - 0s 783us/sample - loss: 0.1948 - accuracy: 0.9815\n",
            "Epoch 638/1000\n",
            "24/24 [==============================] - 0s 580us/sample - loss: 0.1844 - accuracy: 0.9815\n",
            "Epoch 639/1000\n",
            "24/24 [==============================] - 0s 472us/sample - loss: 0.1962 - accuracy: 0.9815\n",
            "Epoch 640/1000\n",
            "24/24 [==============================] - 0s 759us/sample - loss: 0.1898 - accuracy: 0.9815\n",
            "Epoch 641/1000\n",
            "24/24 [==============================] - 0s 755us/sample - loss: 0.1834 - accuracy: 0.9815\n",
            "Epoch 642/1000\n",
            "24/24 [==============================] - 0s 477us/sample - loss: 0.1879 - accuracy: 0.9769\n",
            "Epoch 643/1000\n",
            "24/24 [==============================] - 0s 637us/sample - loss: 0.1851 - accuracy: 0.9815\n",
            "Epoch 644/1000\n",
            "24/24 [==============================] - 0s 478us/sample - loss: 0.1880 - accuracy: 0.9815\n",
            "Epoch 645/1000\n",
            "24/24 [==============================] - 0s 574us/sample - loss: 0.1782 - accuracy: 0.9861\n",
            "Epoch 646/1000\n",
            "24/24 [==============================] - 0s 599us/sample - loss: 0.1831 - accuracy: 0.9815\n",
            "Epoch 647/1000\n",
            "24/24 [==============================] - 0s 427us/sample - loss: 0.1795 - accuracy: 0.9861\n",
            "Epoch 648/1000\n",
            "24/24 [==============================] - 0s 457us/sample - loss: 0.1804 - accuracy: 0.9769\n",
            "Epoch 649/1000\n",
            "24/24 [==============================] - 0s 628us/sample - loss: 0.1749 - accuracy: 0.9861\n",
            "Epoch 650/1000\n",
            "24/24 [==============================] - 0s 492us/sample - loss: 0.1714 - accuracy: 0.9815\n",
            "Epoch 651/1000\n",
            "24/24 [==============================] - 0s 525us/sample - loss: 0.1709 - accuracy: 0.9861\n",
            "Epoch 652/1000\n",
            "24/24 [==============================] - 0s 554us/sample - loss: 0.1716 - accuracy: 0.9861\n",
            "Epoch 653/1000\n",
            "24/24 [==============================] - 0s 473us/sample - loss: 0.1697 - accuracy: 0.9861\n",
            "Epoch 654/1000\n",
            "24/24 [==============================] - 0s 578us/sample - loss: 0.1709 - accuracy: 0.9815\n",
            "Epoch 655/1000\n",
            "24/24 [==============================] - 0s 640us/sample - loss: 0.1663 - accuracy: 0.9861\n",
            "Epoch 656/1000\n",
            "24/24 [==============================] - 0s 568us/sample - loss: 0.1723 - accuracy: 0.9815\n",
            "Epoch 657/1000\n",
            "24/24 [==============================] - 0s 604us/sample - loss: 0.1647 - accuracy: 0.9861\n",
            "Epoch 658/1000\n",
            "24/24 [==============================] - 0s 430us/sample - loss: 0.1647 - accuracy: 0.9907\n",
            "Epoch 659/1000\n",
            "24/24 [==============================] - 0s 586us/sample - loss: 0.1685 - accuracy: 0.9861\n",
            "Epoch 660/1000\n",
            "24/24 [==============================] - 0s 587us/sample - loss: 0.1595 - accuracy: 0.9815\n",
            "Epoch 661/1000\n",
            "24/24 [==============================] - 0s 609us/sample - loss: 0.1632 - accuracy: 0.9861\n",
            "Epoch 662/1000\n",
            "24/24 [==============================] - 0s 515us/sample - loss: 0.1552 - accuracy: 0.9815\n",
            "Epoch 663/1000\n",
            "24/24 [==============================] - 0s 579us/sample - loss: 0.1669 - accuracy: 0.9815\n",
            "Epoch 664/1000\n",
            "24/24 [==============================] - 0s 650us/sample - loss: 0.1649 - accuracy: 0.9815\n",
            "Epoch 665/1000\n",
            "24/24 [==============================] - 0s 637us/sample - loss: 0.1576 - accuracy: 0.9861\n",
            "Epoch 666/1000\n",
            "24/24 [==============================] - 0s 789us/sample - loss: 0.1641 - accuracy: 0.9815\n",
            "Epoch 667/1000\n",
            "24/24 [==============================] - 0s 659us/sample - loss: 0.1565 - accuracy: 0.9861\n",
            "Epoch 668/1000\n",
            "24/24 [==============================] - 0s 712us/sample - loss: 0.1521 - accuracy: 0.9815\n",
            "Epoch 669/1000\n",
            "24/24 [==============================] - 0s 729us/sample - loss: 0.1498 - accuracy: 0.9861\n",
            "Epoch 670/1000\n",
            "24/24 [==============================] - 0s 564us/sample - loss: 0.1484 - accuracy: 0.9907\n",
            "Epoch 671/1000\n",
            "24/24 [==============================] - 0s 580us/sample - loss: 0.1495 - accuracy: 0.9815\n",
            "Epoch 672/1000\n",
            "24/24 [==============================] - 0s 560us/sample - loss: 0.1497 - accuracy: 0.9815\n",
            "Epoch 673/1000\n",
            "24/24 [==============================] - 0s 538us/sample - loss: 0.1456 - accuracy: 0.9815\n",
            "Epoch 674/1000\n",
            "24/24 [==============================] - 0s 609us/sample - loss: 0.1469 - accuracy: 0.9861\n",
            "Epoch 675/1000\n",
            "24/24 [==============================] - 0s 557us/sample - loss: 0.1433 - accuracy: 0.9861\n",
            "Epoch 676/1000\n",
            "24/24 [==============================] - 0s 547us/sample - loss: 0.1440 - accuracy: 0.9861\n",
            "Epoch 677/1000\n",
            "24/24 [==============================] - 0s 489us/sample - loss: 0.1481 - accuracy: 0.9861\n",
            "Epoch 678/1000\n",
            "24/24 [==============================] - 0s 684us/sample - loss: 0.1374 - accuracy: 0.9861\n",
            "Epoch 679/1000\n",
            "24/24 [==============================] - 0s 636us/sample - loss: 0.1409 - accuracy: 0.9861\n",
            "Epoch 680/1000\n",
            "24/24 [==============================] - 0s 608us/sample - loss: 0.1401 - accuracy: 0.9815\n",
            "Epoch 681/1000\n",
            "24/24 [==============================] - 0s 556us/sample - loss: 0.1371 - accuracy: 0.9861\n",
            "Epoch 682/1000\n",
            "24/24 [==============================] - 0s 453us/sample - loss: 0.1440 - accuracy: 0.9815\n",
            "Epoch 683/1000\n",
            "24/24 [==============================] - 0s 607us/sample - loss: 0.1365 - accuracy: 0.9861\n",
            "Epoch 684/1000\n",
            "24/24 [==============================] - 0s 577us/sample - loss: 0.1386 - accuracy: 0.9861\n",
            "Epoch 685/1000\n",
            "24/24 [==============================] - 0s 490us/sample - loss: 0.1366 - accuracy: 0.9815\n",
            "Epoch 686/1000\n",
            "24/24 [==============================] - 0s 466us/sample - loss: 0.1343 - accuracy: 0.9861\n",
            "Epoch 687/1000\n",
            "24/24 [==============================] - 0s 697us/sample - loss: 0.1311 - accuracy: 0.9861\n",
            "Epoch 688/1000\n",
            "24/24 [==============================] - 0s 624us/sample - loss: 0.1371 - accuracy: 0.9861\n",
            "Epoch 689/1000\n",
            "24/24 [==============================] - 0s 528us/sample - loss: 0.1340 - accuracy: 0.9815\n",
            "Epoch 690/1000\n",
            "24/24 [==============================] - 0s 733us/sample - loss: 0.1351 - accuracy: 0.9815\n",
            "Epoch 691/1000\n",
            "24/24 [==============================] - 0s 465us/sample - loss: 0.1318 - accuracy: 0.9769\n",
            "Epoch 692/1000\n",
            "24/24 [==============================] - 0s 530us/sample - loss: 0.1261 - accuracy: 0.9861\n",
            "Epoch 693/1000\n",
            "24/24 [==============================] - 0s 580us/sample - loss: 0.1243 - accuracy: 0.9861\n",
            "Epoch 694/1000\n",
            "24/24 [==============================] - 0s 617us/sample - loss: 0.1276 - accuracy: 0.9861\n",
            "Epoch 695/1000\n",
            "24/24 [==============================] - 0s 743us/sample - loss: 0.1235 - accuracy: 0.9815\n",
            "Epoch 696/1000\n",
            "24/24 [==============================] - 0s 640us/sample - loss: 0.1257 - accuracy: 0.9861\n",
            "Epoch 697/1000\n",
            "24/24 [==============================] - 0s 444us/sample - loss: 0.1233 - accuracy: 0.9861\n",
            "Epoch 698/1000\n",
            "24/24 [==============================] - 0s 473us/sample - loss: 0.1248 - accuracy: 0.9907\n",
            "Epoch 699/1000\n",
            "24/24 [==============================] - 0s 466us/sample - loss: 0.1205 - accuracy: 0.9907\n",
            "Epoch 700/1000\n",
            "24/24 [==============================] - 0s 602us/sample - loss: 0.1248 - accuracy: 0.9861\n",
            "Epoch 701/1000\n",
            "24/24 [==============================] - 0s 646us/sample - loss: 0.1237 - accuracy: 0.9861\n",
            "Epoch 702/1000\n",
            "24/24 [==============================] - 0s 777us/sample - loss: 0.1196 - accuracy: 0.9861\n",
            "Epoch 703/1000\n",
            "24/24 [==============================] - 0s 603us/sample - loss: 0.1196 - accuracy: 0.9861\n",
            "Epoch 704/1000\n",
            "24/24 [==============================] - 0s 649us/sample - loss: 0.1188 - accuracy: 0.9907\n",
            "Epoch 705/1000\n",
            "24/24 [==============================] - 0s 627us/sample - loss: 0.1240 - accuracy: 0.9861\n",
            "Epoch 706/1000\n",
            "24/24 [==============================] - 0s 618us/sample - loss: 0.1139 - accuracy: 0.9907\n",
            "Epoch 707/1000\n",
            "24/24 [==============================] - 0s 628us/sample - loss: 0.1151 - accuracy: 0.9861\n",
            "Epoch 708/1000\n",
            "24/24 [==============================] - 0s 531us/sample - loss: 0.1195 - accuracy: 0.9861\n",
            "Epoch 709/1000\n",
            "24/24 [==============================] - 0s 524us/sample - loss: 0.1177 - accuracy: 0.9861\n",
            "Epoch 710/1000\n",
            "24/24 [==============================] - 0s 504us/sample - loss: 0.1123 - accuracy: 0.9861\n",
            "Epoch 711/1000\n",
            "24/24 [==============================] - 0s 559us/sample - loss: 0.1125 - accuracy: 0.9815\n",
            "Epoch 712/1000\n",
            "24/24 [==============================] - 0s 527us/sample - loss: 0.1105 - accuracy: 0.9861\n",
            "Epoch 713/1000\n",
            "24/24 [==============================] - 0s 422us/sample - loss: 0.1057 - accuracy: 0.9861\n",
            "Epoch 714/1000\n",
            "24/24 [==============================] - 0s 472us/sample - loss: 0.1096 - accuracy: 0.9861\n",
            "Epoch 715/1000\n",
            "24/24 [==============================] - 0s 424us/sample - loss: 0.1092 - accuracy: 0.9861\n",
            "Epoch 716/1000\n",
            "24/24 [==============================] - 0s 505us/sample - loss: 0.1070 - accuracy: 0.9815\n",
            "Epoch 717/1000\n",
            "24/24 [==============================] - 0s 686us/sample - loss: 0.1066 - accuracy: 0.9861\n",
            "Epoch 718/1000\n",
            "24/24 [==============================] - 0s 594us/sample - loss: 0.1040 - accuracy: 0.9861\n",
            "Epoch 719/1000\n",
            "24/24 [==============================] - 0s 535us/sample - loss: 0.1067 - accuracy: 0.9861\n",
            "Epoch 720/1000\n",
            "24/24 [==============================] - 0s 530us/sample - loss: 0.1047 - accuracy: 0.9861\n",
            "Epoch 721/1000\n",
            "24/24 [==============================] - 0s 608us/sample - loss: 0.1052 - accuracy: 0.9907\n",
            "Epoch 722/1000\n",
            "24/24 [==============================] - 0s 610us/sample - loss: 0.1060 - accuracy: 0.9815\n",
            "Epoch 723/1000\n",
            "24/24 [==============================] - 0s 695us/sample - loss: 0.0980 - accuracy: 0.9861\n",
            "Epoch 724/1000\n",
            "24/24 [==============================] - 0s 893us/sample - loss: 0.1056 - accuracy: 0.9861\n",
            "Epoch 725/1000\n",
            "24/24 [==============================] - 0s 768us/sample - loss: 0.1006 - accuracy: 0.9861\n",
            "Epoch 726/1000\n",
            "24/24 [==============================] - 0s 624us/sample - loss: 0.0995 - accuracy: 0.9815\n",
            "Epoch 727/1000\n",
            "24/24 [==============================] - 0s 505us/sample - loss: 0.1030 - accuracy: 0.9861\n",
            "Epoch 728/1000\n",
            "24/24 [==============================] - 0s 605us/sample - loss: 0.1025 - accuracy: 0.9861\n",
            "Epoch 729/1000\n",
            "24/24 [==============================] - 0s 621us/sample - loss: 0.0980 - accuracy: 0.9861\n",
            "Epoch 730/1000\n",
            "24/24 [==============================] - 0s 595us/sample - loss: 0.0959 - accuracy: 0.9815\n",
            "Epoch 731/1000\n",
            "24/24 [==============================] - 0s 590us/sample - loss: 0.0996 - accuracy: 0.9861\n",
            "Epoch 732/1000\n",
            "24/24 [==============================] - 0s 600us/sample - loss: 0.0966 - accuracy: 0.9815\n",
            "Epoch 733/1000\n",
            "24/24 [==============================] - 0s 610us/sample - loss: 0.0969 - accuracy: 0.9861\n",
            "Epoch 734/1000\n",
            "24/24 [==============================] - 0s 585us/sample - loss: 0.0975 - accuracy: 0.9861\n",
            "Epoch 735/1000\n",
            "24/24 [==============================] - 0s 648us/sample - loss: 0.0939 - accuracy: 0.9861\n",
            "Epoch 736/1000\n",
            "24/24 [==============================] - 0s 438us/sample - loss: 0.0945 - accuracy: 0.9815\n",
            "Epoch 737/1000\n",
            "24/24 [==============================] - 0s 570us/sample - loss: 0.0907 - accuracy: 0.9861\n",
            "Epoch 738/1000\n",
            "24/24 [==============================] - 0s 723us/sample - loss: 0.0895 - accuracy: 0.9861\n",
            "Epoch 739/1000\n",
            "24/24 [==============================] - 0s 502us/sample - loss: 0.0894 - accuracy: 0.9907\n",
            "Epoch 740/1000\n",
            "24/24 [==============================] - 0s 477us/sample - loss: 0.0917 - accuracy: 0.9815\n",
            "Epoch 741/1000\n",
            "24/24 [==============================] - 0s 404us/sample - loss: 0.0908 - accuracy: 0.9861\n",
            "Epoch 742/1000\n",
            "24/24 [==============================] - 0s 772us/sample - loss: 0.0900 - accuracy: 0.9815\n",
            "Epoch 743/1000\n",
            "24/24 [==============================] - 0s 546us/sample - loss: 0.0868 - accuracy: 0.9861\n",
            "Epoch 744/1000\n",
            "24/24 [==============================] - 0s 429us/sample - loss: 0.0863 - accuracy: 0.9861\n",
            "Epoch 745/1000\n",
            "24/24 [==============================] - 0s 580us/sample - loss: 0.0861 - accuracy: 0.9815\n",
            "Epoch 746/1000\n",
            "24/24 [==============================] - 0s 476us/sample - loss: 0.0919 - accuracy: 0.9907\n",
            "Epoch 747/1000\n",
            "24/24 [==============================] - 0s 539us/sample - loss: 0.0880 - accuracy: 0.9815\n",
            "Epoch 748/1000\n",
            "24/24 [==============================] - 0s 512us/sample - loss: 0.0883 - accuracy: 0.9861\n",
            "Epoch 749/1000\n",
            "24/24 [==============================] - 0s 580us/sample - loss: 0.0866 - accuracy: 0.9861\n",
            "Epoch 750/1000\n",
            "24/24 [==============================] - 0s 609us/sample - loss: 0.0890 - accuracy: 0.9861\n",
            "Epoch 751/1000\n",
            "24/24 [==============================] - 0s 658us/sample - loss: 0.0835 - accuracy: 0.9861\n",
            "Epoch 752/1000\n",
            "24/24 [==============================] - 0s 529us/sample - loss: 0.0790 - accuracy: 0.9861\n",
            "Epoch 753/1000\n",
            "24/24 [==============================] - 0s 551us/sample - loss: 0.0859 - accuracy: 0.9861\n",
            "Epoch 754/1000\n",
            "24/24 [==============================] - 0s 489us/sample - loss: 0.0809 - accuracy: 0.9861\n",
            "Epoch 755/1000\n",
            "24/24 [==============================] - 0s 512us/sample - loss: 0.0864 - accuracy: 0.9815\n",
            "Epoch 756/1000\n",
            "24/24 [==============================] - 0s 677us/sample - loss: 0.0794 - accuracy: 0.9907\n",
            "Epoch 757/1000\n",
            "24/24 [==============================] - 0s 463us/sample - loss: 0.0818 - accuracy: 0.9815\n",
            "Epoch 758/1000\n",
            "24/24 [==============================] - 0s 560us/sample - loss: 0.0806 - accuracy: 0.9815\n",
            "Epoch 759/1000\n",
            "24/24 [==============================] - 0s 452us/sample - loss: 0.0769 - accuracy: 0.9907\n",
            "Epoch 760/1000\n",
            "24/24 [==============================] - 0s 459us/sample - loss: 0.0810 - accuracy: 0.9861\n",
            "Epoch 761/1000\n",
            "24/24 [==============================] - 0s 589us/sample - loss: 0.0829 - accuracy: 0.9861\n",
            "Epoch 762/1000\n",
            "24/24 [==============================] - 0s 670us/sample - loss: 0.0789 - accuracy: 0.9861\n",
            "Epoch 763/1000\n",
            "24/24 [==============================] - 0s 465us/sample - loss: 0.0789 - accuracy: 0.9861\n",
            "Epoch 764/1000\n",
            "24/24 [==============================] - 0s 696us/sample - loss: 0.0803 - accuracy: 0.9815\n",
            "Epoch 765/1000\n",
            "24/24 [==============================] - 0s 609us/sample - loss: 0.0744 - accuracy: 0.9815\n",
            "Epoch 766/1000\n",
            "24/24 [==============================] - 0s 636us/sample - loss: 0.0740 - accuracy: 0.9861\n",
            "Epoch 767/1000\n",
            "24/24 [==============================] - 0s 548us/sample - loss: 0.0759 - accuracy: 0.9861\n",
            "Epoch 768/1000\n",
            "24/24 [==============================] - 0s 687us/sample - loss: 0.0773 - accuracy: 0.9861\n",
            "Epoch 769/1000\n",
            "24/24 [==============================] - 0s 714us/sample - loss: 0.0811 - accuracy: 0.9861\n",
            "Epoch 770/1000\n",
            "24/24 [==============================] - 0s 610us/sample - loss: 0.0741 - accuracy: 0.9907\n",
            "Epoch 771/1000\n",
            "24/24 [==============================] - 0s 408us/sample - loss: 0.0730 - accuracy: 0.9907\n",
            "Epoch 772/1000\n",
            "24/24 [==============================] - 0s 536us/sample - loss: 0.0740 - accuracy: 0.9907\n",
            "Epoch 773/1000\n",
            "24/24 [==============================] - 0s 561us/sample - loss: 0.0738 - accuracy: 0.9815\n",
            "Epoch 774/1000\n",
            "24/24 [==============================] - 0s 561us/sample - loss: 0.0781 - accuracy: 0.9861\n",
            "Epoch 775/1000\n",
            "24/24 [==============================] - 0s 597us/sample - loss: 0.0752 - accuracy: 0.9815\n",
            "Epoch 776/1000\n",
            "24/24 [==============================] - 0s 478us/sample - loss: 0.0756 - accuracy: 0.9861\n",
            "Epoch 777/1000\n",
            "24/24 [==============================] - 0s 540us/sample - loss: 0.0729 - accuracy: 0.9815\n",
            "Epoch 778/1000\n",
            "24/24 [==============================] - 0s 657us/sample - loss: 0.0719 - accuracy: 0.9815\n",
            "Epoch 779/1000\n",
            "24/24 [==============================] - 0s 673us/sample - loss: 0.0732 - accuracy: 0.9861\n",
            "Epoch 780/1000\n",
            "24/24 [==============================] - 0s 522us/sample - loss: 0.0701 - accuracy: 0.9815\n",
            "Epoch 781/1000\n",
            "24/24 [==============================] - 0s 1ms/sample - loss: 0.0724 - accuracy: 0.9907\n",
            "Epoch 782/1000\n",
            "24/24 [==============================] - 0s 816us/sample - loss: 0.0697 - accuracy: 0.9861\n",
            "Epoch 783/1000\n",
            "24/24 [==============================] - 0s 692us/sample - loss: 0.0703 - accuracy: 0.9861\n",
            "Epoch 784/1000\n",
            "24/24 [==============================] - 0s 805us/sample - loss: 0.0721 - accuracy: 0.9907\n",
            "Epoch 785/1000\n",
            "24/24 [==============================] - 0s 503us/sample - loss: 0.0718 - accuracy: 0.9815\n",
            "Epoch 786/1000\n",
            "24/24 [==============================] - 0s 619us/sample - loss: 0.0723 - accuracy: 0.9815\n",
            "Epoch 787/1000\n",
            "24/24 [==============================] - 0s 501us/sample - loss: 0.0690 - accuracy: 0.9861\n",
            "Epoch 788/1000\n",
            "24/24 [==============================] - 0s 728us/sample - loss: 0.0699 - accuracy: 0.9861\n",
            "Epoch 789/1000\n",
            "24/24 [==============================] - 0s 601us/sample - loss: 0.0674 - accuracy: 0.9861\n",
            "Epoch 790/1000\n",
            "24/24 [==============================] - 0s 655us/sample - loss: 0.0671 - accuracy: 0.9861\n",
            "Epoch 791/1000\n",
            "24/24 [==============================] - 0s 472us/sample - loss: 0.0707 - accuracy: 0.9861\n",
            "Epoch 792/1000\n",
            "24/24 [==============================] - 0s 641us/sample - loss: 0.0668 - accuracy: 0.9861\n",
            "Epoch 793/1000\n",
            "24/24 [==============================] - 0s 493us/sample - loss: 0.0678 - accuracy: 0.9861\n",
            "Epoch 794/1000\n",
            "24/24 [==============================] - 0s 554us/sample - loss: 0.0696 - accuracy: 0.9815\n",
            "Epoch 795/1000\n",
            "24/24 [==============================] - 0s 542us/sample - loss: 0.0666 - accuracy: 0.9861\n",
            "Epoch 796/1000\n",
            "24/24 [==============================] - 0s 564us/sample - loss: 0.0658 - accuracy: 0.9861\n",
            "Epoch 797/1000\n",
            "24/24 [==============================] - 0s 531us/sample - loss: 0.0636 - accuracy: 0.9907\n",
            "Epoch 798/1000\n",
            "24/24 [==============================] - 0s 564us/sample - loss: 0.0644 - accuracy: 0.9861\n",
            "Epoch 799/1000\n",
            "24/24 [==============================] - 0s 547us/sample - loss: 0.0663 - accuracy: 0.9861\n",
            "Epoch 800/1000\n",
            "24/24 [==============================] - 0s 614us/sample - loss: 0.0635 - accuracy: 0.9861\n",
            "Epoch 801/1000\n",
            "24/24 [==============================] - 0s 581us/sample - loss: 0.0638 - accuracy: 0.9815\n",
            "Epoch 802/1000\n",
            "24/24 [==============================] - 0s 502us/sample - loss: 0.0681 - accuracy: 0.9861\n",
            "Epoch 803/1000\n",
            "24/24 [==============================] - 0s 456us/sample - loss: 0.0621 - accuracy: 0.9907\n",
            "Epoch 804/1000\n",
            "24/24 [==============================] - 0s 593us/sample - loss: 0.0600 - accuracy: 0.9815\n",
            "Epoch 805/1000\n",
            "24/24 [==============================] - 0s 431us/sample - loss: 0.0633 - accuracy: 0.9815\n",
            "Epoch 806/1000\n",
            "24/24 [==============================] - 0s 638us/sample - loss: 0.0612 - accuracy: 0.9907\n",
            "Epoch 807/1000\n",
            "24/24 [==============================] - 0s 457us/sample - loss: 0.0615 - accuracy: 0.9815\n",
            "Epoch 808/1000\n",
            "24/24 [==============================] - 0s 481us/sample - loss: 0.0630 - accuracy: 0.9861\n",
            "Epoch 809/1000\n",
            "24/24 [==============================] - 0s 440us/sample - loss: 0.0604 - accuracy: 0.9907\n",
            "Epoch 810/1000\n",
            "24/24 [==============================] - 0s 529us/sample - loss: 0.0623 - accuracy: 0.9907\n",
            "Epoch 811/1000\n",
            "24/24 [==============================] - 0s 410us/sample - loss: 0.0631 - accuracy: 0.9861\n",
            "Epoch 812/1000\n",
            "24/24 [==============================] - 0s 458us/sample - loss: 0.0596 - accuracy: 0.9861\n",
            "Epoch 813/1000\n",
            "24/24 [==============================] - 0s 593us/sample - loss: 0.0618 - accuracy: 0.9861\n",
            "Epoch 814/1000\n",
            "24/24 [==============================] - 0s 559us/sample - loss: 0.0595 - accuracy: 0.9954\n",
            "Epoch 815/1000\n",
            "24/24 [==============================] - 0s 569us/sample - loss: 0.0603 - accuracy: 0.9861\n",
            "Epoch 816/1000\n",
            "24/24 [==============================] - 0s 553us/sample - loss: 0.0603 - accuracy: 0.9861\n",
            "Epoch 817/1000\n",
            "24/24 [==============================] - 0s 616us/sample - loss: 0.0623 - accuracy: 0.9861\n",
            "Epoch 818/1000\n",
            "24/24 [==============================] - 0s 556us/sample - loss: 0.0613 - accuracy: 0.9815\n",
            "Epoch 819/1000\n",
            "24/24 [==============================] - 0s 635us/sample - loss: 0.0607 - accuracy: 0.9815\n",
            "Epoch 820/1000\n",
            "24/24 [==============================] - 0s 523us/sample - loss: 0.0584 - accuracy: 0.9861\n",
            "Epoch 821/1000\n",
            "24/24 [==============================] - 0s 609us/sample - loss: 0.0572 - accuracy: 0.9907\n",
            "Epoch 822/1000\n",
            "24/24 [==============================] - 0s 540us/sample - loss: 0.0580 - accuracy: 0.9815\n",
            "Epoch 823/1000\n",
            "24/24 [==============================] - 0s 478us/sample - loss: 0.0556 - accuracy: 0.9861\n",
            "Epoch 824/1000\n",
            "24/24 [==============================] - 0s 505us/sample - loss: 0.0600 - accuracy: 0.9907\n",
            "Epoch 825/1000\n",
            "24/24 [==============================] - 0s 417us/sample - loss: 0.0610 - accuracy: 0.9907\n",
            "Epoch 826/1000\n",
            "24/24 [==============================] - 0s 552us/sample - loss: 0.0564 - accuracy: 0.9815\n",
            "Epoch 827/1000\n",
            "24/24 [==============================] - 0s 489us/sample - loss: 0.0594 - accuracy: 0.9815\n",
            "Epoch 828/1000\n",
            "24/24 [==============================] - 0s 522us/sample - loss: 0.0606 - accuracy: 0.9815\n",
            "Epoch 829/1000\n",
            "24/24 [==============================] - 0s 644us/sample - loss: 0.0616 - accuracy: 0.9861\n",
            "Epoch 830/1000\n",
            "24/24 [==============================] - 0s 498us/sample - loss: 0.0596 - accuracy: 0.9815\n",
            "Epoch 831/1000\n",
            "24/24 [==============================] - 0s 528us/sample - loss: 0.0563 - accuracy: 0.9861\n",
            "Epoch 832/1000\n",
            "24/24 [==============================] - 0s 507us/sample - loss: 0.0568 - accuracy: 0.9815\n",
            "Epoch 833/1000\n",
            "24/24 [==============================] - 0s 552us/sample - loss: 0.0594 - accuracy: 0.9861\n",
            "Epoch 834/1000\n",
            "24/24 [==============================] - 0s 669us/sample - loss: 0.0545 - accuracy: 0.9861\n",
            "Epoch 835/1000\n",
            "24/24 [==============================] - 0s 622us/sample - loss: 0.0532 - accuracy: 0.9907\n",
            "Epoch 836/1000\n",
            "24/24 [==============================] - 0s 640us/sample - loss: 0.0570 - accuracy: 0.9861\n",
            "Epoch 837/1000\n",
            "24/24 [==============================] - 0s 742us/sample - loss: 0.0561 - accuracy: 0.9907\n",
            "Epoch 838/1000\n",
            "24/24 [==============================] - 0s 514us/sample - loss: 0.0586 - accuracy: 0.9907\n",
            "Epoch 839/1000\n",
            "24/24 [==============================] - 0s 769us/sample - loss: 0.0548 - accuracy: 0.9861\n",
            "Epoch 840/1000\n",
            "24/24 [==============================] - 0s 483us/sample - loss: 0.0539 - accuracy: 0.9815\n",
            "Epoch 841/1000\n",
            "24/24 [==============================] - 0s 539us/sample - loss: 0.0559 - accuracy: 0.9815\n",
            "Epoch 842/1000\n",
            "24/24 [==============================] - 0s 518us/sample - loss: 0.0535 - accuracy: 0.9907\n",
            "Epoch 843/1000\n",
            "24/24 [==============================] - 0s 531us/sample - loss: 0.0541 - accuracy: 0.9861\n",
            "Epoch 844/1000\n",
            "24/24 [==============================] - 0s 614us/sample - loss: 0.0514 - accuracy: 0.9907\n",
            "Epoch 845/1000\n",
            "24/24 [==============================] - 0s 596us/sample - loss: 0.0514 - accuracy: 0.9954\n",
            "Epoch 846/1000\n",
            "24/24 [==============================] - 0s 542us/sample - loss: 0.0509 - accuracy: 0.9907\n",
            "Epoch 847/1000\n",
            "24/24 [==============================] - 0s 521us/sample - loss: 0.0547 - accuracy: 0.9861\n",
            "Epoch 848/1000\n",
            "24/24 [==============================] - 0s 630us/sample - loss: 0.0510 - accuracy: 0.9907\n",
            "Epoch 849/1000\n",
            "24/24 [==============================] - 0s 565us/sample - loss: 0.0542 - accuracy: 0.9907\n",
            "Epoch 850/1000\n",
            "24/24 [==============================] - 0s 702us/sample - loss: 0.0509 - accuracy: 0.9861\n",
            "Epoch 851/1000\n",
            "24/24 [==============================] - 0s 655us/sample - loss: 0.0554 - accuracy: 0.9861\n",
            "Epoch 852/1000\n",
            "24/24 [==============================] - 0s 603us/sample - loss: 0.0515 - accuracy: 0.9861\n",
            "Epoch 853/1000\n",
            "24/24 [==============================] - 0s 464us/sample - loss: 0.0528 - accuracy: 0.9815\n",
            "Epoch 854/1000\n",
            "24/24 [==============================] - 0s 754us/sample - loss: 0.0531 - accuracy: 0.9815\n",
            "Epoch 855/1000\n",
            "24/24 [==============================] - 0s 563us/sample - loss: 0.0541 - accuracy: 0.9815\n",
            "Epoch 856/1000\n",
            "24/24 [==============================] - 0s 416us/sample - loss: 0.0528 - accuracy: 0.9861\n",
            "Epoch 857/1000\n",
            "24/24 [==============================] - 0s 460us/sample - loss: 0.0514 - accuracy: 0.9861\n",
            "Epoch 858/1000\n",
            "24/24 [==============================] - 0s 519us/sample - loss: 0.0514 - accuracy: 0.9815\n",
            "Epoch 859/1000\n",
            "24/24 [==============================] - 0s 535us/sample - loss: 0.0530 - accuracy: 0.9815\n",
            "Epoch 860/1000\n",
            "24/24 [==============================] - 0s 612us/sample - loss: 0.0517 - accuracy: 0.9861\n",
            "Epoch 861/1000\n",
            "24/24 [==============================] - 0s 678us/sample - loss: 0.0532 - accuracy: 0.9815\n",
            "Epoch 862/1000\n",
            "24/24 [==============================] - 0s 594us/sample - loss: 0.0512 - accuracy: 0.9907\n",
            "Epoch 863/1000\n",
            "24/24 [==============================] - 0s 550us/sample - loss: 0.0518 - accuracy: 0.9861\n",
            "Epoch 864/1000\n",
            "24/24 [==============================] - 0s 754us/sample - loss: 0.0514 - accuracy: 0.9861\n",
            "Epoch 865/1000\n",
            "24/24 [==============================] - 0s 567us/sample - loss: 0.0509 - accuracy: 0.9907\n",
            "Epoch 866/1000\n",
            "24/24 [==============================] - 0s 599us/sample - loss: 0.0487 - accuracy: 0.9954\n",
            "Epoch 867/1000\n",
            "24/24 [==============================] - 0s 494us/sample - loss: 0.0513 - accuracy: 0.9861\n",
            "Epoch 868/1000\n",
            "24/24 [==============================] - 0s 552us/sample - loss: 0.0504 - accuracy: 0.9861\n",
            "Epoch 869/1000\n",
            "24/24 [==============================] - 0s 588us/sample - loss: 0.0516 - accuracy: 0.9861\n",
            "Epoch 870/1000\n",
            "24/24 [==============================] - 0s 502us/sample - loss: 0.0492 - accuracy: 0.9861\n",
            "Epoch 871/1000\n",
            "24/24 [==============================] - 0s 607us/sample - loss: 0.0490 - accuracy: 0.9815\n",
            "Epoch 872/1000\n",
            "24/24 [==============================] - 0s 584us/sample - loss: 0.0463 - accuracy: 0.9815\n",
            "Epoch 873/1000\n",
            "24/24 [==============================] - 0s 564us/sample - loss: 0.0481 - accuracy: 0.9907\n",
            "Epoch 874/1000\n",
            "24/24 [==============================] - 0s 507us/sample - loss: 0.0497 - accuracy: 0.9907\n",
            "Epoch 875/1000\n",
            "24/24 [==============================] - 0s 585us/sample - loss: 0.0477 - accuracy: 0.9907\n",
            "Epoch 876/1000\n",
            "24/24 [==============================] - 0s 545us/sample - loss: 0.0492 - accuracy: 0.9861\n",
            "Epoch 877/1000\n",
            "24/24 [==============================] - 0s 534us/sample - loss: 0.0490 - accuracy: 0.9907\n",
            "Epoch 878/1000\n",
            "24/24 [==============================] - 0s 595us/sample - loss: 0.0469 - accuracy: 0.9815\n",
            "Epoch 879/1000\n",
            "24/24 [==============================] - 0s 566us/sample - loss: 0.0469 - accuracy: 0.9907\n",
            "Epoch 880/1000\n",
            "24/24 [==============================] - 0s 663us/sample - loss: 0.0483 - accuracy: 0.9815\n",
            "Epoch 881/1000\n",
            "24/24 [==============================] - 0s 615us/sample - loss: 0.0499 - accuracy: 0.9861\n",
            "Epoch 882/1000\n",
            "24/24 [==============================] - 0s 612us/sample - loss: 0.0480 - accuracy: 0.9815\n",
            "Epoch 883/1000\n",
            "24/24 [==============================] - 0s 570us/sample - loss: 0.0485 - accuracy: 0.9861\n",
            "Epoch 884/1000\n",
            "24/24 [==============================] - 0s 554us/sample - loss: 0.0480 - accuracy: 0.9815\n",
            "Epoch 885/1000\n",
            "24/24 [==============================] - 0s 571us/sample - loss: 0.0483 - accuracy: 0.9861\n",
            "Epoch 886/1000\n",
            "24/24 [==============================] - 0s 527us/sample - loss: 0.0471 - accuracy: 0.9907\n",
            "Epoch 887/1000\n",
            "24/24 [==============================] - 0s 512us/sample - loss: 0.0501 - accuracy: 0.9815\n",
            "Epoch 888/1000\n",
            "24/24 [==============================] - 0s 611us/sample - loss: 0.0460 - accuracy: 0.9907\n",
            "Epoch 889/1000\n",
            "24/24 [==============================] - 0s 532us/sample - loss: 0.0457 - accuracy: 0.9907\n",
            "Epoch 890/1000\n",
            "24/24 [==============================] - 0s 529us/sample - loss: 0.0477 - accuracy: 0.9861\n",
            "Epoch 891/1000\n",
            "24/24 [==============================] - 0s 587us/sample - loss: 0.0456 - accuracy: 0.9815\n",
            "Epoch 892/1000\n",
            "24/24 [==============================] - 0s 477us/sample - loss: 0.0466 - accuracy: 0.9769\n",
            "Epoch 893/1000\n",
            "24/24 [==============================] - 0s 456us/sample - loss: 0.0491 - accuracy: 0.9815\n",
            "Epoch 894/1000\n",
            "24/24 [==============================] - 0s 402us/sample - loss: 0.0481 - accuracy: 0.9861\n",
            "Epoch 895/1000\n",
            "24/24 [==============================] - 0s 451us/sample - loss: 0.0447 - accuracy: 0.9907\n",
            "Epoch 896/1000\n",
            "24/24 [==============================] - 0s 527us/sample - loss: 0.0461 - accuracy: 0.9861\n",
            "Epoch 897/1000\n",
            "24/24 [==============================] - 0s 996us/sample - loss: 0.0447 - accuracy: 0.9954\n",
            "Epoch 898/1000\n",
            "24/24 [==============================] - 0s 603us/sample - loss: 0.0443 - accuracy: 0.9861\n",
            "Epoch 899/1000\n",
            "24/24 [==============================] - 0s 494us/sample - loss: 0.0436 - accuracy: 0.9815\n",
            "Epoch 900/1000\n",
            "24/24 [==============================] - 0s 784us/sample - loss: 0.0436 - accuracy: 0.9907\n",
            "Epoch 901/1000\n",
            "24/24 [==============================] - 0s 547us/sample - loss: 0.0461 - accuracy: 0.9815\n",
            "Epoch 902/1000\n",
            "24/24 [==============================] - 0s 812us/sample - loss: 0.0441 - accuracy: 0.9907\n",
            "Epoch 903/1000\n",
            "24/24 [==============================] - 0s 497us/sample - loss: 0.0468 - accuracy: 0.9907\n",
            "Epoch 904/1000\n",
            "24/24 [==============================] - 0s 602us/sample - loss: 0.0435 - accuracy: 0.9861\n",
            "Epoch 905/1000\n",
            "24/24 [==============================] - 0s 751us/sample - loss: 0.0428 - accuracy: 0.9907\n",
            "Epoch 906/1000\n",
            "24/24 [==============================] - 0s 583us/sample - loss: 0.0446 - accuracy: 0.9907\n",
            "Epoch 907/1000\n",
            "24/24 [==============================] - 0s 663us/sample - loss: 0.0431 - accuracy: 0.9954\n",
            "Epoch 908/1000\n",
            "24/24 [==============================] - 0s 584us/sample - loss: 0.0463 - accuracy: 0.9861\n",
            "Epoch 909/1000\n",
            "24/24 [==============================] - 0s 637us/sample - loss: 0.0459 - accuracy: 0.9861\n",
            "Epoch 910/1000\n",
            "24/24 [==============================] - 0s 572us/sample - loss: 0.0449 - accuracy: 0.9861\n",
            "Epoch 911/1000\n",
            "24/24 [==============================] - 0s 597us/sample - loss: 0.0433 - accuracy: 0.9861\n",
            "Epoch 912/1000\n",
            "24/24 [==============================] - 0s 630us/sample - loss: 0.0461 - accuracy: 0.9907\n",
            "Epoch 913/1000\n",
            "24/24 [==============================] - 0s 433us/sample - loss: 0.0445 - accuracy: 0.9861\n",
            "Epoch 914/1000\n",
            "24/24 [==============================] - 0s 668us/sample - loss: 0.0425 - accuracy: 0.9907\n",
            "Epoch 915/1000\n",
            "24/24 [==============================] - 0s 658us/sample - loss: 0.0444 - accuracy: 0.9861\n",
            "Epoch 916/1000\n",
            "24/24 [==============================] - 0s 646us/sample - loss: 0.0428 - accuracy: 0.9907\n",
            "Epoch 917/1000\n",
            "24/24 [==============================] - 0s 573us/sample - loss: 0.0425 - accuracy: 0.9815\n",
            "Epoch 918/1000\n",
            "24/24 [==============================] - 0s 524us/sample - loss: 0.0418 - accuracy: 0.9861\n",
            "Epoch 919/1000\n",
            "24/24 [==============================] - 0s 511us/sample - loss: 0.0452 - accuracy: 0.9769\n",
            "Epoch 920/1000\n",
            "24/24 [==============================] - 0s 581us/sample - loss: 0.0441 - accuracy: 0.9861\n",
            "Epoch 921/1000\n",
            "24/24 [==============================] - 0s 542us/sample - loss: 0.0455 - accuracy: 0.9815\n",
            "Epoch 922/1000\n",
            "24/24 [==============================] - 0s 508us/sample - loss: 0.0420 - accuracy: 0.9861\n",
            "Epoch 923/1000\n",
            "24/24 [==============================] - 0s 526us/sample - loss: 0.0438 - accuracy: 0.9861\n",
            "Epoch 924/1000\n",
            "24/24 [==============================] - 0s 483us/sample - loss: 0.0415 - accuracy: 0.9861\n",
            "Epoch 925/1000\n",
            "24/24 [==============================] - 0s 540us/sample - loss: 0.0429 - accuracy: 0.9907\n",
            "Epoch 926/1000\n",
            "24/24 [==============================] - 0s 502us/sample - loss: 0.0436 - accuracy: 0.9861\n",
            "Epoch 927/1000\n",
            "24/24 [==============================] - 0s 425us/sample - loss: 0.0433 - accuracy: 0.9769\n",
            "Epoch 928/1000\n",
            "24/24 [==============================] - 0s 506us/sample - loss: 0.0423 - accuracy: 0.9815\n",
            "Epoch 929/1000\n",
            "24/24 [==============================] - 0s 559us/sample - loss: 0.0411 - accuracy: 0.9907\n",
            "Epoch 930/1000\n",
            "24/24 [==============================] - 0s 476us/sample - loss: 0.0412 - accuracy: 0.9907\n",
            "Epoch 931/1000\n",
            "24/24 [==============================] - 0s 606us/sample - loss: 0.0435 - accuracy: 0.9815\n",
            "Epoch 932/1000\n",
            "24/24 [==============================] - 0s 568us/sample - loss: 0.0404 - accuracy: 0.9907\n",
            "Epoch 933/1000\n",
            "24/24 [==============================] - 0s 538us/sample - loss: 0.0413 - accuracy: 0.9861\n",
            "Epoch 934/1000\n",
            "24/24 [==============================] - 0s 522us/sample - loss: 0.0380 - accuracy: 0.9907\n",
            "Epoch 935/1000\n",
            "24/24 [==============================] - 0s 656us/sample - loss: 0.0439 - accuracy: 0.9815\n",
            "Epoch 936/1000\n",
            "24/24 [==============================] - 0s 559us/sample - loss: 0.0405 - accuracy: 0.9954\n",
            "Epoch 937/1000\n",
            "24/24 [==============================] - 0s 492us/sample - loss: 0.0432 - accuracy: 0.9861\n",
            "Epoch 938/1000\n",
            "24/24 [==============================] - 0s 617us/sample - loss: 0.0418 - accuracy: 0.9861\n",
            "Epoch 939/1000\n",
            "24/24 [==============================] - 0s 621us/sample - loss: 0.0412 - accuracy: 0.9861\n",
            "Epoch 940/1000\n",
            "24/24 [==============================] - 0s 469us/sample - loss: 0.0409 - accuracy: 0.9815\n",
            "Epoch 941/1000\n",
            "24/24 [==============================] - 0s 533us/sample - loss: 0.0409 - accuracy: 0.9861\n",
            "Epoch 942/1000\n",
            "24/24 [==============================] - 0s 535us/sample - loss: 0.0411 - accuracy: 0.9907\n",
            "Epoch 943/1000\n",
            "24/24 [==============================] - 0s 507us/sample - loss: 0.0407 - accuracy: 0.9815\n",
            "Epoch 944/1000\n",
            "24/24 [==============================] - 0s 579us/sample - loss: 0.0410 - accuracy: 0.9907\n",
            "Epoch 945/1000\n",
            "24/24 [==============================] - 0s 469us/sample - loss: 0.0388 - accuracy: 0.9907\n",
            "Epoch 946/1000\n",
            "24/24 [==============================] - 0s 563us/sample - loss: 0.0377 - accuracy: 0.9861\n",
            "Epoch 947/1000\n",
            "24/24 [==============================] - 0s 468us/sample - loss: 0.0395 - accuracy: 0.9815\n",
            "Epoch 948/1000\n",
            "24/24 [==============================] - 0s 430us/sample - loss: 0.0401 - accuracy: 0.9907\n",
            "Epoch 949/1000\n",
            "24/24 [==============================] - 0s 662us/sample - loss: 0.0384 - accuracy: 0.9954\n",
            "Epoch 950/1000\n",
            "24/24 [==============================] - 0s 618us/sample - loss: 0.0381 - accuracy: 0.9861\n",
            "Epoch 951/1000\n",
            "24/24 [==============================] - 0s 450us/sample - loss: 0.0404 - accuracy: 0.9861\n",
            "Epoch 952/1000\n",
            "24/24 [==============================] - 0s 462us/sample - loss: 0.0410 - accuracy: 0.9861\n",
            "Epoch 953/1000\n",
            "24/24 [==============================] - 0s 699us/sample - loss: 0.0392 - accuracy: 0.9861\n",
            "Epoch 954/1000\n",
            "24/24 [==============================] - 0s 577us/sample - loss: 0.0399 - accuracy: 0.9815\n",
            "Epoch 955/1000\n",
            "24/24 [==============================] - 0s 1ms/sample - loss: 0.0398 - accuracy: 0.9907\n",
            "Epoch 956/1000\n",
            "24/24 [==============================] - 0s 662us/sample - loss: 0.0395 - accuracy: 0.9907\n",
            "Epoch 957/1000\n",
            "24/24 [==============================] - 0s 562us/sample - loss: 0.0371 - accuracy: 0.9954\n",
            "Epoch 958/1000\n",
            "24/24 [==============================] - 0s 626us/sample - loss: 0.0400 - accuracy: 0.9954\n",
            "Epoch 959/1000\n",
            "24/24 [==============================] - 0s 615us/sample - loss: 0.0397 - accuracy: 0.9815\n",
            "Epoch 960/1000\n",
            "24/24 [==============================] - 0s 547us/sample - loss: 0.0425 - accuracy: 0.9769\n",
            "Epoch 961/1000\n",
            "24/24 [==============================] - 0s 555us/sample - loss: 0.0406 - accuracy: 0.9815\n",
            "Epoch 962/1000\n",
            "24/24 [==============================] - 0s 621us/sample - loss: 0.0400 - accuracy: 0.9861\n",
            "Epoch 963/1000\n",
            "24/24 [==============================] - 0s 716us/sample - loss: 0.0390 - accuracy: 0.9815\n",
            "Epoch 964/1000\n",
            "24/24 [==============================] - 0s 661us/sample - loss: 0.0388 - accuracy: 0.9907\n",
            "Epoch 965/1000\n",
            "24/24 [==============================] - 0s 618us/sample - loss: 0.0382 - accuracy: 0.9861\n",
            "Epoch 966/1000\n",
            "24/24 [==============================] - 0s 498us/sample - loss: 0.0385 - accuracy: 0.9815\n",
            "Epoch 967/1000\n",
            "24/24 [==============================] - 0s 663us/sample - loss: 0.0393 - accuracy: 0.9861\n",
            "Epoch 968/1000\n",
            "24/24 [==============================] - 0s 507us/sample - loss: 0.0384 - accuracy: 0.9907\n",
            "Epoch 969/1000\n",
            "24/24 [==============================] - 0s 481us/sample - loss: 0.0379 - accuracy: 0.9861\n",
            "Epoch 970/1000\n",
            "24/24 [==============================] - 0s 589us/sample - loss: 0.0374 - accuracy: 0.9907\n",
            "Epoch 971/1000\n",
            "24/24 [==============================] - 0s 623us/sample - loss: 0.0402 - accuracy: 0.9815\n",
            "Epoch 972/1000\n",
            "24/24 [==============================] - 0s 566us/sample - loss: 0.0369 - accuracy: 0.9907\n",
            "Epoch 973/1000\n",
            "24/24 [==============================] - 0s 520us/sample - loss: 0.0384 - accuracy: 0.9815\n",
            "Epoch 974/1000\n",
            "24/24 [==============================] - 0s 593us/sample - loss: 0.0396 - accuracy: 0.9815\n",
            "Epoch 975/1000\n",
            "24/24 [==============================] - 0s 728us/sample - loss: 0.0373 - accuracy: 0.9815\n",
            "Epoch 976/1000\n",
            "24/24 [==============================] - 0s 616us/sample - loss: 0.0386 - accuracy: 0.9861\n",
            "Epoch 977/1000\n",
            "24/24 [==============================] - 0s 611us/sample - loss: 0.0424 - accuracy: 0.9907\n",
            "Epoch 978/1000\n",
            "24/24 [==============================] - 0s 522us/sample - loss: 0.0381 - accuracy: 0.9815\n",
            "Epoch 979/1000\n",
            "24/24 [==============================] - 0s 628us/sample - loss: 0.0397 - accuracy: 0.9907\n",
            "Epoch 980/1000\n",
            "24/24 [==============================] - 0s 592us/sample - loss: 0.0371 - accuracy: 0.9861\n",
            "Epoch 981/1000\n",
            "24/24 [==============================] - 0s 552us/sample - loss: 0.0397 - accuracy: 0.9861\n",
            "Epoch 982/1000\n",
            "24/24 [==============================] - 0s 695us/sample - loss: 0.0391 - accuracy: 0.9815\n",
            "Epoch 983/1000\n",
            "24/24 [==============================] - 0s 727us/sample - loss: 0.0362 - accuracy: 0.9861\n",
            "Epoch 984/1000\n",
            "24/24 [==============================] - 0s 581us/sample - loss: 0.0351 - accuracy: 0.9954\n",
            "Epoch 985/1000\n",
            "24/24 [==============================] - 0s 611us/sample - loss: 0.0418 - accuracy: 0.9861\n",
            "Epoch 986/1000\n",
            "24/24 [==============================] - 0s 476us/sample - loss: 0.0382 - accuracy: 0.9815\n",
            "Epoch 987/1000\n",
            "24/24 [==============================] - 0s 607us/sample - loss: 0.0345 - accuracy: 0.9954\n",
            "Epoch 988/1000\n",
            "24/24 [==============================] - 0s 541us/sample - loss: 0.0388 - accuracy: 0.9861\n",
            "Epoch 989/1000\n",
            "24/24 [==============================] - 0s 503us/sample - loss: 0.0381 - accuracy: 0.9907\n",
            "Epoch 990/1000\n",
            "24/24 [==============================] - 0s 423us/sample - loss: 0.0366 - accuracy: 0.9907\n",
            "Epoch 991/1000\n",
            "24/24 [==============================] - 0s 535us/sample - loss: 0.0343 - accuracy: 0.9861\n",
            "Epoch 992/1000\n",
            "24/24 [==============================] - 0s 564us/sample - loss: 0.0376 - accuracy: 0.9861\n",
            "Epoch 993/1000\n",
            "24/24 [==============================] - 0s 409us/sample - loss: 0.0359 - accuracy: 0.9861\n",
            "Epoch 994/1000\n",
            "24/24 [==============================] - 0s 623us/sample - loss: 0.0359 - accuracy: 0.9815\n",
            "Epoch 995/1000\n",
            "24/24 [==============================] - 0s 544us/sample - loss: 0.0379 - accuracy: 0.9815\n",
            "Epoch 996/1000\n",
            "24/24 [==============================] - 0s 577us/sample - loss: 0.0358 - accuracy: 0.9907\n",
            "Epoch 997/1000\n",
            "24/24 [==============================] - 0s 536us/sample - loss: 0.0343 - accuracy: 0.9954\n",
            "Epoch 998/1000\n",
            "24/24 [==============================] - 0s 565us/sample - loss: 0.0366 - accuracy: 0.9815\n",
            "Epoch 999/1000\n",
            "24/24 [==============================] - 0s 673us/sample - loss: 0.0374 - accuracy: 0.9815\n",
            "Epoch 1000/1000\n",
            "24/24 [==============================] - 0s 632us/sample - loss: 0.0351 - accuracy: 0.9861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fccacf1bf60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJjdRQSFPa8K",
        "colab_type": "code",
        "outputId": "69d3fa62-54e2-4928-eec5-4170ff0d8c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "start_string = 'grandeur'\n",
        "str_encoded = tokenizer.texts_to_sequences([start_string])\n",
        "print(str_encoded)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[108]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlM6_QObzAqt",
        "colab_type": "code",
        "outputId": "597ed375-f6c3-4494-badc-db6cda9b8312",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.predict_classes(str_encoded)[0][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iUDkfZD2tkX",
        "colab_type": "code",
        "outputId": "7fcbff7b-e21f-49d0-ec13-39035c0be0f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "reverse = {}\n",
        "for key in tokenizer.word_index:\n",
        "  reverse[tokenizer.word_index[key]] = key\n",
        "print(reverse)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 'the', 2: 'of', 3: 'a', 4: 'and', 5: 'for', 6: 'us', 7: 'we', 8: 'all', 9: 'such', 10: 'beauty', 11: 'is', 12: 'will', 13: 'quiet', 14: 'are', 15: 'to', 16: 'spite', 17: 'our', 18: 'in', 19: 'from', 20: 'with', 21: 'that', 22: 'have', 23: 'thing', 24: 'joy', 25: 'forever', 26: 'its', 27: 'loveliness', 28: 'increases', 29: 'it', 30: 'never', 31: 'pass', 32: 'into', 33: 'nothingness', 34: 'but', 35: 'still', 36: 'keep', 37: 'bower', 38: 'sleep', 39: 'full', 40: 'sweet', 41: 'dreams', 42: 'health', 43: 'breathing', 44: 'therefore', 45: 'on', 46: 'every', 47: 'morrow', 48: 'wreathing', 49: 'flowery', 50: 'band', 51: 'bind', 52: 'earth', 53: 'despondence', 54: 'inhuman', 55: 'dearth', 56: 'noble', 57: 'natures', 58: 'gloomy', 59: 'days', 60: 'unhealthy', 61: 'o’er', 62: 'darkened', 63: 'ways', 64: 'made', 65: 'searching', 66: 'yes', 67: 'some', 68: 'shape', 69: 'moves', 70: 'away', 71: 'pall', 72: 'dark', 73: 'spirits', 74: 'sun', 75: 'moon', 76: 'trees', 77: 'old', 78: 'young', 79: 'sprouting', 80: 'shady', 81: 'boon', 82: 'simple', 83: 'sheep', 84: 'daffodils', 85: 'green', 86: 'world', 87: 'they', 88: 'live', 89: 'clear', 90: 'rills', 91: 'themselves', 92: 'cooling', 93: 'covert', 94: 'make', 95: '’gainst', 96: 'hot', 97: 'season', 98: 'mid', 99: 'forest', 100: 'brake', 101: 'rich', 102: 'sprinkling', 103: 'fair', 104: 'musk', 105: 'rose', 106: 'blooms', 107: 'too', 108: 'grandeur', 109: 'dooms', 110: 'imagined', 111: 'mighty', 112: 'dead', 113: 'lovely', 114: 'tales', 115: 'heard', 116: 'or', 117: 'read', 118: 'an', 119: 'endless', 120: 'fountain', 121: 'immortal', 122: 'drink', 123: 'pouring', 124: 'unto', 125: 'heaven’s', 126: 'brink'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzeYDp-50w8H",
        "colab_type": "code",
        "outputId": "bf2a4e90-f62b-4176-a866-f169d4a93379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "num_words = 20\n",
        "text = [start_string]\n",
        "word = str_encoded\n",
        "for i in range(num_words):\n",
        "  word = model.predict_classes(word)\n",
        "  text.append(reverse[word[0][0]])\n",
        "print(text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['grandeur', 'of', 'noble', 'have', 'our', 'flowery', 'simple', 'old', 'old', 'old', 'old', 'old', 'old', 'old', 'old', 'old', 'old', 'old', 'old', 'old', 'old']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7svs86yab5O",
        "colab_type": "text"
      },
      "source": [
        "The prediction are a little gibberish and repetitive after a certain length. Its probably because of lack of data. Training the model on more corpus can result in more meaningful sentences and less repetitive words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpLK1msq32N2",
        "colab_type": "code",
        "outputId": "900d56e1-32ad-424b-f36a-fcd7cce7cce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget https://storage.googleapis.com/laurencemoroney-blog.appspot.com/irish-lyrics-eof.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-11 07:50:20--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/irish-lyrics-eof.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 2607:f8b0:400e:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68970 (67K) [text/plain]\n",
            "Saving to: ‘irish-lyrics-eof.txt’\n",
            "\n",
            "\rirish-lyrics-eof.tx   0%[                    ]       0  --.-KB/s               \rirish-lyrics-eof.tx 100%[===================>]  67.35K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2019-08-11 07:50:20 (73.7 MB/s) - ‘irish-lyrics-eof.txt’ saved [68970/68970]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKNdYtXQa-eS",
        "colab_type": "code",
        "outputId": "9ffdc074-32e2-47d4-dd53-731ef54002a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "with open('irish-lyrics-eof.txt') as f:\n",
        "  data = f.read().splitlines()\n",
        "print(data[0:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Come all ye maidens young and fair', 'And you that are blooming in your prime', 'Always beware and keep your garden fair', 'Let no man steal away your thyme', 'For thyme it is a precious thing']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgYSOw0ZjuxZ",
        "colab_type": "code",
        "outputId": "5a9338ff-0e2d-484d-b716-69a5d381803f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1692"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4zKhlVPkHqX",
        "colab_type": "code",
        "outputId": "b65d3c8b-feb1-441b-811c-6b4d4838a6bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data)\n",
        "print(tokenizer.word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 1, 'and': 2, 'i': 3, 'to': 4, 'a': 5, 'of': 6, 'my': 7, 'in': 8, 'me': 9, 'for': 10, 'you': 11, 'all': 12, 'was': 13, 'she': 14, 'that': 15, 'on': 16, 'with': 17, 'her': 18, 'but': 19, 'as': 20, 'when': 21, 'love': 22, 'is': 23, 'your': 24, 'it': 25, 'will': 26, 'from': 27, 'by': 28, 'they': 29, 'be': 30, 'are': 31, 'so': 32, 'he': 33, 'old': 34, 'no': 35, 'oh': 36, 'ill': 37, 'at': 38, 'one': 39, 'his': 40, 'there': 41, 'were': 42, 'heart': 43, 'down': 44, 'now': 45, 'we': 46, 'where': 47, 'young': 48, 'never': 49, 'go': 50, 'come': 51, 'then': 52, 'did': 53, 'not': 54, 'said': 55, 'away': 56, 'their': 57, 'sweet': 58, 'them': 59, 'green': 60, 'if': 61, 'take': 62, 'our': 63, 'like': 64, 'night': 65, 'day': 66, 'o': 67, 'out': 68, 'fair': 69, 'this': 70, 'town': 71, 'have': 72, 'can': 73, 'true': 74, 'its': 75, 'thou': 76, 'see': 77, 'dear': 78, 'more': 79, 'theres': 80, 'or': 81, 'had': 82, 'would': 83, 'over': 84, 'hear': 85, 'up': 86, 'ive': 87, 'through': 88, 'home': 89, 'again': 90, 'well': 91, 'oer': 92, 'land': 93, 'good': 94, 'im': 95, 'ye': 96, 'sea': 97, 'left': 98, 'still': 99, 'father': 100, 'long': 101, 'rose': 102, 'could': 103, 'morning': 104, 'wild': 105, 'who': 106, 'eyes': 107, 'came': 108, 'while': 109, 'too': 110, 'back': 111, 'little': 112, 'an': 113, 'took': 114, 'him': 115, 'bow': 116, 'first': 117, 'let': 118, 'man': 119, 'shall': 120, 'know': 121, 'get': 122, 'high': 123, 'gone': 124, 'say': 125, 'ever': 126, 'some': 127, 'mary': 128, 'hand': 129, 'till': 130, 'put': 131, 'own': 132, 'time': 133, 'heard': 134, 'dead': 135, 'may': 136, 'bright': 137, 'mountain': 138, 'early': 139, 'rosin': 140, 'gave': 141, 'thee': 142, 'only': 143, 'far': 144, 'maid': 145, 'must': 146, 'find': 147, 'girl': 148, 'sure': 149, 'round': 150, 'dublin': 151, 'once': 152, 'world': 153, 'delight': 154, 'last': 155, 'johnny': 156, 'seen': 157, 'has': 158, 'fine': 159, 'road': 160, 'mother': 161, 'tis': 162, 'what': 163, 'way': 164, 'moon': 165, 'soul': 166, 'neer': 167, 'id': 168, 'just': 169, 'thats': 170, 'days': 171, 'darling': 172, 'went': 173, 'white': 174, 'die': 175, 'than': 176, 'hair': 177, 'goes': 178, 'meet': 179, 'today': 180, 'do': 181, 'girls': 182, 'shes': 183, 'thyme': 184, 'thy': 185, 'sing': 186, 'pretty': 187, 'new': 188, 'poor': 189, 'into': 190, 'life': 191, 'irish': 192, 'give': 193, 'boy': 194, 'youre': 195, 'make': 196, 'passed': 197, 'lovely': 198, 'black': 199, 'youll': 200, 'died': 201, 'red': 202, 'smile': 203, 'keep': 204, 'loves': 205, 'free': 206, 'leave': 207, 'friends': 208, 'each': 209, 'saw': 210, 'behind': 211, 'song': 212, 'ra': 213, 'dont': 214, 'arms': 215, 'am': 216, 'sun': 217, 'saying': 218, 'made': 219, 'wish': 220, 'cold': 221, 'met': 222, 'before': 223, 'should': 224, 'rocky': 225, 'light': 226, 'wid': 227, 'boys': 228, 'best': 229, 'fields': 230, 'since': 231, 'ball': 232, 'water': 233, 'casey': 234, 'mind': 235, 'along': 236, 'loved': 237, 'place': 238, 'ireland': 239, 'next': 240, 'three': 241, 'many': 242, 'years': 243, 'door': 244, 'us': 245, 'drink': 246, 'got': 247, 'might': 248, 'live': 249, 'roses': 250, 'play': 251, 'soon': 252, 'ground': 253, 'times': 254, 'spent': 255, 'going': 256, 'tree': 257, 'barley': 258, 'grass': 259, 'kind': 260, 'twas': 261, 'bridge': 262, 'around': 263, 'blue': 264, 'tell': 265, 'row': 266, 'how': 267, 'money': 268, 'merry': 269, 'stepped': 270, 'corporal': 271, 'always': 272, 'though': 273, 'near': 274, 'taken': 275, 'ones': 276, 'daughter': 277, 'forever': 278, 'loo': 279, 'shining': 280, 'plenty': 281, 'hes': 282, 'ship': 283, 'banks': 284, 'think': 285, 'very': 286, 'stand': 287, 'heres': 288, 'snow': 289, 'mountains': 290, 'molly': 291, 'wheel': 292, 'street': 293, 'erin': 294, 'side': 295, 'feet': 296, 'star': 297, 'look': 298, 'brave': 299, 'woman': 300, 'sons': 301, 'two': 302, 'says': 303, 'asked': 304, 'lanigans': 305, 'singing': 306, 'men': 307, 'toome': 308, 'stole': 309, 'god': 310, 'hill': 311, 'lonely': 312, 'lover': 313, 'tears': 314, 'fathers': 315, 'low': 316, 'voice': 317, 'quite': 318, 'able': 319, 'nice': 320, 'laid': 321, 'comrades': 322, 'wind': 323, 'another': 324, 'sit': 325, 'face': 326, 'band': 327, 'call': 328, 'colleen': 329, 'until': 330, 'hills': 331, 'mine': 332, 'above': 333, 'upon': 334, 'eer': 335, 'youve': 336, 'fly': 337, 'been': 338, 'late': 339, 'alive': 340, 'ballyjamesduff': 341, 'looked': 342, 'great': 343, 'why': 344, 'every': 345, 'proud': 346, 'found': 347, 'bragh': 348, 'such': 349, 'birds': 350, 'wedding': 351, 'welcome': 352, 'dancing': 353, 'da': 354, 'fell': 355, 'thinking': 356, 'roddy': 357, 'mccorley': 358, 'smiling': 359, 'mallow': 360, 'blooming': 361, 'thought': 362, 'peace': 363, 'soft': 364, 'pure': 365, 'harp': 366, 'dream': 367, 'alas': 368, 'yet': 369, 'clear': 370, 'art': 371, 'off': 372, 'hope': 373, 'fought': 374, 'mothers': 375, 'shore': 376, 'ago': 377, 'fol': 378, 'de': 379, 'house': 380, 'married': 381, 'bound': 382, 'danced': 383, 'devil': 384, 'dawning': 385, 'makes': 386, 'same': 387, 'sat': 388, 'any': 389, 'glass': 390, 'gay': 391, 'relations': 392, 'evening': 393, 'watched': 394, 'right': 395, 'fellows': 396, 'whiskey': 397, 'bonnie': 398, 'grows': 399, 'women': 400, 'flowers': 401, 'beauty': 402, 'cannot': 403, 'handsome': 404, 'happy': 405, 'gold': 406, 'rover': 407, 'none': 408, 'doneen': 409, 'summers': 410, 'people': 411, 'set': 412, 'paddy': 413, 'morn': 414, 'most': 415, 'easy': 416, 'struck': 417, 'beautiful': 418, 'those': 419, 'golden': 420, 'run': 421, 'pipes': 422, 'glen': 423, 'dying': 424, 'here': 425, 'wall': 426, 'across': 427, 'fire': 428, 'eileen': 429, 'longer': 430, 'cheeks': 431, 'valley': 432, 'both': 433, 'dew': 434, 'care': 435, 'bride': 436, 'nothing': 437, 'wont': 438, 'theyre': 439, 'colonel': 440, 'maiden': 441, 'shed': 442, 'til': 443, 'brown': 444, 'breast': 445, 'corn': 446, 'sinking': 447, 'began': 448, 'name': 449, 'cruel': 450, 'sound': 451, 'spancil': 452, 'county': 453, 'lies': 454, 'color': 455, 'thing': 456, 'decay': 457, 'sleep': 458, 'hours': 459, 'loving': 460, 'weary': 461, 'ringing': 462, 'please': 463, 'forget': 464, 'lie': 465, 'ran': 466, 'tore': 467, 'country': 468, 'fear': 469, 'fortune': 470, 'kissed': 471, 'alone': 472, 'ould': 473, 'cry': 474, 'dreams': 475, 'used': 476, 'horse': 477, 'break': 478, 'bells': 479, 'didnt': 480, 'weeks': 481, 'without': 482, 'raw': 483, 'nor': 484, 'twenty': 485, 'tune': 486, 'hed': 487, 'roving': 488, 'leaves': 489, 'cant': 490, 'death': 491, 'ten': 492, 'prison': 493, 'judge': 494, 'against': 495, 'lads': 496, 'shell': 497, 'fill': 498, 'valleys': 499, 'other': 500, 'pale': 501, 'joy': 502, 'wide': 503, 'bring': 504, 'ah': 505, 'cliffs': 506, 'city': 507, 'end': 508, 'turn': 509, 'sky': 510, 'born': 511, 'knew': 512, 'smiled': 513, 'rosie': 514, 'comes': 515, 'sayin': 516, 'lord': 517, 'dungannon': 518, 'blood': 519, 'air': 520, 'danny': 521, 'calling': 522, 'sunshine': 523, 'spring': 524, 'bid': 525, 'grow': 526, 'truth': 527, 'tear': 528, 'rings': 529, 'guns': 530, 'bay': 531, 'oflynn': 532, 'och': 533, 'stick': 534, 'rest': 535, 'four': 536, 'jewel': 537, 'tried': 538, 'grief': 539, 'answer': 540, 'kathleen': 541, 'fond': 542, 'eye': 543, 'goin': 544, 'pistols': 545, 'musha': 546, 'whack': 547, 'creole': 548, 'together': 549, 'room': 550, 'fall': 551, 'swore': 552, 'being': 553, 'step': 554, 'lark': 555, 'cailín': 556, 'deas': 557, 'crúite': 558, 'na': 559, 'mbó': 560, 'sir': 561, 'isle': 562, 'waiting': 563, 'magic': 564, 'skibbereen': 565, 'loud': 566, 'raise': 567, 'bent': 568, 'aged': 569, 'summer': 570, 'jenny': 571, 'excise': 572, 'rigadoo': 573, 'auld': 574, 'hearts': 575, 'nay': 576, 'stool': 577, 'farrell': 578, 'garden': 579, 'precious': 580, 'child': 581, 'slumber': 582, 'sleeping': 583, 'watch': 584, 'gently': 585, 'minstrel': 586, 'praise': 587, 'bell': 588, 'shaken': 589, 'immortal': 590, 'pray': 591, 'stay': 592, 'spoke': 593, 'cross': 594, 'brothers': 595, 'much': 596, 'past': 597, 'killarney': 598, 'sang': 599, 'tones': 600, 'ral': 601, 'wander': 602, 'cot': 603, 'feel': 604, 'yore': 605, 'answered': 606, 'divil': 607, 'middle': 608, 'bit': 609, 'led': 610, 'soldiers': 611, 'lily': 612, 'bed': 613, 'lassie': 614, 'clothes': 615, 'return': 616, 'broken': 617, 'derry': 618, 'sighed': 619, 'english': 620, 'tomorrow': 621, 'souls': 622, 'van': 623, 'diemans': 624, 'law': 625, 'neither': 626, 'winds': 627, 'rather': 628, 'doesnt': 629, 'rosy': 630, 'neatest': 631, 'hands': 632, 'whereon': 633, 'stands': 634, 'write': 635, 'thousand': 636, 'fare': 637, 'youd': 638, 'velvet': 639, 'neat': 640, 'landed': 641, 'health': 642, 'kellswater': 643, 'quiet': 644, 'stars': 645, 'beside': 646, 'warm': 647, 'sunday': 648, 'grey': 649, 'ocean': 650, 'sad': 651, 'spend': 652, 'kilkenny': 653, 'silver': 654, 'view': 655, 'west': 656, 'plain': 657, 'barrow': 658, 'broad': 659, 'narrow': 660, 'crying': 661, 'wonder': 662, 'save': 663, 'stop': 664, 'tender': 665, 'told': 666, 'lip': 667, 'dance': 668, 'foot': 669, 'kilrain': 670, 'saint': 671, 'visit': 672, 'mossy': 673, 'wexford': 674, 'irishmen': 675, 'shadow': 676, 'tho': 677, 'salley': 678, 'gardens': 679, 'foolish': 680, 'youth': 681, 'fade': 682, 'war': 683, 'believe': 684, 'which': 685, 'change': 686, 'entwine': 687, 'turns': 688, 'turned': 689, 'crown': 690, 'played': 691, 'captain': 692, 'blow': 693, 'children': 694, 'slainte': 695, 'gentle': 696, 'heavens': 697, 'bloom': 698, 'grand': 699, 'bush': 700, 'nest': 701, 'rich': 702, 'parting': 703, 'better': 704, 'window': 705, 'haste': 706, 'fresh': 707, 'stream': 708, 'rays': 709, 'ma': 710, 'ring': 711, 'lad': 712, 'athy': 713, 'drop': 714, 'hardly': 715, 'done': 716, 'arm': 717, 'leg': 718, 'beg': 719, 'drew': 720, 'bold': 721, 'drawn': 722, 'jail': 723, 'writin': 724, 'farewell': 725, 'tired': 726, 'lake': 727, 'want': 728, 'ringlets': 729, 'myself': 730, 'songs': 731, 'reel': 732, 'steps': 733, 'hearty': 734, 'fainted': 735, 'called': 736, 'under': 737, 'toe': 738, 'mairi': 739, 'fairest': 740, 'darlin': 741, 'bird': 742, 'memory': 743, 'lips': 744, 'sweetly': 745, 'morrow': 746, 'consent': 747, 'else': 748, 'sold': 749, 'stout': 750, 'pair': 751, 'drinking': 752, 'meself': 753, 'fray': 754, 'pike': 755, 'coat': 756, 'beneath': 757, 'rent': 758, 'part': 759, 'half': 760, 'head': 761, 'friend': 762, 'standing': 763, 'floor': 764, 'bare': 765, 'wed': 766, 'son': 767, 'pride': 768, 'vision': 769, 'sword': 770, 'after': 771, 'won': 772, 'farmers': 773, 'flower': 774, 'nut': 775, 'surely': 776, 'stood': 777, 'wandered': 778, 'athenry': 779, 'rising': 780, 'beating': 781, 'form': 782, 'dhu': 783, 'buy': 784, 'laughter': 785, 'wear': 786, 'raking': 787, 'rakes': 788, 'claret': 789, 'shure': 790, 'tralee': 791, 'slower': 792, 'lower': 793, 'deep': 794, 'wearin': 795, 'duram': 796, 'takes': 797, 'beware': 798, 'steal': 799, 'brings': 800, 'things': 801, 'joys': 802, 'bunch': 803, 'sailor': 804, 'chanced': 805, 'pass': 806, 'angels': 807, 'send': 808, 'drowsy': 809, 'keeping': 810, 'spirit': 811, 'stealing': 812, 'feeling': 813, 'roam': 814, 'presence': 815, 'heavenward': 816, 'dust': 817, 'dim': 818, 'journey': 819, 'waves': 820, 'frightened': 821, 'leaving': 822, 'struggle': 823, 'parents': 824, 'courage': 825, 'weeping': 826, 'pain': 827, 'mist': 828, 'felt': 829, 'roared': 830, 'making': 831, 'fever': 832, 'moment': 833, 'distance': 834, 'wailing': 835, 'oft': 836, 'held': 837, 'fast': 838, 'cabin': 839, 'honey': 840, 'diddle': 841, 'clearly': 842, 'open': 843, 'opened': 844, 'table': 845, 'wine': 846, 'lay': 847, 'shells': 848, 'sailed': 849, 'drown': 850, 'fetters': 851, 'chains': 852, 'wives': 853, 'sorrow': 854, 'thoughts': 855, 'cursed': 856, 'hell': 857, 'five': 858, 'buried': 859, 'lost': 860, 'endless': 861, 'slavery': 862, 'gun': 863, 'rain': 864, 'cares': 865, 'ghosts': 866, 'runaway': 867, 'twill': 868, 'month': 869, 'meadows': 870, 'prettiest': 871, 'winters': 872, 'satisfied': 873, 'few': 874, 'short': 875, 'lines': 876, 'shone': 877, 'shoulder': 878, 'belfast': 879, 'trade': 880, 'bad': 881, 'caused': 882, 'stray': 883, 'meaning': 884, 'damsel': 885, 'appear': 886, 'seven': 887, 'sentence': 888, 'jolly': 889, 'whenever': 890, 'wee': 891, 'wife': 892, 'lives': 893, 'martha': 894, 'courted': 895, 'bridgit': 896, 'omalley': 897, 'desolation': 898, 'thorn': 899, 'gaze': 900, 'stone': 901, 'approaching': 902, 'sets': 903, 'carrigfergus': 904, 'nights': 905, 'swim': 906, 'wings': 907, 'sober': 908, 'travel': 909, 'native': 910, 'places': 911, 'slopes': 912, 'hares': 913, 'lofty': 914, 'malone': 915, 'wheeled': 916, 'streets': 917, 'enough': 918, 'reilly': 919, 'tough': 920, 'whispers': 921, 'phil': 922, 'threw': 923, 'straight': 924, 'belles': 925, 'moor': 926, 'brand': 927, 'shapes': 928, 'work': 929, 'vow': 930, 'blarney': 931, 'paid': 932, 'bower': 933, 'remain': 934, 'charming': 935, 'storied': 936, 'chieftains': 937, 'slaughter': 938, 'bann': 939, 'boyne': 940, 'liffey': 941, 'gallant': 942, 'awake': 943, 'greet': 944, 'meadow': 945, 'sweeter': 946, 'dirty': 947, 'cats': 948, 'crossed': 949, 'field': 950, 'river': 951, 'full': 952, 'aroon': 953, 'sends': 954, 'woe': 955, 'chain': 956, 'main': 957, 'charms': 958, 'fondly': 959, 'fleet': 960, 'fairy': 961, 'thine': 962, 'known': 963, 'truly': 964, 'close': 965, 'story': 966, 'flag': 967, 'sweetest': 968, 'honor': 969, 'playing': 970, 'mauser': 971, 'music': 972, 'tom': 973, 'hurrah': 974, 'big': 975, 'lead': 976, 'south': 977, 'generation': 978, 'freedom': 979, 'agin': 980, 'creature': 981, 'dad': 982, 'venture': 983, 'word': 984, 'wonderful': 985, 'crazy': 986, 'lazy': 987, 'grave': 988, 'jest': 989, 'remark': 990, 'strangers': 991, 'strong': 992, 'shook': 993, 'walk': 994, 'north': 995, 'ours': 996, 'cease': 997, 'strife': 998, 'whats': 999, 'lilacs': 1000, 'prove': 1001, 'sweetheart': 1002, 'letters': 1003, 'sent': 1004, 'speak': 1005, 'brow': 1006, 'albert': 1007, 'mooney': 1008, 'fighting': 1009, 'fingers': 1010, 'toes': 1011, 'john': 1012, 'hurroo': 1013, 'drums': 1014, 'beguiled': 1015, 'carry': 1016, 'bone': 1017, 'havent': 1018, 'walkin': 1019, 'kilgary': 1020, 'pepper': 1021, 'countin': 1022, 'forth': 1023, 'deliver': 1024, 'daddy': 1025, 'em': 1026, 'deceive': 1027, 'between': 1028, 'even': 1029, 'prisoner': 1030, 'fists': 1031, 'knocked': 1032, 'carriages': 1033, 'rollin': 1034, 'juice': 1035, 'courtin': 1036, 'ponchartrain': 1037, 'does': 1038, 'stranger': 1039, 'marry': 1040, 'adieu': 1041, 'ask': 1042, 'tipped': 1043, 'arrived': 1044, 'ladies': 1045, 'potatoes': 1046, 'courting': 1047, 'miss': 1048, 'small': 1049, 'ned': 1050, 'ribbons': 1051, 'heel': 1052, 'bonny': 1053, 'pipe': 1054, 'thrush': 1055, 'sweethearts': 1056, 'unto': 1057, 'rise': 1058, 'softly': 1059, 'milking': 1060, 'rare': 1061, 'pity': 1062, 'treasure': 1063, 'noon': 1064, 'sailing': 1065, 'banish': 1066, 'riches': 1067, 'comfort': 1068, 'yonder': 1069, 'flows': 1070, 'fairer': 1071, 'lass': 1072, 'woods': 1073, 'strayed': 1074, 'locks': 1075, 'breaking': 1076, 'june': 1077, 'started': 1078, 'hearted': 1079, 'beer': 1080, 'daylight': 1081, 'among': 1082, 'bundle': 1083, 'connaught': 1084, 'quay': 1085, 'erins': 1086, 'galway': 1087, 'fearless': 1088, 'bravely': 1089, 'marches': 1090, 'fate': 1091, 'neck': 1092, 'trod': 1093, 'marched': 1094, 'antrim': 1095, 'sash': 1096, 'flashed': 1097, 'hath': 1098, 'foemans': 1099, 'fight': 1100, 'heavy': 1101, 'bore': 1102, 'mans': 1103, 'counter': 1104, 'dozen': 1105, 'gallon': 1106, 'bottles': 1107, 'diamond': 1108, 'resemble': 1109, 'tiny': 1110, 'friendly': 1111, 'weather': 1112, 'inside': 1113, 'remember': 1114, 'someone': 1115, 'hat': 1116, 'body': 1117, 'dancers': 1118, 'hanging': 1119, 'empty': 1120, 'shoes': 1121, 'broke': 1122, 'december': 1123, 'move': 1124, 'reason': 1125, 'roof': 1126, 'naught': 1127, 'tower': 1128, 'power': 1129, 'king': 1130, 'dreaming': 1131, 'crew': 1132, 'whos': 1133, 'mccann': 1134, 'smoke': 1135, 'notes': 1136, 'yeoman': 1137, 'cavalry': 1138, 'guard': 1139, 'forced': 1140, 'brother': 1141, 'cousin': 1142, 'blame': 1143, 'croppy': 1144, 'dressed': 1145, 'trees': 1146, 'wore': 1147, 'words': 1148, 'swiftly': 1149, 'dawn': 1150, 'lovd': 1151, 'voices': 1152, 'moaning': 1153, 'dark': 1154, 'gather': 1155, 'tay': 1156, 'swinging': 1157, 'drinkin': 1158, 'sitting': 1159, 'stile': 1160, 'springing': 1161, 'yours': 1162, 'kept': 1163, 'aisey': 1164, 'rub': 1165, 'dub': 1166, 'dow': 1167, 'shelah': 1168, 'fairly': 1169, 'beggarman': 1170, 'begging': 1171, 'slept': 1172, 'holes': 1173, 'coming': 1174, 'thru': 1175, 'boo': 1176, 'lady': 1177, 'kerry': 1178, 'pipers': 1179, 'laugh': 1180, 'beaming': 1181, 'guineas': 1182, 'least': 1183, 'diggin': 1184, 'mourne': 1185, 'spending': 1186, 'mellow': 1187, 'plying': 1188, 'slowly': 1189, 'mooncoin': 1190, 'flow': 1191, 'sounds': 1192, 'shine': 1193, 'cool': 1194, 'crystal': 1195, 'fountain': 1196, 'moonlight': 1197, 'grandmother': 1198, 'crooning': 1199, 'merrily': 1200, 'spins': 1201, 'lightly': 1202, 'moving': 1203, 'lattice': 1204, 'grove': 1205, 'swings': 1206, 'finger': 1207, 'shamrock': 1208, 'pocket': 1209, 'springtime': 1210, 'gilgarra': 1211, 'rapier': 1212, 'ringum': 1213, 'mornin': 1214, 'heather': 1215, 'build': 1216, 'maidens': 1217, 'prime': 1218, 'nlyme': 1219, 'flavours': 1220, 'lusty': 1221, 'reminded': 1222, 'attend': 1223, 'guardian': 1224, 'creeping': 1225, 'dale': 1226, 'vigil': 1227, 'visions': 1228, 'revealing': 1229, 'breathes': 1230, 'holy': 1231, 'strains': 1232, 'hover': 1233, 'hark': 1234, 'solemn': 1235, 'winging': 1236, 'earthly': 1237, 'shalt': 1238, 'awaken': 1239, 'destiny': 1240, 'emigrants': 1241, 'amid': 1242, 'longing': 1243, 'parted': 1244, 'townland': 1245, 'vessel': 1246, 'crowded': 1247, 'disquieted': 1248, 'folk': 1249, 'escape': 1250, 'hardship': 1251, 'sustaining': 1252, 'glimpse': 1253, 'faded': 1254, 'strangely': 1255, 'seas': 1256, 'anger': 1257, 'desperate': 1258, 'plight': 1259, 'worsened': 1260, 'delirium': 1261, 'possessed': 1262, 'clouded': 1263, 'prayers': 1264, 'begged': 1265, 'forgiveness': 1266, 'seeking': 1267, 'distant': 1268, 'mither': 1269, 'simple': 1270, 'ditty': 1271, 'ld': 1272, 'li': 1273, 'hush': 1274, 'lullaby': 1275, 'huggin': 1276, 'hummin': 1277, 'rock': 1278, 'asleep': 1279, 'outside': 1280, 'modestly': 1281, 'ry': 1282, 'ay': 1283, 'di': 1284, 're': 1285, 'dai': 1286, 'rie': 1287, 'shc': 1288, 'bridle': 1289, 'stable': 1290, 'oats': 1291, 'eat': 1292, 'soldier': 1293, 'aisy': 1294, 'arose': 1295, 'christmas': 1296, '1803': 1297, 'australia': 1298, 'marks': 1299, 'carried': 1300, 'rusty': 1301, 'iron': 1302, 'wains': 1303, 'mainsails': 1304, 'unfurled': 1305, 'curses': 1306, 'hurled': 1307, 'swell': 1308, 'moth': 1309, 'firelights': 1310, 'horses': 1311, 'rode': 1312, 'taking': 1313, 'hades': 1314, 'twilight': 1315, 'forty': 1316, 'slime': 1317, 'climate': 1318, 'bravery': 1319, 'ended': 1320, 'bond': 1321, 'rebel': 1322, 'iii': 1323, 'violin': 1324, 'clay': 1325, 'sooner': 1326, 'sport': 1327, 'colour': 1328, 'knows': 1329, 'earth': 1330, 'serve': 1331, 'clyde': 1332, 'mourn': 1333, 'weep': 1334, 'suffer': 1335, 'diamonds': 1336, 'queen': 1337, 'hung': 1338, 'tied': 1339, 'apprenticed': 1340, 'happiness': 1341, 'misfortune': 1342, 'follow': 1343, 'strolling': 1344, 'selling': 1345, 'bar': 1346, 'customer': 1347, 'slipped': 1348, 'luck': 1349, 'jury': 1350, 'trial': 1351, 'case': 1352, 'warning': 1353, 'liquor': 1354, 'porter': 1355, 'pleasures': 1356, 'fishing': 1357, 'farming': 1358, 'glens': 1359, 'softest': 1360, 'dripping': 1361, 'snare': 1362, 'lose': 1363, 'court': 1364, 'primrose': 1365, 'bee': 1366, 'hopeless': 1367, 'wonders': 1368, 'admiration': 1369, 'haunt': 1370, 'wherever': 1371, 'sands': 1372, 'purer': 1373, 'within': 1374, 'grieve': 1375, 'drumslieve': 1376, 'ballygrant': 1377, 'deepest': 1378, 'boatsman': 1379, 'ferry': 1380, 'childhood': 1381, 'reflections': 1382, 'boyhood': 1383, 'melting': 1384, 'roaming': 1385, 'reported': 1386, 'marble': 1387, 'stones': 1388, 'ink': 1389, 'support': 1390, 'drunk': 1391, 'seldom': 1392, 'sick': 1393, 'numbered': 1394, 'foam': 1395, 'compare': 1396, 'sights': 1397, 'coast': 1398, 'clare': 1399, 'kilkee': 1400, 'kilrush': 1401, 'watching': 1402, 'pheasants': 1403, 'homes': 1404, 'streams': 1405, 'dublins': 1406, 'cockles': 1407, 'mussels': 1408, 'fish': 1409, 'monger': 1410, 'ghost': 1411, 'wheels': 1412, 'eden': 1413, 'vanished': 1414, 'finea': 1415, 'halfway': 1416, 'cootehill': 1417, 'gruff': 1418, 'whispering': 1419, 'crow': 1420, 'newborn': 1421, 'babies': 1422, 'huff': 1423, 'start': 1424, 'sorrowful': 1425, 'squall': 1426, 'babys': 1427, 'toil': 1428, 'worn': 1429, 'fore': 1430, 'flute': 1431, 'yer': 1432, 'boot': 1433, 'magee': 1434, 'scruff': 1435, 'slanderin': 1436, 'marchin': 1437, 'assisted': 1438, 'drain': 1439, 'dudeen': 1440, 'puff': 1441, 'whisperings': 1442, 'barrin': 1443, 'chocolate': 1444, 'feegee': 1445, 'sort': 1446, 'moonshiny': 1447, 'stuff': 1448, 'addle': 1449, 'brain': 1450, 'ringin': 1451, 'glamour': 1452, 'gas': 1453, 'guff': 1454, 'whisper': 1455, 'oil': 1456, 'remarkable': 1457, 'policeman': 1458, 'bluff': 1459, 'maintain': 1460, 'guril': 1461, 'sic': 1462, 'passage': 1463, 'rough': 1464, 'borne': 1465, 'breeze': 1466, 'boundless': 1467, 'stupendous': 1468, 'roll': 1469, 'thundering': 1470, 'motion': 1471, 'mermaids': 1472, 'fierce': 1473, 'tempest': 1474, 'gathers': 1475, 'oneill': 1476, 'odonnell': 1477, 'lucan': 1478, 'oconnell': 1479, 'brian': 1480, 'drove': 1481, 'danes': 1482, 'patrick': 1483, 'vermin': 1484, 'whose': 1485, 'benburb': 1486, 'blackwater': 1487, 'owen': 1488, 'roe': 1489, 'munroe': 1490, 'lambs': 1491, 'skip': 1492, 'views': 1493, 'enchanting': 1494, 'rostrevor': 1495, 'groves': 1496, 'lakes': 1497, 'ride': 1498, 'tide': 1499, 'majestic': 1500, 'shannon': 1501, 'sail': 1502, 'loch': 1503, 'neagh': 1504, 'ross': 1505, 'gorey': 1506, 'saxon': 1507, 'tory': 1508, 'soil': 1509, 'sanctified': 1510, 'enemies': 1511, 'links': 1512, 'encumbered': 1513, 'resound': 1514, 'hosannahs': 1515, 'bide': 1516, 'hushed': 1517, 'lying': 1518, 'kneel': 1519, 'ave': 1520, 'tread': 1521, 'fail': 1522, 'simply': 1523, 'gasworks': 1524, 'croft': 1525, 'dreamed': 1526, 'canal': 1527, 'factory': 1528, 'clouds': 1529, 'drifting': 1530, 'prowling': 1531, 'beat': 1532, 'springs': 1533, 'siren': 1534, 'docks': 1535, 'train': 1536, 'smelled': 1537, 'smokey': 1538, 'sharp': 1539, 'axe': 1540, 'steel': 1541, 'tempered': 1542, 'chop': 1543, 't': 1544, 'agree': 1545, 'leaning': 1546, 'weirs': 1547, 'ray': 1548, 'glow': 1549, 'changeless': 1550, 'constant': 1551, 'bounding': 1552, 'castles': 1553, 'sacked': 1554, 'scattered': 1555, 'fixed': 1556, 'endearing': 1557, 'gifts': 1558, 'fading': 1559, 'wouldst': 1560, 'adored': 1561, 'loveliness': 1562, 'ruin': 1563, 'itself': 1564, 'verdantly': 1565, 'unprofaned': 1566, 'fervor': 1567, 'faith': 1568, 'forgets': 1569, 'sunflower': 1570, 'rag': 1571, 'games': 1572, 'hold': 1573, 'defend': 1574, 'veteran': 1575, 'volunteers': 1576, 'pat': 1577, 'pearse': 1578, 'clark': 1579, 'macdonagh': 1580, 'macdiarmada': 1581, 'mcbryde': 1582, 'james': 1583, 'connolly': 1584, 'placed': 1585, 'machine': 1586, 'ranting': 1587, 'hour': 1588, 'bullet': 1589, 'stuck': 1590, 'craw': 1591, 'poisoning': 1592, 'ceannt': 1593, 'lions': 1594, 'union': 1595, 'poured': 1596, 'dismay': 1597, 'horror': 1598, 'englishmen': 1599, 'khaki': 1600, 'renown': 1601, 'fame': 1602, 'forefathers': 1603, 'blaze': 1604, 'priests': 1605, 'offer': 1606, 'charmin': 1607, 'variety': 1608, 'renownd': 1609, 'learnin': 1610, 'piety': 1611, 'advance': 1612, 'widout': 1613, 'impropriety': 1614, 'flowr': 1615, 'cho': 1616, 'powrfulest': 1617, 'preacher': 1618, 'tenderest': 1619, 'teacher': 1620, 'kindliest': 1621, 'donegal': 1622, 'talk': 1623, 'provost': 1624, 'trinity': 1625, 'famous': 1626, 'greek': 1627, 'latinity': 1628, 'divils': 1629, 'divinity': 1630, 'd': 1631, 'likes': 1632, 'logic': 1633, 'mythology': 1634, 'thayology': 1635, 'conchology': 1636, 'sinners': 1637, 'wishful': 1638, 'childer': 1639, 'avick': 1640, 'gad': 1641, 'flock': 1642, 'grandest': 1643, 'control': 1644, 'checking': 1645, 'coaxin': 1646, 'onaisy': 1647, 'lifting': 1648, 'avoidin': 1649, 'frivolity': 1650, 'seasons': 1651, 'innocent': 1652, 'jollity': 1653, 'playboy': 1654, 'claim': 1655, 'equality': 1656, 'comicality': 1657, 'bishop': 1658, 'lave': 1659, 'gaiety': 1660, 'laity': 1661, 'clergy': 1662, 'jewels': 1663, 'plundering': 1664, 'pillage': 1665, 'starved': 1666, 'cries': 1667, 'thems': 1668, 'bondage': 1669, 'fourth': 1670, 'tabhair': 1671, 'dom': 1672, 'lámh': 1673, 'harmony': 1674, 'east': 1675, 'destroy': 1676, 'command': 1677, 'gesture': 1678, 'troubles': 1679, 'weak': 1680, 'peoples': 1681, 'creeds': 1682, 'lets': 1683, 'needs': 1684, 'passion': 1685, 'fashion': 1686, 'guide': 1687, 'share': 1688, 'sparkling': 1689, 'meeting': 1690, 'iull': 1691, 'contented': 1692, 'ache': 1693, 'painful': 1694, 'wrote': 1695, 'twisted': 1696, 'twined': 1697, 'cheek': 1698, 'bedim': 1699, 'holds': 1700, 'smiles': 1701, 'scarcely': 1702, 'darkning': 1703, 'beyond': 1704, 'yearn': 1705, 'laughs': 1706, 'humble': 1707, 'brightest': 1708, 'gleam': 1709, 'forgot': 1710, 'pulled': 1711, 'comb': 1712, 'counting': 1713, 'knock': 1714, 'murray': 1715, 'fellow': 1716, 'hail': 1717, 'tumblin': 1718, 'apple': 1719, 'pie': 1720, 'gets': 1721, 'doleful': 1722, 'enemy': 1723, 'nearly': 1724, 'slew': 1725, 'queer': 1726, 'mild': 1727, 'legs': 1728, 'indeed': 1729, 'island': 1730, 'sulloon': 1731, 'flesh': 1732, 'yere': 1733, 'armless': 1734, 'boneless': 1735, 'chickenless': 1736, 'egg': 1737, 'yell': 1738, 'bowl': 1739, 'rolling': 1740, 'swearing': 1741, 'rattled': 1742, 'saber': 1743, 'deceiver': 1744, 'rig': 1745, 'um': 1746, 'du': 1747, 'rum': 1748, 'jar': 1749, 'shinin': 1750, 'coins': 1751, 'promised': 1752, 'vowed': 1753, 'devils': 1754, 'awakened': 1755, 'six': 1756, 'guards': 1757, 'numbers': 1758, 'odd': 1759, 'flew': 1760, 'mistaken': 1761, 'mollys': 1762, 'robbing': 1763, 'sentry': 1764, 'sligo': 1765, 'fishin': 1766, 'bowlin': 1767, 'others': 1768, 'railroad': 1769, 'ties': 1770, 'crossings': 1771, 'swamps': 1772, 'elevations': 1773, 'resolved': 1774, 'sunset': 1775, 'higher': 1776, 'win': 1777, 'allegators': 1778, 'wood': 1779, 'treated': 1780, 'shoulders': 1781, 'paint': 1782, 'picture': 1783, 'vain': 1784, 'returned': 1785, 'cottage': 1786, 'sociable': 1787, 'foaming': 1788, 'n': 1789, 'jeremy': 1790, 'lanigan': 1791, 'battered': 1792, 'hadnt': 1793, 'pound': 1794, 'farm': 1795, 'acres': 1796, 'party': 1797, 'listen': 1798, 'glisten': 1799, 'rows': 1800, 'ructions': 1801, 'invitation': 1802, 'minute': 1803, 'bees': 1804, 'cask': 1805, 'judy': 1806, 'odaly': 1807, 'milliner': 1808, 'wink': 1809, 'peggy': 1810, 'mcgilligan': 1811, 'lashings': 1812, 'punch': 1813, 'cakes': 1814, 'bacon': 1815, 'tea': 1816, 'nolans': 1817, 'dolans': 1818, 'ogradys': 1819, 'sounded': 1820, 'taras': 1821, 'hall': 1822, 'nelly': 1823, 'gray': 1824, 'rat': 1825, 'catchers': 1826, 'doing': 1827, 'kinds': 1828, 'nonsensical': 1829, 'polkas': 1830, 'whirligig': 1831, 'julia': 1832, 'banished': 1833, 'nonsense': 1834, 'twist': 1835, 'jig': 1836, 'mavrone': 1837, 'mad': 1838, 'ceiling': 1839, 'brooks': 1840, 'academy': 1841, 'learning': 1842, 'learn': 1843, 'couples': 1844, 'groups': 1845, 'accident': 1846, 'happened': 1847, 'terrance': 1848, 'mccarthy': 1849, 'finnertys': 1850, 'hoops': 1851, 'cried': 1852, 'meelia': 1853, 'murther': 1854, 'gathered': 1855, 'carmody': 1856, 'further': 1857, 'satisfaction': 1858, 'midst': 1859, 'kerrigan': 1860, 'declared': 1861, 'painted': 1862, 'suppose': 1863, 'morgan': 1864, 'powerful': 1865, 'stretched': 1866, 'smashed': 1867, 'chaneys': 1868, 'runctions': 1869, 'lick': 1870, 'phelim': 1871, 'mchugh': 1872, 'replied': 1873, 'introduction': 1874, 'kicked': 1875, 'terrible': 1876, 'hullabaloo': 1877, 'piper': 1878, 'strangled': 1879, 'squeezed': 1880, 'bellows': 1881, 'chanters': 1882, 'entangled': 1883, 'gaily': 1884, 'mairis': 1885, 'hillways': 1886, 'myrtle': 1887, 'bracken': 1888, 'sheilings': 1889, 'sake': 1890, 'rowans': 1891, 'herring': 1892, 'meal': 1893, 'peat': 1894, 'creel': 1895, 'bairns': 1896, 'weel': 1897, 'toast': 1898, 'soar': 1899, 'blackbird': 1900, 'note': 1901, 'linnet': 1902, 'lure': 1903, 'cozy': 1904, 'catch': 1905, 'company': 1906, 'harm': 1907, 'wit': 1908, 'recall': 1909, 'leisure': 1910, 'awhile': 1911, 'sorely': 1912, 'ruby': 1913, 'enthralled': 1914, 'sorry': 1915, 'theyd': 1916, 'falls': 1917, 'lot': 1918, 'tuned': 1919, 'bough': 1920, 'cow': 1921, 'chanting': 1922, 'melodious': 1923, 'scarce': 1924, 'soothed': 1925, 'solace': 1926, 'courtesy': 1927, 'salute': 1928, 'amiable': 1929, 'captive': 1930, 'slave': 1931, 'future': 1932, 'banter': 1933, 'enamour': 1934, 'indies': 1935, 'afford': 1936, 'transparently': 1937, 'flame': 1938, 'add': 1939, 'fuel': 1940, 'grant': 1941, 'desire': 1942, 'expire': 1943, 'wealth': 1944, 'damer': 1945, 'african': 1946, 'devonshire': 1947, 'lamp': 1948, 'alladin': 1949, 'genie': 1950, 'also': 1951, 'withdraw': 1952, 'tease': 1953, 'single': 1954, 'airy': 1955, 'embarrass': 1956, 'besides': 1957, 'almanack': 1958, 'useless': 1959, 'date': 1960, 'ware': 1961, 'rate': 1962, 'fragrance': 1963, 'loses': 1964, 'consumed': 1965, 'october': 1966, 'knowing': 1967, 'steer': 1968, 'blast': 1969, 'danger': 1970, 'farthing': 1971, 'affection': 1972, 'enjoy': 1973, 'choose': 1974, 'killarneys': 1975, 'sister': 1976, 'pains': 1977, 'loss': 1978, 'tuam': 1979, 'saluted': 1980, 'drank': 1981, 'pint': 1982, 'smother': 1983, 'reap': 1984, 'cut': 1985, 'goblins': 1986, 'bought': 1987, 'brogues': 1988, 'rattling': 1989, 'bogs': 1990, 'frightning': 1991, 'dogs': 1992, 'hunt': 1993, 'hare': 1994, 'follol': 1995, 'rah': 1996, 'mullingar': 1997, 'rested': 1998, 'limbs': 1999, 'blithe': 2000, 'heartfrom': 2001, 'paddys': 2002, 'cure': 2003, 'lassies': 2004, 'laughing': 2005, 'curious': 2006, 'style': 2007, 'twould': 2008, 'bubblin': 2009, 'hired': 2010, 'wages': 2011, 'required': 2012, 'almost': 2013, 'deprived': 2014, 'stroll': 2015, 'quality': 2016, 'locality': 2017, 'something': 2018, 'wobblin': 2019, 'enquiring': 2020, 'rogue': 2021, 'brogue': 2022, 'wasnt': 2023, 'vogue': 2024, 'spirits': 2025, 'falling': 2026, 'jumped': 2027, 'aboard': 2028, 'pigs': 2029, 'rigs': 2030, 'jigs': 2031, 'bubbling': 2032, 'holyhead': 2033, 'wished': 2034, 'instead': 2035, 'bouys': 2036, 'liverpool': 2037, 'safely': 2038, 'fool': 2039, 'boil': 2040, 'temper': 2041, 'losing': 2042, 'abusing': 2043, 'shillelagh': 2044, 'nigh': 2045, 'hobble': 2046, 'load': 2047, 'hurray': 2048, 'joined': 2049, 'affray': 2050, 'quitely': 2051, 'cleared': 2052, 'host': 2053, 'march': 2054, 'faces': 2055, 'farmstead': 2056, 'fishers': 2057, 'ban': 2058, 'vengeance': 2059, 'hapless': 2060, 'about': 2061, 'hemp': 2062, 'rope': 2063, 'clung': 2064, 'grim': 2065, 'array': 2066, 'earnest': 2067, 'stalwart': 2068, 'stainless': 2069, 'banner': 2070, 'marching': 2071, 'torn': 2072, 'furious': 2073, 'odds': 2074, 'keen': 2075, 'toomebridge': 2076, 'treads': 2077, 'upwards': 2078, 'traveled': 2079, 'quarters': 2080, 'below': 2081, 'hogshead': 2082, 'stack': 2083, 'stagger': 2084, 'dig': 2085, 'hole': 2086, 'couple': 2087, 'scratch': 2088, 'consolation': 2089, 'tyrant': 2090, 'remorseless': 2091, 'foe': 2092, 'lift': 2093, 'stranded': 2094, 'prince': 2095, 'edward': 2096, 'coffee': 2097, 'trace': 2098, 'fiddlin': 2099, 'dime': 2100, 'shy': 2101, 'hello': 2102, 'wintry': 2103, 'yellow': 2104, 'somewhere': 2105, 'written': 2106, 'begin': 2107, 'tap': 2108, 'caught': 2109, 'leap': 2110, 'clumsy': 2111, 'graceful': 2112, 'fiddlers': 2113, 'everywhere': 2114, 'boots': 2115, 'laughtcr': 2116, 'suits': 2117, 'easter': 2118, 'gowns': 2119, 'sailors': 2120, 'pianos': 2121, 'setting': 2122, 'someones': 2123, 'hats': 2124, 'rack': 2125, 'chair': 2126, 'wooden': 2127, 'feels': 2128, 'touch': 2129, 'awaitin': 2130, 'thc': 2131, 'fiddles': 2132, 'closet': 2133, 'strings': 2134, 'tbe': 2135, 'covers': 2136, 'buttoned': 2137, 'sometimes': 2138, 'melody': 2139, 'passes': 2140, 'slight': 2141, 'lack': 2142, 'moved': 2143, 'homeward': 2144, 'swan': 2145, 'moves': 2146, 'goods': 2147, 'gear': 2148, 'din': 2149, 'rude': 2150, 'wherein': 2151, 'dwell': 2152, 'abandon': 2153, 'energy': 2154, 'blight': 2155, 'praties': 2156, 'sheep': 2157, 'cattle': 2158, 'taxes': 2159, 'unpaid': 2160, 'redeem': 2161, 'bleak': 2162, 'landlord': 2163, 'sheriff': 2164, 'spleen': 2165, 'heaved': 2166, 'sigh': 2167, 'bade': 2168, 'goodbye': 2169, 'stony': 2170, 'anguish': 2171, 'seeing': 2172, 'feeble': 2173, 'frame': 2174, 'wrapped': 2175, 'c�ta': 2176, 'm�r': 2177, 'unseen': 2178, 'stern': 2179, 'rally': 2180, 'cheer': 2181, 'revenge': 2182, 'waking': 2183, 'wisdom': 2184, 'dwelling': 2185, 'battleshield': 2186, 'dignity': 2187, 'shelter': 2188, 'heed': 2189, 'inheritance': 2190, 'heavem': 2191, 'heaven': 2192, 'victory': 2193, 'reach': 2194, 'whatever': 2195, 'befall': 2196, 'ruler': 2197, 'pleasant': 2198, 'rambling': 2199, 'board': 2200, 'followed': 2201, 'shortly': 2202, 'anchor': 2203, '23rd': 2204, 'lrelands': 2205, 'daughters': 2206, 'crowds': 2207, 'assembled': 2208, 'fulfill': 2209, 'jovial': 2210, 'conversations': 2211, 'neighbors': 2212, 'turning': 2213, 'tailor': 2214, 'quigley': 2215, 'bould': 2216, 'britches': 2217, 'lived': 2218, 'flying': 2219, 'dove': 2220, 'hiii': 2221, 'dreamt': 2222, 'joking': 2223, 'manys': 2224, 'cock': 2225, 'shrill': 2226, 'awoke': 2227, 'california': 2228, 'miles': 2229, 'banbridge': 2230, 'july': 2231, 'boreen': 2232, 'sheen': 2233, 'coaxing': 2234, 'elf': 2235, 'shake': 2236, 'bantry': 2237, 'onward': 2238, 'sped': 2239, 'gazed': 2240, 'passerby': 2241, 'gem': 2242, 'irelands': 2243, 'travelled': 2244, 'hit': 2245, 'career': 2246, 'square': 2247, 'surrendered': 2248, 'tenant': 2249, 'shawl': 2250, 'gown': 2251, 'crossroads': 2252, 'dress': 2253, 'try': 2254, 'sheeps': 2255, 'deludhering': 2256, 'yoke': 2257, 'rust': 2258, 'plow': 2259, 'fireside': 2260, 'sits': 2261, 'whistle': 2262, 'changing': 2263, 'fright': 2264, 'downfall': 2265, 'cornwall': 2266, 'parlour': 2267, 'passing': 2268, 'william': 2269, 'betray': 2270, 'guinea': 2271, 'walking': 2272, 'mounted': 2273, 'platform': 2274, 'deny': 2275, 'walked': 2276, 'margin': 2277, 'lough': 2278, 'leane': 2279, 'bloomed': 2280, 'whom': 2281, 'cap': 2282, 'cloak': 2283, 'glossy': 2284, 'pail': 2285, 'palm': 2286, 'venus': 2287, 'bank': 2288, 'travelians': 2289, 'babes': 2290, 'freebirds': 2291, 'grew': 2292, 'matters': 2293, 'famine': 2294, 'rebelled': 2295, 'windswept': 2296, 'harbour': 2297, 'botany': 2298, 'whilst': 2299, 'wan': 2300, 'cloud': 2301, 'shannons': 2302, 'returnd': 2303, 'doubts': 2304, 'fears': 2305, 'aching': 2306, 'seemd': 2307, 'mingling': 2308, 'flood': 2309, 'path': 2310, 'wrath': 2311, 'lamenting': 2312, 'sudden': 2313, 'kissd': 2314, 'showrs': 2315, 'flowing': 2316, 'laughd': 2317, 'beam': 2318, 'soared': 2319, 'aloft': 2320, 'phantom': 2321, 'outspread': 2322, 'throbbing': 2323, 'hid': 2324, 'treasures': 2325, 'pots': 2326, 'tin': 2327, 'cans': 2328, 'mash': 2329, 'bran': 2330, 'barney': 2331, 'peeled': 2332, 'searching': 2333, 'connemara': 2334, 'butcher': 2335, 'quart': 2336, 'bottle': 2337, 'help': 2338, 'gate': 2339, 'glory': 2340, 'lane': 2341, 'village': 2342, 'church': 2343, 'spire': 2344, 'graveyard': 2345, 'baby': 2346, 'blessing': 2347, 'hoping': 2348, 'trust': 2349, 'strength': 2350, 'thank': 2351, 'bidding': 2352, 'bread': 2353, 'shines': 2354, 'fifty': 2355, 'often': 2356, 'shut': 2357, 'frisky': 2358, 'pig': 2359, 'whisky': 2360, 'uncle': 2361, 'enlisted': 2362, 'trudged': 2363, 'bosom': 2364, 'daisy': 2365, 'drubbing': 2366, 'shirts': 2367, 'battle': 2368, 'blows': 2369, 'pate': 2370, 'bothered': 2371, 'rarely': 2372, 'dropped': 2373, 'honest': 2374, 'thinks': 2375, 'eight': 2376, 'score': 2377, 'basin': 2378, 'zoo': 2379, 'everybody': 2380, 'calls': 2381, 'trades': 2382, 'dinner': 2383, 'slip': 2384, 'corner': 2385, 'barn': 2386, 'currabawn': 2387, 'shocking': 2388, 'wet': 2389, 'raindrops': 2390, 'rats': 2391, 'peek': 2392, 'waken': 2393, 'spotted': 2394, 'apron': 2395, 'calico': 2396, 'blouse': 2397, 'frighten': 2398, 'afraid': 2399, 'flaxen': 2400, 'haired': 2401, 'rags': 2402, 'tags': 2403, 'leggins': 2404, 'collar': 2405, 'tie': 2406, 'goggles': 2407, 'fashioned': 2408, 'bag': 2409, 'bulging': 2410, 'sack': 2411, 'peeping': 2412, 'skin': 2413, 'rink': 2414, 'doodle': 2415, 'getting': 2416, 'raked': 2417, 'gladness': 2418, 'tuning': 2419, 'fills': 2420, 'eily': 2421, 'prouder': 2422, 'thady': 2423, 'boldly': 2424, 'lasses': 2425, 'fled': 2426, 'silent': 2427, 'glad': 2428, 'echo': 2429, 'companions': 2430, 'soars': 2431, 'enchanted': 2432, 'granted': 2433, 'adoration': 2434, 'gives': 2435, 'joyous': 2436, 'elation': 2437, 'covered': 2438, 'winter': 2439, 'riding': 2440, 'cherry': 2441, 'coal': 2442, 'falter': 2443, 'bowed': 2444, 'bonnet': 2445, 'courteous': 2446, 'looks': 2447, 'engaging': 2448, 'sell': 2449, 'purse': 2450, 'yearly': 2451, 'need': 2452, 'market': 2453, 'gain': 2454, 'dearly': 2455, 'tarry': 2456, 'although': 2457, 'parlay': 2458, 'ranks': 2459, 'girded': 2460, 'slung': 2461, 'warrior': 2462, 'bard': 2463, 'betrays': 2464, 'rights': 2465, 'faithful': 2466, 'chords': 2467, 'asunder': 2468, 'sully': 2469, 'bravry': 2470, 'londons': 2471, 'sight': 2472, 'workin': 2473, 'sow': 2474, 'wheat': 2475, 'gangs': 2476, 'sweep': 2477, 'expressed': 2478, 'london': 2479, 'top': 2480, 'dresses': 2481, 'bath': 2482, 'startin': 2483, 'fashions': 2484, 'mccree': 2485, 'nature': 2486, 'designed': 2487, 'complexions': 2488, 'cream': 2489, 'regard': 2490, 'sip': 2491, 'colors': 2492, 'wait': 2493, 'waitin': 2494, 'sweeps': 2495, 'beauing': 2496, 'belling': 2497, 'windows': 2498, 'cursing': 2499, 'faster': 2500, 'waiters': 2501, 'bailiffs': 2502, 'duns': 2503, 'bacchus': 2504, 'begotten': 2505, 'politicians': 2506, 'funds': 2507, 'dadda': 2508, 'living': 2509, 'drives': 2510, 'having': 2511, 'racking': 2512, 'tenants': 2513, 'stewards': 2514, 'teasing': 2515, 'raising': 2516, 'wishing': 2517, 'sunny': 2518, 'doves': 2519, 'coo': 2520, 'neath': 2521, 'sunbeam': 2522, 'robin': 2523, 'waters': 2524, 'larks': 2525, 'join': 2526, 'breaks': 2527, 'oftimes': 2528, 'lilies': 2529, 'declining': 2530, 'vale': 2531, 'shades': 2532, 'mantle': 2533, 'spreading': 2534, 'listening': 2535, 'shedding': 2536, 'beginning': 2537, 'spinning': 2538, 'blind': 2539, 'drowsily': 2540, 'knitting': 2541, 'cheerily': 2542, 'noiselessly': 2543, 'whirring': 2544, 'foots': 2545, 'stirring': 2546, 'sprightly': 2547, 'chara': 2548, 'tapping': 2549, 'ivy': 2550, 'flapping': 2551, 'somebody': 2552, 'sighing': 2553, 'autumn': 2554, 'noise': 2555, 'chirping': 2556, 'holly': 2557, 'shoving': 2558, 'wrong': 2559, 'coolin': 2560, 'casement': 2561, 'rove': 2562, 'moons': 2563, 'brightly': 2564, 'shakes': 2565, 'lays': 2566, 'longs': 2567, 'lingers': 2568, 'glance': 2569, 'puts': 2570, 'lazily': 2571, 'easily': 2572, 'lowly': 2573, 'reels': 2574, 'noiseless': 2575, 'leaps': 2576, 'ere': 2577, 'lovers': 2578, 'roved': 2579, 'verdant': 2580, 'braes': 2581, 'skreen': 2582, 'countrie': 2583, 'foreign': 2584, 'strand': 2585, 'dewy': 2586, 'climb': 2587, 'rob': 2588, 'boat': 2589, 'sails': 2590, 'loaded': 2591, 'sink': 2592, 'leaned': 2593, 'oak': 2594, 'trusty': 2595, 'false': 2596, 'reached': 2597, 'pricked': 2598, 'waxes': 2599, 'fades': 2600, 'wholl': 2601, 'cockle': 2602, 'gloom': 2603, 'news': 2604, 'forbid': 2605, 'patricks': 2606, 'napper': 2607, 'tandy': 2608, 'hows': 2609, 'distressful': 2610, 'englands': 2611, 'remind': 2612, 'pull': 2613, 'throw': 2614, 'sod': 2615, 'root': 2616, 'underfoot': 2617, 'laws': 2618, 'blades': 2619, 'growin': 2620, 'dare': 2621, 'show': 2622, 'caubeen': 2623, 'year': 2624, 'returning': 2625, 'store': 2626, 'ale': 2627, 'frequent': 2628, 'landlady': 2629, 'credit': 2630, 'custom': 2631, 'sovereigns': 2632, 'landladys': 2633, 'wines': 2634, 'confess': 2635, 'pardon': 2636, 'prodigal': 2637, 'caress': 2638, 'forgive': 2639, 'ofttimes': 2640, 'wondering': 2641, 'powr': 2642, 'beguile': 2643, 'teardrop': 2644, 'lilting': 2645, 'laughters': 2646, 'twinkle': 2647, 'lilt': 2648, 'seems': 2649, 'linnets': 2650, 'real': 2651, 'regret': 2652, 'throughout': 2653, 'youths': 2654, 'chance': 2655, 'spied': 2656, 'receiver': 2657, 'counted': 2658, 'penny': 2659, 'bu': 2660, 'rungum': 2661, 'chamber': 2662, 'course': 2663, 'charges': 2664, 'filled': 2665, 'ready': 2666, 'footmen': 2667, 'likewise': 2668, 'draw': 2669, 'pistol': 2670, 'couldnt': 2671, 'shoot': 2672, 'robbin': 2673, 'jailer': 2674, 'tight': 2675, 'fisted': 2676, 'army': 2677, 'stationed': 2678, 'cork': 2679, 'roamin': 2680, 'swear': 2681, 'treat': 2682, 'sportin': 2683, 'hurley': 2684, 'bollin': 2685, 'maids': 2686, 'summertime': 2687, 'pluck': 2688, 'yon': 2689}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaLZt9eaokYF",
        "colab_type": "code",
        "outputId": "a22828a9-c3d1-416e-bfc0-f2a742fea0e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "sequences = np.array(tokenizer.texts_to_sequences(data))\n",
        "print(sequences[0])\n",
        "padded = pad_sequences(sequences,truncating='post',padding='pre')\n",
        "print(padded[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[51, 12, 96, 1217, 48, 2, 69]\n",
            "[   0    0    0    0    0    0    0    0    0   51   12   96 1217   48\n",
            "    2   69]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19Xy9YdXvfe1",
        "colab_type": "code",
        "outputId": "4b8e9398-8265-47b2-9bf2-23a1888d656a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "padded.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1692, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLmnC68_v8qR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq = padded[:,:-1]\n",
        "labels = padded[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Omr_7Ex8wtNl",
        "colab_type": "code",
        "outputId": "be124c3d-166e-46d1-b3c1-178064886c66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(f'{seq[0]}..........{labels[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0   51   12   96 1217   48\n",
            "    2]..........69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THjLnxJm2DPD",
        "colab_type": "code",
        "outputId": "923b7ce5-e2ef-4d23-9882-9b013fec8324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seq.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1692, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF7Cga9d2XTV",
        "colab_type": "code",
        "outputId": "f098acd6-3806-4768-e391-5c601decd4cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1692,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mGqL6KZ2Zk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encode the output variable\n",
        "labels = np_utils.to_categorical(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHGoGh813znd",
        "colab_type": "code",
        "outputId": "c529a420-5980-4dd1-85b4-49bcf563c07e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1692, 2686)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1p6p_CY44aU",
        "colab_type": "code",
        "outputId": "2580923a-3b00-4d5b-fb5b-7544a3859117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(tokenizer.word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2689"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2nfj3Dw31t0",
        "colab_type": "code",
        "outputId": "f28880cd-187a-4a88-8188-1d7eae62f6a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "#model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(2690,64))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150)))\n",
        "model.add(tf.keras.layers.Dropout(0.1))\n",
        "model.add(tf.keras.layers.Dense(2686,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 64)          172160    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 300)               258000    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2686)              808486    \n",
            "=================================================================\n",
            "Total params: 1,238,646\n",
            "Trainable params: 1,238,646\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI03nbPR5mGl",
        "colab_type": "code",
        "outputId": "b4b10ac1-ceb5-40ba-a489-df935ca17156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(seq, labels, epochs=60, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1692 samples\n",
            "Epoch 1/60\n",
            "1692/1692 [==============================] - 2s 1ms/sample - loss: 7.6127 - accuracy: 0.0195\n",
            "Epoch 2/60\n",
            "1692/1692 [==============================] - 1s 614us/sample - loss: 6.6885 - accuracy: 0.0236\n",
            "Epoch 3/60\n",
            "1692/1692 [==============================] - 1s 627us/sample - loss: 6.4461 - accuracy: 0.0236\n",
            "Epoch 4/60\n",
            "1692/1692 [==============================] - 1s 639us/sample - loss: 6.2313 - accuracy: 0.0236\n",
            "Epoch 5/60\n",
            "1692/1692 [==============================] - 1s 629us/sample - loss: 6.0880 - accuracy: 0.0242\n",
            "Epoch 6/60\n",
            "1692/1692 [==============================] - 1s 628us/sample - loss: 5.9623 - accuracy: 0.0242\n",
            "Epoch 7/60\n",
            "1692/1692 [==============================] - 1s 628us/sample - loss: 5.8816 - accuracy: 0.0254\n",
            "Epoch 8/60\n",
            "1692/1692 [==============================] - 1s 626us/sample - loss: 5.8014 - accuracy: 0.0254\n",
            "Epoch 9/60\n",
            "1692/1692 [==============================] - 1s 639us/sample - loss: 5.7365 - accuracy: 0.0260\n",
            "Epoch 10/60\n",
            "1692/1692 [==============================] - 1s 631us/sample - loss: 5.6586 - accuracy: 0.0296\n",
            "Epoch 11/60\n",
            "1692/1692 [==============================] - 1s 621us/sample - loss: 5.5213 - accuracy: 0.0355\n",
            "Epoch 12/60\n",
            "1692/1692 [==============================] - 1s 642us/sample - loss: 5.4453 - accuracy: 0.0461\n",
            "Epoch 13/60\n",
            "1692/1692 [==============================] - 1s 622us/sample - loss: 5.3572 - accuracy: 0.0473\n",
            "Epoch 14/60\n",
            "1692/1692 [==============================] - 1s 631us/sample - loss: 5.1927 - accuracy: 0.0550\n",
            "Epoch 15/60\n",
            "1692/1692 [==============================] - 1s 638us/sample - loss: 4.9800 - accuracy: 0.0656\n",
            "Epoch 16/60\n",
            "1692/1692 [==============================] - 1s 638us/sample - loss: 4.7193 - accuracy: 0.0851\n",
            "Epoch 17/60\n",
            "1692/1692 [==============================] - 1s 638us/sample - loss: 4.3955 - accuracy: 0.1087\n",
            "Epoch 18/60\n",
            "1692/1692 [==============================] - 1s 654us/sample - loss: 4.1076 - accuracy: 0.1359\n",
            "Epoch 19/60\n",
            "1692/1692 [==============================] - 1s 691us/sample - loss: 3.8031 - accuracy: 0.1667\n",
            "Epoch 20/60\n",
            "1692/1692 [==============================] - 1s 630us/sample - loss: 3.4671 - accuracy: 0.2175\n",
            "Epoch 21/60\n",
            "1692/1692 [==============================] - 1s 630us/sample - loss: 3.1313 - accuracy: 0.2819\n",
            "Epoch 22/60\n",
            "1692/1692 [==============================] - 1s 631us/sample - loss: 2.8432 - accuracy: 0.3410\n",
            "Epoch 23/60\n",
            "1692/1692 [==============================] - 1s 626us/sample - loss: 2.6286 - accuracy: 0.4001\n",
            "Epoch 24/60\n",
            "1692/1692 [==============================] - 1s 645us/sample - loss: 2.4473 - accuracy: 0.4468\n",
            "Epoch 25/60\n",
            "1692/1692 [==============================] - 1s 650us/sample - loss: 2.1726 - accuracy: 0.5177\n",
            "Epoch 26/60\n",
            "1692/1692 [==============================] - 1s 613us/sample - loss: 1.8719 - accuracy: 0.6318\n",
            "Epoch 27/60\n",
            "1692/1692 [==============================] - 1s 616us/sample - loss: 1.6241 - accuracy: 0.7134\n",
            "Epoch 28/60\n",
            "1692/1692 [==============================] - 1s 624us/sample - loss: 1.4090 - accuracy: 0.7701\n",
            "Epoch 29/60\n",
            "1692/1692 [==============================] - 1s 620us/sample - loss: 1.2604 - accuracy: 0.7920\n",
            "Epoch 30/60\n",
            "1692/1692 [==============================] - 1s 623us/sample - loss: 1.1161 - accuracy: 0.8322\n",
            "Epoch 31/60\n",
            "1692/1692 [==============================] - 1s 621us/sample - loss: 0.9598 - accuracy: 0.8658\n",
            "Epoch 32/60\n",
            "1692/1692 [==============================] - 1s 614us/sample - loss: 0.8353 - accuracy: 0.9001\n",
            "Epoch 33/60\n",
            "1692/1692 [==============================] - 1s 612us/sample - loss: 0.7296 - accuracy: 0.9090\n",
            "Epoch 34/60\n",
            "1692/1692 [==============================] - 1s 613us/sample - loss: 0.6260 - accuracy: 0.9362\n",
            "Epoch 35/60\n",
            "1692/1692 [==============================] - 1s 621us/sample - loss: 0.5333 - accuracy: 0.9527\n",
            "Epoch 36/60\n",
            "1692/1692 [==============================] - 1s 622us/sample - loss: 0.4650 - accuracy: 0.9592\n",
            "Epoch 37/60\n",
            "1692/1692 [==============================] - 1s 627us/sample - loss: 0.3944 - accuracy: 0.9716\n",
            "Epoch 38/60\n",
            "1692/1692 [==============================] - 1s 621us/sample - loss: 0.3397 - accuracy: 0.9781\n",
            "Epoch 39/60\n",
            "1692/1692 [==============================] - 1s 619us/sample - loss: 0.2989 - accuracy: 0.9817\n",
            "Epoch 40/60\n",
            "1692/1692 [==============================] - 1s 626us/sample - loss: 0.2538 - accuracy: 0.9882\n",
            "Epoch 41/60\n",
            "1692/1692 [==============================] - 1s 613us/sample - loss: 0.2118 - accuracy: 0.9935\n",
            "Epoch 42/60\n",
            "1692/1692 [==============================] - 1s 620us/sample - loss: 0.1845 - accuracy: 0.9935\n",
            "Epoch 43/60\n",
            "1692/1692 [==============================] - 1s 624us/sample - loss: 0.1643 - accuracy: 0.9959\n",
            "Epoch 44/60\n",
            "1692/1692 [==============================] - 1s 623us/sample - loss: 0.1465 - accuracy: 0.9970\n",
            "Epoch 45/60\n",
            "1692/1692 [==============================] - 1s 622us/sample - loss: 0.1319 - accuracy: 0.9976\n",
            "Epoch 46/60\n",
            "1692/1692 [==============================] - 1s 629us/sample - loss: 0.1211 - accuracy: 0.9982\n",
            "Epoch 47/60\n",
            "1692/1692 [==============================] - 1s 620us/sample - loss: 0.1115 - accuracy: 0.9970\n",
            "Epoch 48/60\n",
            "1692/1692 [==============================] - 1s 620us/sample - loss: 0.1033 - accuracy: 0.9970\n",
            "Epoch 49/60\n",
            "1692/1692 [==============================] - 1s 619us/sample - loss: 0.0866 - accuracy: 0.9982\n",
            "Epoch 50/60\n",
            "1692/1692 [==============================] - 1s 646us/sample - loss: 0.0810 - accuracy: 0.9976\n",
            "Epoch 51/60\n",
            "1692/1692 [==============================] - 1s 659us/sample - loss: 0.0726 - accuracy: 0.9988\n",
            "Epoch 52/60\n",
            "1692/1692 [==============================] - 1s 622us/sample - loss: 0.0675 - accuracy: 0.9988\n",
            "Epoch 53/60\n",
            "1692/1692 [==============================] - 1s 614us/sample - loss: 0.0622 - accuracy: 0.9976\n",
            "Epoch 54/60\n",
            "1692/1692 [==============================] - 1s 615us/sample - loss: 0.0568 - accuracy: 0.9982\n",
            "Epoch 55/60\n",
            "1692/1692 [==============================] - 1s 621us/sample - loss: 0.0569 - accuracy: 0.9976\n",
            "Epoch 56/60\n",
            "1692/1692 [==============================] - 1s 628us/sample - loss: 0.0551 - accuracy: 0.9970\n",
            "Epoch 57/60\n",
            "1692/1692 [==============================] - 1s 625us/sample - loss: 0.0485 - accuracy: 0.9982\n",
            "Epoch 58/60\n",
            "1692/1692 [==============================] - 1s 616us/sample - loss: 0.0471 - accuracy: 0.9982\n",
            "Epoch 59/60\n",
            "1692/1692 [==============================] - 1s 624us/sample - loss: 0.0433 - accuracy: 0.9982\n",
            "Epoch 60/60\n",
            "1692/1692 [==============================] - 1s 617us/sample - loss: 0.0412 - accuracy: 0.9982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcc5c8019e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaYZLTh1Bsbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_dic = {value:key for key,value in tokenizer.word_index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JRVYx2y6vX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(seed,num_sent):\n",
        "  for _ in range(num_sent):\n",
        "    token_list = tokenizer.texts_to_sequences([seed])[0]\n",
        "    token_list = pad_sequences([token_list],maxlen=15,padding='pre')\n",
        "    predicted = model.predict_classes(token_list,verbose=0)[0]\n",
        "    #print(f'predicted = {predicted}')\n",
        "    output_word = \"\"\n",
        "    if predicted in reverse_dic:\n",
        "      output_word = reverse_dic[predicted]\n",
        "    seed += \" \" + output_word\n",
        "  return seed\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R70WRtuFOio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_text = generate_text(\"that is the way i like\",100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIOq8C-tFam_",
        "colab_type": "code",
        "outputId": "e24ecc7c-1a18-4052-e694-d1ed0e23f987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "generated_text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'that is the way i like athy malone lass mooncoin taken married bubblin here eyes eyes eyes eyes frame man year tears locality jewel runaway barley yet eyes eyes frisky sweet rest rest rest rest eye eyes after fulfill kilkenny after show bran caubeen entwine been moving man laughing laughing year eye eyes eyes eyes eyes eyes eyes eyes eyes frame tie rest sod pride year year hill derry craw wobblin wobblin caubeen caubeen molly grey ra sent sent sent sent sent trace boyne frame rocky ground sod sod pride unseen stick sod pride pride canal canal play wonder unseen play sends grey play unseen tory'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36zlpmVhahK6",
        "colab_type": "text"
      },
      "source": [
        "## character level generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u08nadmrU4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = open('irish-lyrics-eof.txt', 'rb').read().decode(encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffS_q5Eiru10",
        "colab_type": "code",
        "outputId": "c29a3ad5-3f41-4fd0-ab01-6128190757ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "corpus[0:100]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Come all ye maidens young and fair\\nAnd you that are blooming in your prime\\nAlways beware and keep yo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onIfNIl9eD35",
        "colab_type": "code",
        "outputId": "7d86ba55-c7b2-4b38-800c-d8762b690689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "char_tokenizer = Tokenizer(char_level=True)\n",
        "char_tokenizer.fit_on_texts(corpus)\n",
        "print(char_tokenizer.word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 1, 'e': 2, 'a': 3, 'o': 4, 't': 5, 'n': 6, 'i': 7, 'r': 8, 'h': 9, 's': 10, 'l': 11, 'd': 12, '\\n': 13, 'y': 14, 'm': 15, 'w': 16, 'u': 17, 'g': 18, 'f': 19, 'b': 20, 'c': 21, ',': 22, 'p': 23, 'v': 24, 'k': 25, '.': 26, 'j': 27, '-': 28, '!': 29, ';': 30, 'q': 31, 'x': 32, '?': 33, 'z': 34, ':': 35, 'í': 36, 'ú': 37, 'ó': 38, '3': 39, '(': 40, ')': 41, '�': 42, '1': 43, '8': 44, '0': 45, 'á': 46, '&': 47, '2': 48}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFwZ84SXZlST",
        "colab_type": "code",
        "outputId": "cdfd9e4b-ce31-4e65-af6d-b5e897eb6e65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(char_tokenizer.word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOO6-G42el9m",
        "colab_type": "code",
        "outputId": "0ae8cd1a-59d2-4045-8c24-92d25da2f836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "char_sequences = np.array(char_tokenizer.texts_to_sequences(corpus))\n",
        "print(char_sequences[0:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[21]\n",
            " [ 4]\n",
            " [15]\n",
            " [ 2]\n",
            " [ 1]\n",
            " [ 3]\n",
            " [11]\n",
            " [11]\n",
            " [ 1]\n",
            " [14]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N73iJgwlfnHb",
        "colab_type": "code",
        "outputId": "4a9371d4-2255-4992-b6e8-6f82efbce62f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(corpus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68953"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEAyQnwnppmz",
        "colab_type": "code",
        "outputId": "97fea637-fe02-4d63-9de8-10f21d26eb85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "slce = char_sequences[0:12]\n",
        "type(slce)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_23tGROv2CF",
        "colab_type": "code",
        "outputId": "5cb59f51-d625-4a09-a04f-d51c2f0706ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "slce.T[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([21,  4, 15,  2,  1,  3, 11, 11,  1, 14,  2,  1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYbMTZtC0XVq",
        "colab_type": "code",
        "outputId": "d0b06a52-7610-421b-ce81-a8321803f697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(char_sequences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68953"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEN8wWPFv_cS",
        "colab_type": "code",
        "outputId": "c6985a47-1010-4764-c569-90961c4a7758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "seq_list = np.empty((0,90), int)\n",
        "for i in range(0,(len(corpus)//90)):\n",
        "  k = i*90\n",
        "  seq_list = np.append(seq_list,[char_sequences[k:k+90].T[0]],axis=0)\n",
        "print(seq_list[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[21  4 15  2  1  3 11 11  1 14  2  1 15  3  7 12  2  6 10  1 14  4 17  6\n",
            " 18  1  3  6 12  1 19  3  7  8 13  3  6 12  1 14  4 17  1  5  9  3  5  1\n",
            "  3  8  2  1 20 11  4  4 15  7  6 18  1  7  6  1 14  4 17  8  1 23  8  7\n",
            " 15  2 13  3 11 16  3 14 10  1 20  2 16  3  8  2  1  3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzqGTKml1URB",
        "colab_type": "code",
        "outputId": "63fda88e-e650-48f1-e910-eb6eb115aec0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seq_list.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(766, 90)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umQEgi5n2Ru5",
        "colab_type": "code",
        "outputId": "4ab423e4-d296-4126-ce82-74b89fc59124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "inp = seq_list[:,:-1]\n",
        "oup = seq_list[:,1:]\n",
        "print(f'input seq = {inp[0]}')\n",
        "print(f'output seq = {oup[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input seq = [21  4 15  2  1  3 11 11  1 14  2  1 15  3  7 12  2  6 10  1 14  4 17  6\n",
            " 18  1  3  6 12  1 19  3  7  8 13  3  6 12  1 14  4 17  1  5  9  3  5  1\n",
            "  3  8  2  1 20 11  4  4 15  7  6 18  1  7  6  1 14  4 17  8  1 23  8  7\n",
            " 15  2 13  3 11 16  3 14 10  1 20  2 16  3  8  2  1]\n",
            "output seq = [ 4 15  2  1  3 11 11  1 14  2  1 15  3  7 12  2  6 10  1 14  4 17  6 18\n",
            "  1  3  6 12  1 19  3  7  8 13  3  6 12  1 14  4 17  1  5  9  3  5  1  3\n",
            "  8  2  1 20 11  4  4 15  7  6 18  1  7  6  1 14  4 17  8  1 23  8  7 15\n",
            "  2 13  3 11 16  3 14 10  1 20  2 16  3  8  2  1  3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVME4u_xkMNt",
        "colab_type": "code",
        "outputId": "01cdaa97-69fe-4b91-9d2d-c0b9e9a9045b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(f'input shape = {inp.shape}')\n",
        "print(f'output shape = {oup.shape}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape = (766, 89)\n",
            "output shape = (766, 89)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwFg_PaKZSm4",
        "colab_type": "code",
        "outputId": "0fe045ef-cbdb-46ab-c156-cd58d202851c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = np_utils.to_categorical(oup)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(766, 89, 49)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9-s1pxakEc2",
        "colab_type": "code",
        "outputId": "4ac439f0-1887-463a-ff20-f7d866e6993c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(49,64))\n",
        "model.add(tf.keras.layers.LSTM(150,return_sequences=True))\n",
        "model.add(tf.keras.layers.Dropout(0.1))\n",
        "model.add(tf.keras.layers.Dense(49,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 64)          3136      \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 150)         129000    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 150)         0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, None, 49)          7399      \n",
            "=================================================================\n",
            "Total params: 139,535\n",
            "Trainable params: 139,535\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K87ao1K0lfNs",
        "colab_type": "code",
        "outputId": "2c4f34c0-1544-44d2-cc1f-d4d4336b9f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(inp, y, epochs=1000, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0811 07:55:41.263885 140718941046656 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 766 samples\n",
            "Epoch 1/1000\n",
            "766/766 [==============================] - 4s 5ms/sample - loss: 3.4234 - accuracy: 0.1567\n",
            "Epoch 2/1000\n",
            "766/766 [==============================] - 1s 915us/sample - loss: 3.0121 - accuracy: 0.1716\n",
            "Epoch 3/1000\n",
            "766/766 [==============================] - 1s 885us/sample - loss: 2.9687 - accuracy: 0.1742\n",
            "Epoch 4/1000\n",
            "766/766 [==============================] - 1s 881us/sample - loss: 2.9093 - accuracy: 0.1827\n",
            "Epoch 5/1000\n",
            "766/766 [==============================] - 1s 893us/sample - loss: 2.8039 - accuracy: 0.2268\n",
            "Epoch 6/1000\n",
            "766/766 [==============================] - 1s 898us/sample - loss: 2.6679 - accuracy: 0.2717\n",
            "Epoch 7/1000\n",
            "766/766 [==============================] - 1s 881us/sample - loss: 2.5496 - accuracy: 0.2910\n",
            "Epoch 8/1000\n",
            "766/766 [==============================] - 1s 894us/sample - loss: 2.4586 - accuracy: 0.3054\n",
            "Epoch 9/1000\n",
            "766/766 [==============================] - 1s 882us/sample - loss: 2.3968 - accuracy: 0.3159\n",
            "Epoch 10/1000\n",
            "766/766 [==============================] - 1s 885us/sample - loss: 2.3574 - accuracy: 0.3203\n",
            "Epoch 11/1000\n",
            "766/766 [==============================] - 1s 864us/sample - loss: 2.3285 - accuracy: 0.3248\n",
            "Epoch 12/1000\n",
            "766/766 [==============================] - 1s 882us/sample - loss: 2.3007 - accuracy: 0.3320\n",
            "Epoch 13/1000\n",
            "766/766 [==============================] - 1s 860us/sample - loss: 2.2743 - accuracy: 0.3337\n",
            "Epoch 14/1000\n",
            "766/766 [==============================] - 1s 878us/sample - loss: 2.2504 - accuracy: 0.3400\n",
            "Epoch 15/1000\n",
            "766/766 [==============================] - 1s 867us/sample - loss: 2.2262 - accuracy: 0.3450\n",
            "Epoch 16/1000\n",
            "766/766 [==============================] - 1s 866us/sample - loss: 2.2044 - accuracy: 0.3486\n",
            "Epoch 17/1000\n",
            "766/766 [==============================] - 1s 864us/sample - loss: 2.1854 - accuracy: 0.3536\n",
            "Epoch 18/1000\n",
            "766/766 [==============================] - 1s 886us/sample - loss: 2.1662 - accuracy: 0.3588\n",
            "Epoch 19/1000\n",
            "766/766 [==============================] - 1s 862us/sample - loss: 2.1474 - accuracy: 0.3632\n",
            "Epoch 20/1000\n",
            "766/766 [==============================] - 1s 877us/sample - loss: 2.1313 - accuracy: 0.3663\n",
            "Epoch 21/1000\n",
            "766/766 [==============================] - 1s 871us/sample - loss: 2.1158 - accuracy: 0.3713\n",
            "Epoch 22/1000\n",
            "766/766 [==============================] - 1s 875us/sample - loss: 2.1010 - accuracy: 0.3742\n",
            "Epoch 23/1000\n",
            "766/766 [==============================] - 1s 890us/sample - loss: 2.0857 - accuracy: 0.3776\n",
            "Epoch 24/1000\n",
            "766/766 [==============================] - 1s 885us/sample - loss: 2.0740 - accuracy: 0.3809\n",
            "Epoch 25/1000\n",
            "766/766 [==============================] - 1s 883us/sample - loss: 2.0596 - accuracy: 0.3854\n",
            "Epoch 26/1000\n",
            "766/766 [==============================] - 1s 884us/sample - loss: 2.0473 - accuracy: 0.3885\n",
            "Epoch 27/1000\n",
            "766/766 [==============================] - 1s 874us/sample - loss: 2.0350 - accuracy: 0.3901\n",
            "Epoch 28/1000\n",
            "766/766 [==============================] - 1s 869us/sample - loss: 2.0215 - accuracy: 0.3953\n",
            "Epoch 29/1000\n",
            "766/766 [==============================] - 1s 878us/sample - loss: 2.0116 - accuracy: 0.3976\n",
            "Epoch 30/1000\n",
            "766/766 [==============================] - 1s 880us/sample - loss: 2.0023 - accuracy: 0.4012\n",
            "Epoch 31/1000\n",
            "766/766 [==============================] - 1s 864us/sample - loss: 1.9906 - accuracy: 0.4022\n",
            "Epoch 32/1000\n",
            "766/766 [==============================] - 1s 877us/sample - loss: 1.9838 - accuracy: 0.4048\n",
            "Epoch 33/1000\n",
            "766/766 [==============================] - 1s 872us/sample - loss: 1.9736 - accuracy: 0.4076\n",
            "Epoch 34/1000\n",
            "766/766 [==============================] - 1s 877us/sample - loss: 1.9627 - accuracy: 0.4110\n",
            "Epoch 35/1000\n",
            "766/766 [==============================] - 1s 895us/sample - loss: 1.9555 - accuracy: 0.4119\n",
            "Epoch 36/1000\n",
            "766/766 [==============================] - 1s 893us/sample - loss: 1.9486 - accuracy: 0.4142\n",
            "Epoch 37/1000\n",
            "766/766 [==============================] - 1s 866us/sample - loss: 1.9365 - accuracy: 0.4182\n",
            "Epoch 38/1000\n",
            "766/766 [==============================] - 1s 897us/sample - loss: 1.9302 - accuracy: 0.4188\n",
            "Epoch 39/1000\n",
            "766/766 [==============================] - 1s 890us/sample - loss: 1.9229 - accuracy: 0.4192\n",
            "Epoch 40/1000\n",
            "766/766 [==============================] - 1s 872us/sample - loss: 1.9144 - accuracy: 0.4221\n",
            "Epoch 41/1000\n",
            "766/766 [==============================] - 1s 891us/sample - loss: 1.9065 - accuracy: 0.4252\n",
            "Epoch 42/1000\n",
            "766/766 [==============================] - 1s 873us/sample - loss: 1.8990 - accuracy: 0.4283\n",
            "Epoch 43/1000\n",
            "766/766 [==============================] - 1s 870us/sample - loss: 1.8904 - accuracy: 0.4291\n",
            "Epoch 44/1000\n",
            "766/766 [==============================] - 1s 870us/sample - loss: 1.8836 - accuracy: 0.4304\n",
            "Epoch 45/1000\n",
            "766/766 [==============================] - 1s 876us/sample - loss: 1.8762 - accuracy: 0.4320\n",
            "Epoch 46/1000\n",
            "766/766 [==============================] - 1s 875us/sample - loss: 1.8699 - accuracy: 0.4339\n",
            "Epoch 47/1000\n",
            "766/766 [==============================] - 1s 870us/sample - loss: 1.8632 - accuracy: 0.4364\n",
            "Epoch 48/1000\n",
            "766/766 [==============================] - 1s 881us/sample - loss: 1.8573 - accuracy: 0.4374\n",
            "Epoch 49/1000\n",
            "766/766 [==============================] - 1s 874us/sample - loss: 1.8524 - accuracy: 0.4379\n",
            "Epoch 50/1000\n",
            "766/766 [==============================] - 1s 890us/sample - loss: 1.8448 - accuracy: 0.4413\n",
            "Epoch 51/1000\n",
            "766/766 [==============================] - 1s 872us/sample - loss: 1.8365 - accuracy: 0.4432\n",
            "Epoch 52/1000\n",
            "766/766 [==============================] - 1s 865us/sample - loss: 1.8312 - accuracy: 0.4444\n",
            "Epoch 53/1000\n",
            "766/766 [==============================] - 1s 885us/sample - loss: 1.8253 - accuracy: 0.4447\n",
            "Epoch 54/1000\n",
            "766/766 [==============================] - 1s 894us/sample - loss: 1.8185 - accuracy: 0.4476\n",
            "Epoch 55/1000\n",
            "766/766 [==============================] - 1s 873us/sample - loss: 1.8132 - accuracy: 0.4477\n",
            "Epoch 56/1000\n",
            "766/766 [==============================] - 1s 880us/sample - loss: 1.8076 - accuracy: 0.4503\n",
            "Epoch 57/1000\n",
            "766/766 [==============================] - 1s 876us/sample - loss: 1.8040 - accuracy: 0.4500\n",
            "Epoch 58/1000\n",
            "766/766 [==============================] - 1s 876us/sample - loss: 1.7969 - accuracy: 0.4537\n",
            "Epoch 59/1000\n",
            "766/766 [==============================] - 1s 885us/sample - loss: 1.7905 - accuracy: 0.4545\n",
            "Epoch 60/1000\n",
            "766/766 [==============================] - 1s 882us/sample - loss: 1.7839 - accuracy: 0.4571\n",
            "Epoch 61/1000\n",
            "766/766 [==============================] - 1s 874us/sample - loss: 1.7796 - accuracy: 0.4580\n",
            "Epoch 62/1000\n",
            "766/766 [==============================] - 1s 886us/sample - loss: 1.7739 - accuracy: 0.4590\n",
            "Epoch 63/1000\n",
            "766/766 [==============================] - 1s 869us/sample - loss: 1.7691 - accuracy: 0.4605\n",
            "Epoch 64/1000\n",
            "766/766 [==============================] - 1s 889us/sample - loss: 1.7637 - accuracy: 0.4616\n",
            "Epoch 65/1000\n",
            "766/766 [==============================] - 1s 881us/sample - loss: 1.7578 - accuracy: 0.4642\n",
            "Epoch 66/1000\n",
            "766/766 [==============================] - 1s 894us/sample - loss: 1.7515 - accuracy: 0.4651\n",
            "Epoch 67/1000\n",
            "766/766 [==============================] - 1s 878us/sample - loss: 1.7466 - accuracy: 0.4667\n",
            "Epoch 68/1000\n",
            "766/766 [==============================] - 1s 870us/sample - loss: 1.7416 - accuracy: 0.4677\n",
            "Epoch 69/1000\n",
            "766/766 [==============================] - 1s 879us/sample - loss: 1.7365 - accuracy: 0.4679\n",
            "Epoch 70/1000\n",
            "766/766 [==============================] - 1s 880us/sample - loss: 1.7307 - accuracy: 0.4702\n",
            "Epoch 71/1000\n",
            "766/766 [==============================] - 1s 883us/sample - loss: 1.7270 - accuracy: 0.4716\n",
            "Epoch 72/1000\n",
            "766/766 [==============================] - 1s 874us/sample - loss: 1.7193 - accuracy: 0.4742\n",
            "Epoch 73/1000\n",
            "766/766 [==============================] - 1s 887us/sample - loss: 1.7171 - accuracy: 0.4734\n",
            "Epoch 74/1000\n",
            "766/766 [==============================] - 1s 890us/sample - loss: 1.7115 - accuracy: 0.4760\n",
            "Epoch 75/1000\n",
            "766/766 [==============================] - 1s 872us/sample - loss: 1.7047 - accuracy: 0.4770\n",
            "Epoch 76/1000\n",
            "766/766 [==============================] - 1s 889us/sample - loss: 1.7007 - accuracy: 0.4789\n",
            "Epoch 77/1000\n",
            "766/766 [==============================] - 1s 875us/sample - loss: 1.6939 - accuracy: 0.4807\n",
            "Epoch 78/1000\n",
            "766/766 [==============================] - 1s 871us/sample - loss: 1.6910 - accuracy: 0.4816\n",
            "Epoch 79/1000\n",
            "766/766 [==============================] - 1s 883us/sample - loss: 1.6864 - accuracy: 0.4815\n",
            "Epoch 80/1000\n",
            "766/766 [==============================] - 1s 872us/sample - loss: 1.6811 - accuracy: 0.4841\n",
            "Epoch 81/1000\n",
            "766/766 [==============================] - 1s 875us/sample - loss: 1.6749 - accuracy: 0.4859\n",
            "Epoch 82/1000\n",
            "766/766 [==============================] - 1s 883us/sample - loss: 1.6708 - accuracy: 0.4867\n",
            "Epoch 83/1000\n",
            "766/766 [==============================] - 1s 862us/sample - loss: 1.6664 - accuracy: 0.4878\n",
            "Epoch 84/1000\n",
            "766/766 [==============================] - 1s 866us/sample - loss: 1.6638 - accuracy: 0.4876\n",
            "Epoch 85/1000\n",
            "766/766 [==============================] - 1s 868us/sample - loss: 1.6577 - accuracy: 0.4909\n",
            "Epoch 86/1000\n",
            "766/766 [==============================] - 1s 853us/sample - loss: 1.6524 - accuracy: 0.4911\n",
            "Epoch 87/1000\n",
            "766/766 [==============================] - 1s 858us/sample - loss: 1.6479 - accuracy: 0.4933\n",
            "Epoch 88/1000\n",
            "766/766 [==============================] - 1s 866us/sample - loss: 1.6430 - accuracy: 0.4948\n",
            "Epoch 89/1000\n",
            "766/766 [==============================] - 1s 859us/sample - loss: 1.6403 - accuracy: 0.4942\n",
            "Epoch 90/1000\n",
            "766/766 [==============================] - 1s 847us/sample - loss: 1.6337 - accuracy: 0.4956\n",
            "Epoch 91/1000\n",
            "766/766 [==============================] - 1s 856us/sample - loss: 1.6279 - accuracy: 0.4978\n",
            "Epoch 92/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 1.6224 - accuracy: 0.5011\n",
            "Epoch 93/1000\n",
            "766/766 [==============================] - 1s 845us/sample - loss: 1.6191 - accuracy: 0.5021\n",
            "Epoch 94/1000\n",
            "766/766 [==============================] - 1s 856us/sample - loss: 1.6151 - accuracy: 0.5013\n",
            "Epoch 95/1000\n",
            "766/766 [==============================] - 1s 848us/sample - loss: 1.6082 - accuracy: 0.5040\n",
            "Epoch 96/1000\n",
            "766/766 [==============================] - 1s 868us/sample - loss: 1.6038 - accuracy: 0.5054\n",
            "Epoch 97/1000\n",
            "766/766 [==============================] - 1s 855us/sample - loss: 1.6014 - accuracy: 0.5067\n",
            "Epoch 98/1000\n",
            "766/766 [==============================] - 1s 851us/sample - loss: 1.5941 - accuracy: 0.5088\n",
            "Epoch 99/1000\n",
            "766/766 [==============================] - 1s 852us/sample - loss: 1.5898 - accuracy: 0.5101\n",
            "Epoch 100/1000\n",
            "766/766 [==============================] - 1s 858us/sample - loss: 1.5872 - accuracy: 0.5101\n",
            "Epoch 101/1000\n",
            "766/766 [==============================] - 1s 852us/sample - loss: 1.5832 - accuracy: 0.5121\n",
            "Epoch 102/1000\n",
            "766/766 [==============================] - 1s 865us/sample - loss: 1.5789 - accuracy: 0.5119\n",
            "Epoch 103/1000\n",
            "766/766 [==============================] - 1s 851us/sample - loss: 1.5721 - accuracy: 0.5127\n",
            "Epoch 104/1000\n",
            "766/766 [==============================] - 1s 854us/sample - loss: 1.5669 - accuracy: 0.5163\n",
            "Epoch 105/1000\n",
            "766/766 [==============================] - 1s 847us/sample - loss: 1.5636 - accuracy: 0.5164\n",
            "Epoch 106/1000\n",
            "766/766 [==============================] - 1s 860us/sample - loss: 1.5590 - accuracy: 0.5175\n",
            "Epoch 107/1000\n",
            "766/766 [==============================] - 1s 863us/sample - loss: 1.5552 - accuracy: 0.5202\n",
            "Epoch 108/1000\n",
            "766/766 [==============================] - 1s 848us/sample - loss: 1.5467 - accuracy: 0.5213\n",
            "Epoch 109/1000\n",
            "766/766 [==============================] - 1s 858us/sample - loss: 1.5426 - accuracy: 0.5223\n",
            "Epoch 110/1000\n",
            "766/766 [==============================] - 1s 859us/sample - loss: 1.5384 - accuracy: 0.5264\n",
            "Epoch 111/1000\n",
            "766/766 [==============================] - 1s 851us/sample - loss: 1.5352 - accuracy: 0.5250\n",
            "Epoch 112/1000\n",
            "766/766 [==============================] - 1s 863us/sample - loss: 1.5324 - accuracy: 0.5259\n",
            "Epoch 113/1000\n",
            "766/766 [==============================] - 1s 849us/sample - loss: 1.5255 - accuracy: 0.5289\n",
            "Epoch 114/1000\n",
            "766/766 [==============================] - 1s 858us/sample - loss: 1.5188 - accuracy: 0.5320\n",
            "Epoch 115/1000\n",
            "766/766 [==============================] - 1s 860us/sample - loss: 1.5170 - accuracy: 0.5303\n",
            "Epoch 116/1000\n",
            "766/766 [==============================] - 1s 865us/sample - loss: 1.5108 - accuracy: 0.5326\n",
            "Epoch 117/1000\n",
            "766/766 [==============================] - 1s 872us/sample - loss: 1.5099 - accuracy: 0.5337\n",
            "Epoch 118/1000\n",
            "766/766 [==============================] - 1s 858us/sample - loss: 1.5035 - accuracy: 0.5360\n",
            "Epoch 119/1000\n",
            "766/766 [==============================] - 1s 864us/sample - loss: 1.4986 - accuracy: 0.5349\n",
            "Epoch 120/1000\n",
            "766/766 [==============================] - 1s 857us/sample - loss: 1.4974 - accuracy: 0.5359\n",
            "Epoch 121/1000\n",
            "766/766 [==============================] - 1s 861us/sample - loss: 1.4911 - accuracy: 0.5391\n",
            "Epoch 122/1000\n",
            "766/766 [==============================] - 1s 849us/sample - loss: 1.4858 - accuracy: 0.5411\n",
            "Epoch 123/1000\n",
            "766/766 [==============================] - 1s 847us/sample - loss: 1.4811 - accuracy: 0.5414\n",
            "Epoch 124/1000\n",
            "766/766 [==============================] - 1s 857us/sample - loss: 1.4790 - accuracy: 0.5420\n",
            "Epoch 125/1000\n",
            "766/766 [==============================] - 1s 866us/sample - loss: 1.4732 - accuracy: 0.5436\n",
            "Epoch 126/1000\n",
            "766/766 [==============================] - 1s 869us/sample - loss: 1.4673 - accuracy: 0.5462\n",
            "Epoch 127/1000\n",
            "766/766 [==============================] - 1s 855us/sample - loss: 1.4645 - accuracy: 0.5460\n",
            "Epoch 128/1000\n",
            "766/766 [==============================] - 1s 857us/sample - loss: 1.4617 - accuracy: 0.5470\n",
            "Epoch 129/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 1.4552 - accuracy: 0.5497\n",
            "Epoch 130/1000\n",
            "766/766 [==============================] - 1s 865us/sample - loss: 1.4495 - accuracy: 0.5510\n",
            "Epoch 131/1000\n",
            "766/766 [==============================] - 1s 865us/sample - loss: 1.4442 - accuracy: 0.5547\n",
            "Epoch 132/1000\n",
            "766/766 [==============================] - 1s 857us/sample - loss: 1.4402 - accuracy: 0.5549\n",
            "Epoch 133/1000\n",
            "766/766 [==============================] - 1s 865us/sample - loss: 1.4352 - accuracy: 0.5555\n",
            "Epoch 134/1000\n",
            "766/766 [==============================] - 1s 873us/sample - loss: 1.4303 - accuracy: 0.5564\n",
            "Epoch 135/1000\n",
            "766/766 [==============================] - 1s 824us/sample - loss: 1.4280 - accuracy: 0.5580\n",
            "Epoch 136/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 1.4232 - accuracy: 0.5586\n",
            "Epoch 137/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 1.4196 - accuracy: 0.5604\n",
            "Epoch 138/1000\n",
            "766/766 [==============================] - 1s 846us/sample - loss: 1.4120 - accuracy: 0.5619\n",
            "Epoch 139/1000\n",
            "766/766 [==============================] - 1s 828us/sample - loss: 1.4089 - accuracy: 0.5606\n",
            "Epoch 140/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 1.4035 - accuracy: 0.5635\n",
            "Epoch 141/1000\n",
            "766/766 [==============================] - 1s 840us/sample - loss: 1.3992 - accuracy: 0.5649\n",
            "Epoch 142/1000\n",
            "766/766 [==============================] - 1s 846us/sample - loss: 1.3955 - accuracy: 0.5673\n",
            "Epoch 143/1000\n",
            "766/766 [==============================] - 1s 822us/sample - loss: 1.3892 - accuracy: 0.5705\n",
            "Epoch 144/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 1.3833 - accuracy: 0.5697\n",
            "Epoch 145/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 1.3813 - accuracy: 0.5716\n",
            "Epoch 146/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 1.3797 - accuracy: 0.5721\n",
            "Epoch 147/1000\n",
            "766/766 [==============================] - 1s 846us/sample - loss: 1.3730 - accuracy: 0.5756\n",
            "Epoch 148/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 1.3682 - accuracy: 0.5763\n",
            "Epoch 149/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 1.3638 - accuracy: 0.5750\n",
            "Epoch 150/1000\n",
            "766/766 [==============================] - 1s 862us/sample - loss: 1.3591 - accuracy: 0.5793\n",
            "Epoch 151/1000\n",
            "766/766 [==============================] - 1s 824us/sample - loss: 1.3530 - accuracy: 0.5801\n",
            "Epoch 152/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 1.3489 - accuracy: 0.5800\n",
            "Epoch 153/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 1.3478 - accuracy: 0.5807\n",
            "Epoch 154/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 1.3427 - accuracy: 0.5834\n",
            "Epoch 155/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 1.3383 - accuracy: 0.5842\n",
            "Epoch 156/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 1.3311 - accuracy: 0.5861\n",
            "Epoch 157/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 1.3296 - accuracy: 0.5872\n",
            "Epoch 158/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 1.3218 - accuracy: 0.5912\n",
            "Epoch 159/1000\n",
            "766/766 [==============================] - 1s 830us/sample - loss: 1.3164 - accuracy: 0.5889\n",
            "Epoch 160/1000\n",
            "766/766 [==============================] - 1s 853us/sample - loss: 1.3131 - accuracy: 0.5915\n",
            "Epoch 161/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 1.3096 - accuracy: 0.5924\n",
            "Epoch 162/1000\n",
            "766/766 [==============================] - 1s 848us/sample - loss: 1.3050 - accuracy: 0.5958\n",
            "Epoch 163/1000\n",
            "766/766 [==============================] - 1s 829us/sample - loss: 1.3004 - accuracy: 0.5944\n",
            "Epoch 164/1000\n",
            "766/766 [==============================] - 1s 865us/sample - loss: 1.2980 - accuracy: 0.5954\n",
            "Epoch 165/1000\n",
            "766/766 [==============================] - 1s 830us/sample - loss: 1.2883 - accuracy: 0.5991\n",
            "Epoch 166/1000\n",
            "766/766 [==============================] - 1s 854us/sample - loss: 1.2881 - accuracy: 0.5996\n",
            "Epoch 167/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 1.2822 - accuracy: 0.6011\n",
            "Epoch 168/1000\n",
            "766/766 [==============================] - 1s 840us/sample - loss: 1.2821 - accuracy: 0.6011\n",
            "Epoch 169/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 1.2745 - accuracy: 0.6018\n",
            "Epoch 170/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 1.2697 - accuracy: 0.6049\n",
            "Epoch 171/1000\n",
            "766/766 [==============================] - 1s 853us/sample - loss: 1.2679 - accuracy: 0.6046\n",
            "Epoch 172/1000\n",
            "766/766 [==============================] - 1s 849us/sample - loss: 1.2640 - accuracy: 0.6053\n",
            "Epoch 173/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 1.2628 - accuracy: 0.6073\n",
            "Epoch 174/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 1.2573 - accuracy: 0.6076\n",
            "Epoch 175/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 1.2495 - accuracy: 0.6098\n",
            "Epoch 176/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 1.2477 - accuracy: 0.6106\n",
            "Epoch 177/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 1.2431 - accuracy: 0.6113\n",
            "Epoch 178/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 1.2402 - accuracy: 0.6128\n",
            "Epoch 179/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 1.2327 - accuracy: 0.6148\n",
            "Epoch 180/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 1.2294 - accuracy: 0.6157\n",
            "Epoch 181/1000\n",
            "766/766 [==============================] - 1s 827us/sample - loss: 1.2249 - accuracy: 0.6185\n",
            "Epoch 182/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 1.2232 - accuracy: 0.6157\n",
            "Epoch 183/1000\n",
            "766/766 [==============================] - 1s 855us/sample - loss: 1.2198 - accuracy: 0.6188\n",
            "Epoch 184/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 1.2137 - accuracy: 0.6208\n",
            "Epoch 185/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 1.2130 - accuracy: 0.6211\n",
            "Epoch 186/1000\n",
            "766/766 [==============================] - 1s 836us/sample - loss: 1.2071 - accuracy: 0.6223\n",
            "Epoch 187/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 1.2031 - accuracy: 0.6242\n",
            "Epoch 188/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 1.1988 - accuracy: 0.6252\n",
            "Epoch 189/1000\n",
            "766/766 [==============================] - 1s 840us/sample - loss: 1.1937 - accuracy: 0.6275\n",
            "Epoch 190/1000\n",
            "766/766 [==============================] - 1s 849us/sample - loss: 1.1928 - accuracy: 0.6271\n",
            "Epoch 191/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 1.1911 - accuracy: 0.6291\n",
            "Epoch 192/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 1.1892 - accuracy: 0.6284\n",
            "Epoch 193/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 1.1833 - accuracy: 0.6305\n",
            "Epoch 194/1000\n",
            "766/766 [==============================] - 1s 830us/sample - loss: 1.1804 - accuracy: 0.6302\n",
            "Epoch 195/1000\n",
            "766/766 [==============================] - 1s 816us/sample - loss: 1.1757 - accuracy: 0.6302\n",
            "Epoch 196/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 1.1698 - accuracy: 0.6345\n",
            "Epoch 197/1000\n",
            "766/766 [==============================] - 1s 826us/sample - loss: 1.1673 - accuracy: 0.6334\n",
            "Epoch 198/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 1.1620 - accuracy: 0.6368\n",
            "Epoch 199/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 1.1631 - accuracy: 0.6348\n",
            "Epoch 200/1000\n",
            "766/766 [==============================] - 1s 840us/sample - loss: 1.1577 - accuracy: 0.6370\n",
            "Epoch 201/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 1.1535 - accuracy: 0.6408\n",
            "Epoch 202/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 1.1511 - accuracy: 0.6389\n",
            "Epoch 203/1000\n",
            "766/766 [==============================] - 1s 836us/sample - loss: 1.1455 - accuracy: 0.6418\n",
            "Epoch 204/1000\n",
            "766/766 [==============================] - 1s 847us/sample - loss: 1.1469 - accuracy: 0.6412\n",
            "Epoch 205/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 1.1416 - accuracy: 0.6448\n",
            "Epoch 206/1000\n",
            "766/766 [==============================] - 1s 849us/sample - loss: 1.1363 - accuracy: 0.6439\n",
            "Epoch 207/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 1.1345 - accuracy: 0.6441\n",
            "Epoch 208/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 1.1320 - accuracy: 0.6465\n",
            "Epoch 209/1000\n",
            "766/766 [==============================] - 1s 852us/sample - loss: 1.1268 - accuracy: 0.6473\n",
            "Epoch 210/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 1.1260 - accuracy: 0.6473\n",
            "Epoch 211/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 1.1249 - accuracy: 0.6473\n",
            "Epoch 212/1000\n",
            "766/766 [==============================] - 1s 857us/sample - loss: 1.1176 - accuracy: 0.6492\n",
            "Epoch 213/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 1.1183 - accuracy: 0.6499\n",
            "Epoch 214/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 1.1121 - accuracy: 0.6511\n",
            "Epoch 215/1000\n",
            "766/766 [==============================] - 1s 847us/sample - loss: 1.1100 - accuracy: 0.6515\n",
            "Epoch 216/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 1.1143 - accuracy: 0.6509\n",
            "Epoch 217/1000\n",
            "766/766 [==============================] - 1s 852us/sample - loss: 1.1031 - accuracy: 0.6543\n",
            "Epoch 218/1000\n",
            "766/766 [==============================] - 1s 851us/sample - loss: 1.1001 - accuracy: 0.6556\n",
            "Epoch 219/1000\n",
            "766/766 [==============================] - 1s 836us/sample - loss: 1.0977 - accuracy: 0.6545\n",
            "Epoch 220/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 1.0969 - accuracy: 0.6560\n",
            "Epoch 221/1000\n",
            "766/766 [==============================] - 1s 848us/sample - loss: 1.0872 - accuracy: 0.6588\n",
            "Epoch 222/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 1.0922 - accuracy: 0.6563\n",
            "Epoch 223/1000\n",
            "766/766 [==============================] - 1s 836us/sample - loss: 1.0860 - accuracy: 0.6599\n",
            "Epoch 224/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 1.0852 - accuracy: 0.6581\n",
            "Epoch 225/1000\n",
            "766/766 [==============================] - 1s 854us/sample - loss: 1.0843 - accuracy: 0.6598\n",
            "Epoch 226/1000\n",
            "766/766 [==============================] - 1s 846us/sample - loss: 1.0813 - accuracy: 0.6603\n",
            "Epoch 227/1000\n",
            "766/766 [==============================] - 1s 819us/sample - loss: 1.0785 - accuracy: 0.6622\n",
            "Epoch 228/1000\n",
            "766/766 [==============================] - 1s 830us/sample - loss: 1.0789 - accuracy: 0.6621\n",
            "Epoch 229/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 1.0738 - accuracy: 0.6619\n",
            "Epoch 230/1000\n",
            "766/766 [==============================] - 1s 840us/sample - loss: 1.0712 - accuracy: 0.6650\n",
            "Epoch 231/1000\n",
            "766/766 [==============================] - 1s 829us/sample - loss: 1.0665 - accuracy: 0.6659\n",
            "Epoch 232/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 1.0616 - accuracy: 0.6679\n",
            "Epoch 233/1000\n",
            "766/766 [==============================] - 1s 824us/sample - loss: 1.0589 - accuracy: 0.6684\n",
            "Epoch 234/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 1.0605 - accuracy: 0.6670\n",
            "Epoch 235/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 1.0613 - accuracy: 0.6657\n",
            "Epoch 236/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 1.0601 - accuracy: 0.6679\n",
            "Epoch 237/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 1.0560 - accuracy: 0.6669\n",
            "Epoch 238/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 1.0524 - accuracy: 0.6698\n",
            "Epoch 239/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 1.0507 - accuracy: 0.6700\n",
            "Epoch 240/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 1.0457 - accuracy: 0.6709\n",
            "Epoch 241/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 1.0456 - accuracy: 0.6704\n",
            "Epoch 242/1000\n",
            "766/766 [==============================] - 1s 830us/sample - loss: 1.0451 - accuracy: 0.6706\n",
            "Epoch 243/1000\n",
            "766/766 [==============================] - 1s 822us/sample - loss: 1.0411 - accuracy: 0.6716\n",
            "Epoch 244/1000\n",
            "766/766 [==============================] - 1s 850us/sample - loss: 1.0395 - accuracy: 0.6733\n",
            "Epoch 245/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 1.0356 - accuracy: 0.6734\n",
            "Epoch 246/1000\n",
            "766/766 [==============================] - 1s 846us/sample - loss: 1.0313 - accuracy: 0.6752\n",
            "Epoch 247/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 1.0280 - accuracy: 0.6766\n",
            "Epoch 248/1000\n",
            "766/766 [==============================] - 1s 855us/sample - loss: 1.0273 - accuracy: 0.6774\n",
            "Epoch 249/1000\n",
            "766/766 [==============================] - 1s 846us/sample - loss: 1.0282 - accuracy: 0.6763\n",
            "Epoch 250/1000\n",
            "766/766 [==============================] - 1s 856us/sample - loss: 1.0234 - accuracy: 0.6794\n",
            "Epoch 251/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 1.0248 - accuracy: 0.6778\n",
            "Epoch 252/1000\n",
            "766/766 [==============================] - 1s 828us/sample - loss: 1.0230 - accuracy: 0.6783\n",
            "Epoch 253/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 1.0237 - accuracy: 0.6790\n",
            "Epoch 254/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 1.0199 - accuracy: 0.6800\n",
            "Epoch 255/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 1.0140 - accuracy: 0.6810\n",
            "Epoch 256/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 1.0163 - accuracy: 0.6788\n",
            "Epoch 257/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 1.0158 - accuracy: 0.6804\n",
            "Epoch 258/1000\n",
            "766/766 [==============================] - 1s 852us/sample - loss: 1.0076 - accuracy: 0.6829\n",
            "Epoch 259/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 1.0100 - accuracy: 0.6840\n",
            "Epoch 260/1000\n",
            "766/766 [==============================] - 1s 852us/sample - loss: 1.0098 - accuracy: 0.6826\n",
            "Epoch 261/1000\n",
            "766/766 [==============================] - 1s 823us/sample - loss: 1.0102 - accuracy: 0.6825\n",
            "Epoch 262/1000\n",
            "766/766 [==============================] - 1s 848us/sample - loss: 1.0075 - accuracy: 0.6825\n",
            "Epoch 263/1000\n",
            "766/766 [==============================] - 1s 826us/sample - loss: 1.0006 - accuracy: 0.6832\n",
            "Epoch 264/1000\n",
            "766/766 [==============================] - 1s 845us/sample - loss: 0.9989 - accuracy: 0.6871\n",
            "Epoch 265/1000\n",
            "766/766 [==============================] - 1s 840us/sample - loss: 0.9976 - accuracy: 0.6864\n",
            "Epoch 266/1000\n",
            "766/766 [==============================] - 1s 845us/sample - loss: 0.9980 - accuracy: 0.6870\n",
            "Epoch 267/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 1.0062 - accuracy: 0.6819\n",
            "Epoch 268/1000\n",
            "766/766 [==============================] - 1s 824us/sample - loss: 1.0074 - accuracy: 0.6817\n",
            "Epoch 269/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 0.9922 - accuracy: 0.6882\n",
            "Epoch 270/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 0.9931 - accuracy: 0.6877\n",
            "Epoch 271/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.9934 - accuracy: 0.6872\n",
            "Epoch 272/1000\n",
            "766/766 [==============================] - 1s 840us/sample - loss: 0.9894 - accuracy: 0.6876\n",
            "Epoch 273/1000\n",
            "766/766 [==============================] - 1s 827us/sample - loss: 0.9884 - accuracy: 0.6881\n",
            "Epoch 274/1000\n",
            "766/766 [==============================] - 1s 836us/sample - loss: 0.9848 - accuracy: 0.6905\n",
            "Epoch 275/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 0.9835 - accuracy: 0.6899\n",
            "Epoch 276/1000\n",
            "766/766 [==============================] - 1s 833us/sample - loss: 0.9833 - accuracy: 0.6905\n",
            "Epoch 277/1000\n",
            "766/766 [==============================] - 1s 824us/sample - loss: 0.9807 - accuracy: 0.6912\n",
            "Epoch 278/1000\n",
            "766/766 [==============================] - 1s 850us/sample - loss: 0.9810 - accuracy: 0.6907\n",
            "Epoch 279/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 0.9836 - accuracy: 0.6896\n",
            "Epoch 280/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 0.9797 - accuracy: 0.6899\n",
            "Epoch 281/1000\n",
            "766/766 [==============================] - 1s 859us/sample - loss: 0.9758 - accuracy: 0.6923\n",
            "Epoch 282/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 0.9682 - accuracy: 0.6962\n",
            "Epoch 283/1000\n",
            "766/766 [==============================] - 1s 817us/sample - loss: 0.9717 - accuracy: 0.6938\n",
            "Epoch 284/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 0.9705 - accuracy: 0.6947\n",
            "Epoch 285/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 0.9658 - accuracy: 0.6951\n",
            "Epoch 286/1000\n",
            "766/766 [==============================] - 1s 845us/sample - loss: 0.9635 - accuracy: 0.6965\n",
            "Epoch 287/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.9598 - accuracy: 0.6971\n",
            "Epoch 288/1000\n",
            "766/766 [==============================] - 1s 833us/sample - loss: 0.9588 - accuracy: 0.6976\n",
            "Epoch 289/1000\n",
            "766/766 [==============================] - 1s 849us/sample - loss: 0.9591 - accuracy: 0.6985\n",
            "Epoch 290/1000\n",
            "766/766 [==============================] - 1s 840us/sample - loss: 0.9598 - accuracy: 0.6987\n",
            "Epoch 291/1000\n",
            "766/766 [==============================] - 1s 833us/sample - loss: 0.9563 - accuracy: 0.6973\n",
            "Epoch 292/1000\n",
            "766/766 [==============================] - 1s 827us/sample - loss: 0.9536 - accuracy: 0.6980\n",
            "Epoch 293/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 0.9551 - accuracy: 0.6981\n",
            "Epoch 294/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 0.9519 - accuracy: 0.6985\n",
            "Epoch 295/1000\n",
            "766/766 [==============================] - 1s 824us/sample - loss: 0.9512 - accuracy: 0.6999\n",
            "Epoch 296/1000\n",
            "766/766 [==============================] - 1s 845us/sample - loss: 0.9544 - accuracy: 0.6984\n",
            "Epoch 297/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 0.9520 - accuracy: 0.6991\n",
            "Epoch 298/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 0.9569 - accuracy: 0.6980\n",
            "Epoch 299/1000\n",
            "766/766 [==============================] - 1s 850us/sample - loss: 0.9497 - accuracy: 0.7006\n",
            "Epoch 300/1000\n",
            "766/766 [==============================] - 1s 846us/sample - loss: 0.9437 - accuracy: 0.7019\n",
            "Epoch 301/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 0.9475 - accuracy: 0.7010\n",
            "Epoch 302/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 0.9433 - accuracy: 0.7015\n",
            "Epoch 303/1000\n",
            "766/766 [==============================] - 1s 833us/sample - loss: 0.9393 - accuracy: 0.7032\n",
            "Epoch 304/1000\n",
            "766/766 [==============================] - 1s 847us/sample - loss: 0.9408 - accuracy: 0.7039\n",
            "Epoch 305/1000\n",
            "766/766 [==============================] - 1s 840us/sample - loss: 0.9449 - accuracy: 0.7010\n",
            "Epoch 306/1000\n",
            "766/766 [==============================] - 1s 847us/sample - loss: 0.9461 - accuracy: 0.7010\n",
            "Epoch 307/1000\n",
            "766/766 [==============================] - 1s 833us/sample - loss: 0.9409 - accuracy: 0.7015\n",
            "Epoch 308/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 0.9344 - accuracy: 0.7034\n",
            "Epoch 309/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 0.9307 - accuracy: 0.7066\n",
            "Epoch 310/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 0.9301 - accuracy: 0.7056\n",
            "Epoch 311/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 0.9291 - accuracy: 0.7065\n",
            "Epoch 312/1000\n",
            "766/766 [==============================] - 1s 846us/sample - loss: 0.9310 - accuracy: 0.7052\n",
            "Epoch 313/1000\n",
            "766/766 [==============================] - 1s 851us/sample - loss: 0.9220 - accuracy: 0.7097\n",
            "Epoch 314/1000\n",
            "766/766 [==============================] - 1s 853us/sample - loss: 0.9301 - accuracy: 0.7052\n",
            "Epoch 315/1000\n",
            "766/766 [==============================] - 1s 850us/sample - loss: 0.9273 - accuracy: 0.7076\n",
            "Epoch 316/1000\n",
            "766/766 [==============================] - 1s 856us/sample - loss: 0.9263 - accuracy: 0.7073\n",
            "Epoch 317/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 0.9237 - accuracy: 0.7071\n",
            "Epoch 318/1000\n",
            "766/766 [==============================] - 1s 852us/sample - loss: 0.9166 - accuracy: 0.7104\n",
            "Epoch 319/1000\n",
            "766/766 [==============================] - 1s 858us/sample - loss: 0.9220 - accuracy: 0.7091\n",
            "Epoch 320/1000\n",
            "766/766 [==============================] - 1s 849us/sample - loss: 0.9206 - accuracy: 0.7080\n",
            "Epoch 321/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 0.9265 - accuracy: 0.7055\n",
            "Epoch 322/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.9243 - accuracy: 0.7091\n",
            "Epoch 323/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 0.9246 - accuracy: 0.7069\n",
            "Epoch 324/1000\n",
            "766/766 [==============================] - 1s 848us/sample - loss: 0.9166 - accuracy: 0.7099\n",
            "Epoch 325/1000\n",
            "766/766 [==============================] - 1s 827us/sample - loss: 0.9126 - accuracy: 0.7094\n",
            "Epoch 326/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.9128 - accuracy: 0.7118\n",
            "Epoch 327/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.9098 - accuracy: 0.7119\n",
            "Epoch 328/1000\n",
            "766/766 [==============================] - 1s 825us/sample - loss: 0.9107 - accuracy: 0.7113\n",
            "Epoch 329/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.9122 - accuracy: 0.7091\n",
            "Epoch 330/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.9109 - accuracy: 0.7118\n",
            "Epoch 331/1000\n",
            "766/766 [==============================] - 1s 823us/sample - loss: 0.9077 - accuracy: 0.7121\n",
            "Epoch 332/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 0.9086 - accuracy: 0.7137\n",
            "Epoch 333/1000\n",
            "766/766 [==============================] - 1s 828us/sample - loss: 0.9066 - accuracy: 0.7112\n",
            "Epoch 334/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 0.9062 - accuracy: 0.7114\n",
            "Epoch 335/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 0.9096 - accuracy: 0.7112\n",
            "Epoch 336/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.9070 - accuracy: 0.7130\n",
            "Epoch 337/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 0.9025 - accuracy: 0.7143\n",
            "Epoch 338/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 0.9007 - accuracy: 0.7136\n",
            "Epoch 339/1000\n",
            "766/766 [==============================] - 1s 826us/sample - loss: 0.9014 - accuracy: 0.7151\n",
            "Epoch 340/1000\n",
            "766/766 [==============================] - 1s 847us/sample - loss: 0.9039 - accuracy: 0.7117\n",
            "Epoch 341/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 0.9017 - accuracy: 0.7145\n",
            "Epoch 342/1000\n",
            "766/766 [==============================] - 1s 852us/sample - loss: 0.8981 - accuracy: 0.7150\n",
            "Epoch 343/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 0.9025 - accuracy: 0.7142\n",
            "Epoch 344/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 0.8976 - accuracy: 0.7147\n",
            "Epoch 345/1000\n",
            "766/766 [==============================] - 1s 850us/sample - loss: 0.8953 - accuracy: 0.7156\n",
            "Epoch 346/1000\n",
            "766/766 [==============================] - 1s 849us/sample - loss: 0.8931 - accuracy: 0.7173\n",
            "Epoch 347/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 0.8925 - accuracy: 0.7171\n",
            "Epoch 348/1000\n",
            "766/766 [==============================] - 1s 851us/sample - loss: 0.8869 - accuracy: 0.7180\n",
            "Epoch 349/1000\n",
            "766/766 [==============================] - 1s 836us/sample - loss: 0.8867 - accuracy: 0.7187\n",
            "Epoch 350/1000\n",
            "766/766 [==============================] - 1s 828us/sample - loss: 0.8891 - accuracy: 0.7173\n",
            "Epoch 351/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 0.8950 - accuracy: 0.7175\n",
            "Epoch 352/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 0.8946 - accuracy: 0.7147\n",
            "Epoch 353/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 0.8927 - accuracy: 0.7166\n",
            "Epoch 354/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 0.9002 - accuracy: 0.7151\n",
            "Epoch 355/1000\n",
            "766/766 [==============================] - 1s 827us/sample - loss: 0.9012 - accuracy: 0.7133\n",
            "Epoch 356/1000\n",
            "766/766 [==============================] - 1s 851us/sample - loss: 0.8993 - accuracy: 0.7145\n",
            "Epoch 357/1000\n",
            "766/766 [==============================] - 1s 852us/sample - loss: 0.8934 - accuracy: 0.7171\n",
            "Epoch 358/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 0.8845 - accuracy: 0.7196\n",
            "Epoch 359/1000\n",
            "766/766 [==============================] - 1s 829us/sample - loss: 0.8847 - accuracy: 0.7181\n",
            "Epoch 360/1000\n",
            "766/766 [==============================] - 1s 828us/sample - loss: 0.8837 - accuracy: 0.7173\n",
            "Epoch 361/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.8765 - accuracy: 0.7233\n",
            "Epoch 362/1000\n",
            "766/766 [==============================] - 1s 849us/sample - loss: 0.8818 - accuracy: 0.7202\n",
            "Epoch 363/1000\n",
            "766/766 [==============================] - 1s 853us/sample - loss: 0.8718 - accuracy: 0.7225\n",
            "Epoch 364/1000\n",
            "766/766 [==============================] - 1s 836us/sample - loss: 0.8839 - accuracy: 0.7177\n",
            "Epoch 365/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.8787 - accuracy: 0.7218\n",
            "Epoch 366/1000\n",
            "766/766 [==============================] - 1s 829us/sample - loss: 0.8885 - accuracy: 0.7168\n",
            "Epoch 367/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 0.8901 - accuracy: 0.7161\n",
            "Epoch 368/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 0.8815 - accuracy: 0.7196\n",
            "Epoch 369/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 0.8703 - accuracy: 0.7225\n",
            "Epoch 370/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 0.8800 - accuracy: 0.7195\n",
            "Epoch 371/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 0.8779 - accuracy: 0.7208\n",
            "Epoch 372/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.8776 - accuracy: 0.7186\n",
            "Epoch 373/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.8654 - accuracy: 0.7247\n",
            "Epoch 374/1000\n",
            "766/766 [==============================] - 1s 847us/sample - loss: 0.8627 - accuracy: 0.7256\n",
            "Epoch 375/1000\n",
            "766/766 [==============================] - 1s 828us/sample - loss: 0.8579 - accuracy: 0.7267\n",
            "Epoch 376/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.8612 - accuracy: 0.7258\n",
            "Epoch 377/1000\n",
            "766/766 [==============================] - 1s 836us/sample - loss: 0.8605 - accuracy: 0.7261\n",
            "Epoch 378/1000\n",
            "766/766 [==============================] - 1s 828us/sample - loss: 0.8698 - accuracy: 0.7208\n",
            "Epoch 379/1000\n",
            "766/766 [==============================] - 1s 830us/sample - loss: 0.8758 - accuracy: 0.7206\n",
            "Epoch 380/1000\n",
            "766/766 [==============================] - 1s 851us/sample - loss: 0.8657 - accuracy: 0.7249\n",
            "Epoch 381/1000\n",
            "766/766 [==============================] - 1s 833us/sample - loss: 0.8668 - accuracy: 0.7256\n",
            "Epoch 382/1000\n",
            "766/766 [==============================] - 1s 840us/sample - loss: 0.8602 - accuracy: 0.7264\n",
            "Epoch 383/1000\n",
            "766/766 [==============================] - 1s 848us/sample - loss: 0.8582 - accuracy: 0.7267\n",
            "Epoch 384/1000\n",
            "766/766 [==============================] - 1s 848us/sample - loss: 0.8525 - accuracy: 0.7295\n",
            "Epoch 385/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 0.8618 - accuracy: 0.7252\n",
            "Epoch 386/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.8717 - accuracy: 0.7220\n",
            "Epoch 387/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 0.8709 - accuracy: 0.7210\n",
            "Epoch 388/1000\n",
            "766/766 [==============================] - 1s 845us/sample - loss: 0.8708 - accuracy: 0.7211\n",
            "Epoch 389/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 0.8720 - accuracy: 0.7226\n",
            "Epoch 390/1000\n",
            "766/766 [==============================] - 1s 846us/sample - loss: 0.8637 - accuracy: 0.7250\n",
            "Epoch 391/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 0.8561 - accuracy: 0.7274\n",
            "Epoch 392/1000\n",
            "766/766 [==============================] - 1s 851us/sample - loss: 0.8559 - accuracy: 0.7269\n",
            "Epoch 393/1000\n",
            "766/766 [==============================] - 1s 833us/sample - loss: 0.8525 - accuracy: 0.7281\n",
            "Epoch 394/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 0.8489 - accuracy: 0.7298\n",
            "Epoch 395/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 0.8466 - accuracy: 0.7303\n",
            "Epoch 396/1000\n",
            "766/766 [==============================] - 1s 849us/sample - loss: 0.8510 - accuracy: 0.7296\n",
            "Epoch 397/1000\n",
            "766/766 [==============================] - 1s 825us/sample - loss: 0.8471 - accuracy: 0.7304\n",
            "Epoch 398/1000\n",
            "766/766 [==============================] - 1s 825us/sample - loss: 0.8533 - accuracy: 0.7273\n",
            "Epoch 399/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 0.8500 - accuracy: 0.7289\n",
            "Epoch 400/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 0.8466 - accuracy: 0.7286\n",
            "Epoch 401/1000\n",
            "766/766 [==============================] - 1s 829us/sample - loss: 0.8536 - accuracy: 0.7269\n",
            "Epoch 402/1000\n",
            "766/766 [==============================] - 1s 846us/sample - loss: 0.8445 - accuracy: 0.7313\n",
            "Epoch 403/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 0.8458 - accuracy: 0.7292\n",
            "Epoch 404/1000\n",
            "766/766 [==============================] - 1s 848us/sample - loss: 0.8442 - accuracy: 0.7321\n",
            "Epoch 405/1000\n",
            "766/766 [==============================] - 1s 822us/sample - loss: 0.8363 - accuracy: 0.7330\n",
            "Epoch 406/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.8423 - accuracy: 0.7314\n",
            "Epoch 407/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 0.8481 - accuracy: 0.7299\n",
            "Epoch 408/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.8529 - accuracy: 0.7287\n",
            "Epoch 409/1000\n",
            "766/766 [==============================] - 1s 840us/sample - loss: 0.8524 - accuracy: 0.7281\n",
            "Epoch 410/1000\n",
            "766/766 [==============================] - 1s 852us/sample - loss: 0.8556 - accuracy: 0.7263\n",
            "Epoch 411/1000\n",
            "766/766 [==============================] - 1s 828us/sample - loss: 0.8592 - accuracy: 0.7253\n",
            "Epoch 412/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 0.8467 - accuracy: 0.7297\n",
            "Epoch 413/1000\n",
            "766/766 [==============================] - 1s 846us/sample - loss: 0.8438 - accuracy: 0.7308\n",
            "Epoch 414/1000\n",
            "766/766 [==============================] - 1s 833us/sample - loss: 0.8442 - accuracy: 0.7303\n",
            "Epoch 415/1000\n",
            "766/766 [==============================] - 1s 840us/sample - loss: 0.8428 - accuracy: 0.7332\n",
            "Epoch 416/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.8342 - accuracy: 0.7338\n",
            "Epoch 417/1000\n",
            "766/766 [==============================] - 1s 830us/sample - loss: 0.8312 - accuracy: 0.7360\n",
            "Epoch 418/1000\n",
            "766/766 [==============================] - 1s 849us/sample - loss: 0.8335 - accuracy: 0.7332\n",
            "Epoch 419/1000\n",
            "766/766 [==============================] - 1s 850us/sample - loss: 0.8329 - accuracy: 0.7355\n",
            "Epoch 420/1000\n",
            "766/766 [==============================] - 1s 848us/sample - loss: 0.8318 - accuracy: 0.7333\n",
            "Epoch 421/1000\n",
            "766/766 [==============================] - 1s 827us/sample - loss: 0.8290 - accuracy: 0.7356\n",
            "Epoch 422/1000\n",
            "766/766 [==============================] - 1s 853us/sample - loss: 0.8281 - accuracy: 0.7368\n",
            "Epoch 423/1000\n",
            "766/766 [==============================] - 1s 836us/sample - loss: 0.8367 - accuracy: 0.7309\n",
            "Epoch 424/1000\n",
            "766/766 [==============================] - 1s 872us/sample - loss: 0.8332 - accuracy: 0.7325\n",
            "Epoch 425/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 0.8331 - accuracy: 0.7334\n",
            "Epoch 426/1000\n",
            "766/766 [==============================] - 1s 866us/sample - loss: 0.8313 - accuracy: 0.7346\n",
            "Epoch 427/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 0.8357 - accuracy: 0.7326\n",
            "Epoch 428/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 0.8338 - accuracy: 0.7348\n",
            "Epoch 429/1000\n",
            "766/766 [==============================] - 1s 861us/sample - loss: 0.8336 - accuracy: 0.7333\n",
            "Epoch 430/1000\n",
            "766/766 [==============================] - 1s 868us/sample - loss: 0.8329 - accuracy: 0.7330\n",
            "Epoch 431/1000\n",
            "766/766 [==============================] - 1s 874us/sample - loss: 0.8337 - accuracy: 0.7338\n",
            "Epoch 432/1000\n",
            "766/766 [==============================] - 1s 863us/sample - loss: 0.8332 - accuracy: 0.7329\n",
            "Epoch 433/1000\n",
            "766/766 [==============================] - 1s 859us/sample - loss: 0.8379 - accuracy: 0.7339\n",
            "Epoch 434/1000\n",
            "766/766 [==============================] - 1s 850us/sample - loss: 0.8355 - accuracy: 0.7331\n",
            "Epoch 435/1000\n",
            "766/766 [==============================] - 1s 867us/sample - loss: 0.8350 - accuracy: 0.7338\n",
            "Epoch 436/1000\n",
            "766/766 [==============================] - 1s 848us/sample - loss: 0.8307 - accuracy: 0.7337\n",
            "Epoch 437/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 0.8295 - accuracy: 0.7350\n",
            "Epoch 438/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 0.8174 - accuracy: 0.7378\n",
            "Epoch 439/1000\n",
            "766/766 [==============================] - 1s 825us/sample - loss: 0.8258 - accuracy: 0.7365\n",
            "Epoch 440/1000\n",
            "766/766 [==============================] - 1s 836us/sample - loss: 0.8181 - accuracy: 0.7395\n",
            "Epoch 441/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.8265 - accuracy: 0.7359\n",
            "Epoch 442/1000\n",
            "766/766 [==============================] - 1s 836us/sample - loss: 0.8307 - accuracy: 0.7333\n",
            "Epoch 443/1000\n",
            "766/766 [==============================] - 1s 840us/sample - loss: 0.8312 - accuracy: 0.7340\n",
            "Epoch 444/1000\n",
            "766/766 [==============================] - 1s 830us/sample - loss: 0.8327 - accuracy: 0.7353\n",
            "Epoch 445/1000\n",
            "766/766 [==============================] - 1s 836us/sample - loss: 0.8247 - accuracy: 0.7375\n",
            "Epoch 446/1000\n",
            "766/766 [==============================] - 1s 840us/sample - loss: 0.8168 - accuracy: 0.7388\n",
            "Epoch 447/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.8181 - accuracy: 0.7369\n",
            "Epoch 448/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 0.8168 - accuracy: 0.7389\n",
            "Epoch 449/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 0.8113 - accuracy: 0.7406\n",
            "Epoch 450/1000\n",
            "766/766 [==============================] - 1s 845us/sample - loss: 0.8155 - accuracy: 0.7390\n",
            "Epoch 451/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 0.8140 - accuracy: 0.7390\n",
            "Epoch 452/1000\n",
            "766/766 [==============================] - 1s 851us/sample - loss: 0.8135 - accuracy: 0.7406\n",
            "Epoch 453/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.8248 - accuracy: 0.7347\n",
            "Epoch 454/1000\n",
            "766/766 [==============================] - 1s 851us/sample - loss: 0.8340 - accuracy: 0.7342\n",
            "Epoch 455/1000\n",
            "766/766 [==============================] - 1s 845us/sample - loss: 0.8245 - accuracy: 0.7356\n",
            "Epoch 456/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.8264 - accuracy: 0.7352\n",
            "Epoch 457/1000\n",
            "766/766 [==============================] - 1s 840us/sample - loss: 0.8264 - accuracy: 0.7359\n",
            "Epoch 458/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 0.8347 - accuracy: 0.7343\n",
            "Epoch 459/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 0.8323 - accuracy: 0.7302\n",
            "Epoch 460/1000\n",
            "766/766 [==============================] - 1s 845us/sample - loss: 0.8273 - accuracy: 0.7360\n",
            "Epoch 461/1000\n",
            "766/766 [==============================] - 1s 852us/sample - loss: 0.8238 - accuracy: 0.7344\n",
            "Epoch 462/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 0.8157 - accuracy: 0.7395\n",
            "Epoch 463/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 0.8088 - accuracy: 0.7413\n",
            "Epoch 464/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 0.8056 - accuracy: 0.7433\n",
            "Epoch 465/1000\n",
            "766/766 [==============================] - 1s 826us/sample - loss: 0.7996 - accuracy: 0.7439\n",
            "Epoch 466/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 0.8040 - accuracy: 0.7431\n",
            "Epoch 467/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 0.8054 - accuracy: 0.7438\n",
            "Epoch 468/1000\n",
            "766/766 [==============================] - 1s 829us/sample - loss: 0.8029 - accuracy: 0.7432\n",
            "Epoch 469/1000\n",
            "766/766 [==============================] - 1s 828us/sample - loss: 0.8149 - accuracy: 0.7388\n",
            "Epoch 470/1000\n",
            "766/766 [==============================] - 1s 850us/sample - loss: 0.8117 - accuracy: 0.7384\n",
            "Epoch 471/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 0.8063 - accuracy: 0.7414\n",
            "Epoch 472/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 0.8065 - accuracy: 0.7410\n",
            "Epoch 473/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 0.8059 - accuracy: 0.7420\n",
            "Epoch 474/1000\n",
            "766/766 [==============================] - 1s 849us/sample - loss: 0.8072 - accuracy: 0.7421\n",
            "Epoch 475/1000\n",
            "766/766 [==============================] - 1s 826us/sample - loss: 0.8044 - accuracy: 0.7419\n",
            "Epoch 476/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 0.8028 - accuracy: 0.7443\n",
            "Epoch 477/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 0.8087 - accuracy: 0.7410\n",
            "Epoch 478/1000\n",
            "766/766 [==============================] - 1s 845us/sample - loss: 0.8004 - accuracy: 0.7433\n",
            "Epoch 479/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.7919 - accuracy: 0.7460\n",
            "Epoch 480/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 0.7976 - accuracy: 0.7444\n",
            "Epoch 481/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 0.8058 - accuracy: 0.7416\n",
            "Epoch 482/1000\n",
            "766/766 [==============================] - 1s 857us/sample - loss: 0.8119 - accuracy: 0.7395\n",
            "Epoch 483/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 0.8142 - accuracy: 0.7390\n",
            "Epoch 484/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.8115 - accuracy: 0.7401\n",
            "Epoch 485/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 0.8188 - accuracy: 0.7365\n",
            "Epoch 486/1000\n",
            "766/766 [==============================] - 1s 823us/sample - loss: 0.8108 - accuracy: 0.7398\n",
            "Epoch 487/1000\n",
            "766/766 [==============================] - 1s 849us/sample - loss: 0.8007 - accuracy: 0.7423\n",
            "Epoch 488/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.7948 - accuracy: 0.7450\n",
            "Epoch 489/1000\n",
            "766/766 [==============================] - 1s 847us/sample - loss: 0.7942 - accuracy: 0.7459\n",
            "Epoch 490/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 0.7975 - accuracy: 0.7444\n",
            "Epoch 491/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 0.8056 - accuracy: 0.7417\n",
            "Epoch 492/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 0.8045 - accuracy: 0.7416\n",
            "Epoch 493/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 0.7962 - accuracy: 0.7435\n",
            "Epoch 494/1000\n",
            "766/766 [==============================] - 1s 861us/sample - loss: 0.7891 - accuracy: 0.7450\n",
            "Epoch 495/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 0.7947 - accuracy: 0.7464\n",
            "Epoch 496/1000\n",
            "766/766 [==============================] - 1s 852us/sample - loss: 0.7939 - accuracy: 0.7462\n",
            "Epoch 497/1000\n",
            "766/766 [==============================] - 1s 840us/sample - loss: 0.7899 - accuracy: 0.7469\n",
            "Epoch 498/1000\n",
            "766/766 [==============================] - 1s 854us/sample - loss: 0.7897 - accuracy: 0.7469\n",
            "Epoch 499/1000\n",
            "766/766 [==============================] - 1s 849us/sample - loss: 0.8007 - accuracy: 0.7433\n",
            "Epoch 500/1000\n",
            "766/766 [==============================] - 1s 853us/sample - loss: 0.7981 - accuracy: 0.7439\n",
            "Epoch 501/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 0.7964 - accuracy: 0.7444\n",
            "Epoch 502/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.7879 - accuracy: 0.7476\n",
            "Epoch 503/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 0.7895 - accuracy: 0.7467\n",
            "Epoch 504/1000\n",
            "766/766 [==============================] - 1s 848us/sample - loss: 0.7919 - accuracy: 0.7450\n",
            "Epoch 505/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 0.7943 - accuracy: 0.7466\n",
            "Epoch 506/1000\n",
            "766/766 [==============================] - 1s 852us/sample - loss: 0.8008 - accuracy: 0.7433\n",
            "Epoch 507/1000\n",
            "766/766 [==============================] - 1s 828us/sample - loss: 0.8092 - accuracy: 0.7386\n",
            "Epoch 508/1000\n",
            "766/766 [==============================] - 1s 853us/sample - loss: 0.7874 - accuracy: 0.7485\n",
            "Epoch 509/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 0.7867 - accuracy: 0.7459\n",
            "Epoch 510/1000\n",
            "766/766 [==============================] - 1s 848us/sample - loss: 0.8017 - accuracy: 0.7414\n",
            "Epoch 511/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 0.8029 - accuracy: 0.7411\n",
            "Epoch 512/1000\n",
            "766/766 [==============================] - 1s 853us/sample - loss: 0.7999 - accuracy: 0.7430\n",
            "Epoch 513/1000\n",
            "766/766 [==============================] - 1s 840us/sample - loss: 0.7938 - accuracy: 0.7453\n",
            "Epoch 514/1000\n",
            "766/766 [==============================] - 1s 845us/sample - loss: 0.7863 - accuracy: 0.7487\n",
            "Epoch 515/1000\n",
            "766/766 [==============================] - 1s 836us/sample - loss: 0.7811 - accuracy: 0.7487\n",
            "Epoch 516/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 0.7807 - accuracy: 0.7511\n",
            "Epoch 517/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 0.7770 - accuracy: 0.7495\n",
            "Epoch 518/1000\n",
            "766/766 [==============================] - 1s 833us/sample - loss: 0.7847 - accuracy: 0.7496\n",
            "Epoch 519/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 0.7808 - accuracy: 0.7501\n",
            "Epoch 520/1000\n",
            "766/766 [==============================] - 1s 849us/sample - loss: 0.7906 - accuracy: 0.7465\n",
            "Epoch 521/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 0.7982 - accuracy: 0.7441\n",
            "Epoch 522/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 0.8054 - accuracy: 0.7409\n",
            "Epoch 523/1000\n",
            "766/766 [==============================] - 1s 836us/sample - loss: 0.7954 - accuracy: 0.7431\n",
            "Epoch 524/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 0.7937 - accuracy: 0.7445\n",
            "Epoch 525/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 0.7967 - accuracy: 0.7429\n",
            "Epoch 526/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 0.7983 - accuracy: 0.7425\n",
            "Epoch 527/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 0.7906 - accuracy: 0.7482\n",
            "Epoch 528/1000\n",
            "766/766 [==============================] - 1s 851us/sample - loss: 0.7890 - accuracy: 0.7461\n",
            "Epoch 529/1000\n",
            "766/766 [==============================] - 1s 836us/sample - loss: 0.7789 - accuracy: 0.7507\n",
            "Epoch 530/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 0.7735 - accuracy: 0.7509\n",
            "Epoch 531/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 0.7660 - accuracy: 0.7539\n",
            "Epoch 532/1000\n",
            "766/766 [==============================] - 1s 846us/sample - loss: 0.7639 - accuracy: 0.7564\n",
            "Epoch 533/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 0.7639 - accuracy: 0.7546\n",
            "Epoch 534/1000\n",
            "766/766 [==============================] - 1s 852us/sample - loss: 0.7728 - accuracy: 0.7513\n",
            "Epoch 535/1000\n",
            "766/766 [==============================] - 1s 824us/sample - loss: 0.7746 - accuracy: 0.7495\n",
            "Epoch 536/1000\n",
            "766/766 [==============================] - 1s 846us/sample - loss: 0.7724 - accuracy: 0.7521\n",
            "Epoch 537/1000\n",
            "766/766 [==============================] - 1s 830us/sample - loss: 0.7768 - accuracy: 0.7502\n",
            "Epoch 538/1000\n",
            "766/766 [==============================] - 1s 850us/sample - loss: 0.7960 - accuracy: 0.7431\n",
            "Epoch 539/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 0.8138 - accuracy: 0.7377\n",
            "Epoch 540/1000\n",
            "766/766 [==============================] - 1s 833us/sample - loss: 0.8104 - accuracy: 0.7392\n",
            "Epoch 541/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 0.7984 - accuracy: 0.7434\n",
            "Epoch 542/1000\n",
            "766/766 [==============================] - 1s 872us/sample - loss: 0.7860 - accuracy: 0.7466\n",
            "Epoch 543/1000\n",
            "766/766 [==============================] - 1s 840us/sample - loss: 0.7789 - accuracy: 0.7500\n",
            "Epoch 544/1000\n",
            "766/766 [==============================] - 1s 848us/sample - loss: 0.7870 - accuracy: 0.7446\n",
            "Epoch 545/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 0.7862 - accuracy: 0.7460\n",
            "Epoch 546/1000\n",
            "766/766 [==============================] - 1s 856us/sample - loss: 0.8007 - accuracy: 0.7416\n",
            "Epoch 547/1000\n",
            "766/766 [==============================] - 1s 850us/sample - loss: 0.8054 - accuracy: 0.7388\n",
            "Epoch 548/1000\n",
            "766/766 [==============================] - 1s 830us/sample - loss: 0.7874 - accuracy: 0.7464\n",
            "Epoch 549/1000\n",
            "766/766 [==============================] - 1s 846us/sample - loss: 0.7782 - accuracy: 0.7512\n",
            "Epoch 550/1000\n",
            "766/766 [==============================] - 1s 851us/sample - loss: 0.7718 - accuracy: 0.7533\n",
            "Epoch 551/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 0.7645 - accuracy: 0.7544\n",
            "Epoch 552/1000\n",
            "766/766 [==============================] - 1s 861us/sample - loss: 0.7661 - accuracy: 0.7533\n",
            "Epoch 553/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.7580 - accuracy: 0.7554\n",
            "Epoch 554/1000\n",
            "766/766 [==============================] - 1s 847us/sample - loss: 0.7592 - accuracy: 0.7567\n",
            "Epoch 555/1000\n",
            "766/766 [==============================] - 1s 855us/sample - loss: 0.7643 - accuracy: 0.7543\n",
            "Epoch 556/1000\n",
            "766/766 [==============================] - 1s 848us/sample - loss: 0.7675 - accuracy: 0.7542\n",
            "Epoch 557/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 0.7639 - accuracy: 0.7553\n",
            "Epoch 558/1000\n",
            "766/766 [==============================] - 1s 846us/sample - loss: 0.7871 - accuracy: 0.7463\n",
            "Epoch 559/1000\n",
            "766/766 [==============================] - 1s 830us/sample - loss: 0.7948 - accuracy: 0.7447\n",
            "Epoch 560/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 0.7975 - accuracy: 0.7428\n",
            "Epoch 561/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 0.7861 - accuracy: 0.7470\n",
            "Epoch 562/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 0.7758 - accuracy: 0.7491\n",
            "Epoch 563/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.7667 - accuracy: 0.7541\n",
            "Epoch 564/1000\n",
            "766/766 [==============================] - 1s 855us/sample - loss: 0.7614 - accuracy: 0.7552\n",
            "Epoch 565/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 0.7569 - accuracy: 0.7565\n",
            "Epoch 566/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 0.7611 - accuracy: 0.7559\n",
            "Epoch 567/1000\n",
            "766/766 [==============================] - 1s 853us/sample - loss: 0.7625 - accuracy: 0.7541\n",
            "Epoch 568/1000\n",
            "766/766 [==============================] - 1s 833us/sample - loss: 0.7611 - accuracy: 0.7554\n",
            "Epoch 569/1000\n",
            "766/766 [==============================] - 1s 842us/sample - loss: 0.7787 - accuracy: 0.7479\n",
            "Epoch 570/1000\n",
            "766/766 [==============================] - 1s 845us/sample - loss: 0.7750 - accuracy: 0.7506\n",
            "Epoch 571/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 0.7917 - accuracy: 0.7443\n",
            "Epoch 572/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 0.7781 - accuracy: 0.7481\n",
            "Epoch 573/1000\n",
            "766/766 [==============================] - 1s 825us/sample - loss: 0.7691 - accuracy: 0.7519\n",
            "Epoch 574/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 0.7609 - accuracy: 0.7565\n",
            "Epoch 575/1000\n",
            "766/766 [==============================] - 1s 848us/sample - loss: 0.7564 - accuracy: 0.7566\n",
            "Epoch 576/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.7528 - accuracy: 0.7582\n",
            "Epoch 577/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.7529 - accuracy: 0.7585\n",
            "Epoch 578/1000\n",
            "766/766 [==============================] - 1s 822us/sample - loss: 0.7539 - accuracy: 0.7577\n",
            "Epoch 579/1000\n",
            "766/766 [==============================] - 1s 827us/sample - loss: 0.7509 - accuracy: 0.7582\n",
            "Epoch 580/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 0.8153 - accuracy: 0.7373\n",
            "Epoch 581/1000\n",
            "766/766 [==============================] - 1s 822us/sample - loss: 0.8195 - accuracy: 0.7342\n",
            "Epoch 582/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.8314 - accuracy: 0.7319\n",
            "Epoch 583/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 0.8133 - accuracy: 0.7368\n",
            "Epoch 584/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 0.7967 - accuracy: 0.7427\n",
            "Epoch 585/1000\n",
            "766/766 [==============================] - 1s 829us/sample - loss: 0.7818 - accuracy: 0.7475\n",
            "Epoch 586/1000\n",
            "766/766 [==============================] - 1s 827us/sample - loss: 0.7771 - accuracy: 0.7506\n",
            "Epoch 587/1000\n",
            "766/766 [==============================] - 1s 825us/sample - loss: 0.7667 - accuracy: 0.7527\n",
            "Epoch 588/1000\n",
            "766/766 [==============================] - 1s 843us/sample - loss: 0.7578 - accuracy: 0.7562\n",
            "Epoch 589/1000\n",
            "766/766 [==============================] - 1s 824us/sample - loss: 0.7524 - accuracy: 0.7551\n",
            "Epoch 590/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.7431 - accuracy: 0.7616\n",
            "Epoch 591/1000\n",
            "766/766 [==============================] - 1s 829us/sample - loss: 0.7396 - accuracy: 0.7617\n",
            "Epoch 592/1000\n",
            "766/766 [==============================] - 1s 859us/sample - loss: 0.7355 - accuracy: 0.7629\n",
            "Epoch 593/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 0.7340 - accuracy: 0.7651\n",
            "Epoch 594/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.7355 - accuracy: 0.7644\n",
            "Epoch 595/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 0.7387 - accuracy: 0.7629\n",
            "Epoch 596/1000\n",
            "766/766 [==============================] - 1s 815us/sample - loss: 0.7410 - accuracy: 0.7613\n",
            "Epoch 597/1000\n",
            "766/766 [==============================] - 1s 828us/sample - loss: 0.7490 - accuracy: 0.7605\n",
            "Epoch 598/1000\n",
            "766/766 [==============================] - 1s 845us/sample - loss: 0.7461 - accuracy: 0.7599\n",
            "Epoch 599/1000\n",
            "766/766 [==============================] - 1s 827us/sample - loss: 0.7414 - accuracy: 0.7630\n",
            "Epoch 600/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 0.7506 - accuracy: 0.7576\n",
            "Epoch 601/1000\n",
            "766/766 [==============================] - 1s 819us/sample - loss: 0.7567 - accuracy: 0.7562\n",
            "Epoch 602/1000\n",
            "766/766 [==============================] - 1s 827us/sample - loss: 0.7597 - accuracy: 0.7553\n",
            "Epoch 603/1000\n",
            "766/766 [==============================] - 1s 817us/sample - loss: 0.7631 - accuracy: 0.7533\n",
            "Epoch 604/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.7774 - accuracy: 0.7490\n",
            "Epoch 605/1000\n",
            "766/766 [==============================] - 1s 818us/sample - loss: 0.7914 - accuracy: 0.7446\n",
            "Epoch 606/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 0.8005 - accuracy: 0.7406\n",
            "Epoch 607/1000\n",
            "766/766 [==============================] - 1s 836us/sample - loss: 0.7946 - accuracy: 0.7441\n",
            "Epoch 608/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.7875 - accuracy: 0.7461\n",
            "Epoch 609/1000\n",
            "766/766 [==============================] - 1s 853us/sample - loss: 0.7753 - accuracy: 0.7503\n",
            "Epoch 610/1000\n",
            "766/766 [==============================] - 1s 814us/sample - loss: 0.7757 - accuracy: 0.7495\n",
            "Epoch 611/1000\n",
            "766/766 [==============================] - 1s 823us/sample - loss: 0.7752 - accuracy: 0.7497\n",
            "Epoch 612/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 0.7595 - accuracy: 0.7556\n",
            "Epoch 613/1000\n",
            "766/766 [==============================] - 1s 819us/sample - loss: 0.7481 - accuracy: 0.7596\n",
            "Epoch 614/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 0.7367 - accuracy: 0.7641\n",
            "Epoch 615/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 0.7368 - accuracy: 0.7630\n",
            "Epoch 616/1000\n",
            "766/766 [==============================] - 1s 830us/sample - loss: 0.7312 - accuracy: 0.7650\n",
            "Epoch 617/1000\n",
            "766/766 [==============================] - 1s 823us/sample - loss: 0.7275 - accuracy: 0.7663\n",
            "Epoch 618/1000\n",
            "766/766 [==============================] - 1s 829us/sample - loss: 0.7276 - accuracy: 0.7676\n",
            "Epoch 619/1000\n",
            "766/766 [==============================] - 1s 825us/sample - loss: 0.7271 - accuracy: 0.7664\n",
            "Epoch 620/1000\n",
            "766/766 [==============================] - 1s 836us/sample - loss: 0.7288 - accuracy: 0.7666\n",
            "Epoch 621/1000\n",
            "766/766 [==============================] - 1s 816us/sample - loss: 0.7400 - accuracy: 0.7613\n",
            "Epoch 622/1000\n",
            "766/766 [==============================] - 1s 848us/sample - loss: 0.7446 - accuracy: 0.7608\n",
            "Epoch 623/1000\n",
            "766/766 [==============================] - 1s 814us/sample - loss: 0.7548 - accuracy: 0.7558\n",
            "Epoch 624/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 0.7612 - accuracy: 0.7536\n",
            "Epoch 625/1000\n",
            "766/766 [==============================] - 1s 854us/sample - loss: 0.7657 - accuracy: 0.7524\n",
            "Epoch 626/1000\n",
            "766/766 [==============================] - 1s 855us/sample - loss: 0.7724 - accuracy: 0.7502\n",
            "Epoch 627/1000\n",
            "766/766 [==============================] - 1s 833us/sample - loss: 0.7827 - accuracy: 0.7479\n",
            "Epoch 628/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 0.7706 - accuracy: 0.7500\n",
            "Epoch 629/1000\n",
            "766/766 [==============================] - 1s 829us/sample - loss: 0.7604 - accuracy: 0.7528\n",
            "Epoch 630/1000\n",
            "766/766 [==============================] - 1s 827us/sample - loss: 0.7606 - accuracy: 0.7547\n",
            "Epoch 631/1000\n",
            "766/766 [==============================] - 1s 803us/sample - loss: 0.7545 - accuracy: 0.7548\n",
            "Epoch 632/1000\n",
            "766/766 [==============================] - 1s 820us/sample - loss: 0.7731 - accuracy: 0.7493\n",
            "Epoch 633/1000\n",
            "766/766 [==============================] - 1s 830us/sample - loss: 0.7851 - accuracy: 0.7473\n",
            "Epoch 634/1000\n",
            "766/766 [==============================] - 1s 823us/sample - loss: 0.7781 - accuracy: 0.7482\n",
            "Epoch 635/1000\n",
            "766/766 [==============================] - 1s 827us/sample - loss: 0.7623 - accuracy: 0.7542\n",
            "Epoch 636/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.7542 - accuracy: 0.7577\n",
            "Epoch 637/1000\n",
            "766/766 [==============================] - 1s 824us/sample - loss: 0.7478 - accuracy: 0.7576\n",
            "Epoch 638/1000\n",
            "766/766 [==============================] - 1s 845us/sample - loss: 0.7419 - accuracy: 0.7611\n",
            "Epoch 639/1000\n",
            "766/766 [==============================] - 1s 829us/sample - loss: 0.7340 - accuracy: 0.7627\n",
            "Epoch 640/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 0.7349 - accuracy: 0.7615\n",
            "Epoch 641/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.7229 - accuracy: 0.7676\n",
            "Epoch 642/1000\n",
            "766/766 [==============================] - 1s 822us/sample - loss: 0.7294 - accuracy: 0.7648\n",
            "Epoch 643/1000\n",
            "766/766 [==============================] - 1s 816us/sample - loss: 0.7236 - accuracy: 0.7659\n",
            "Epoch 644/1000\n",
            "766/766 [==============================] - 1s 826us/sample - loss: 0.7228 - accuracy: 0.7677\n",
            "Epoch 645/1000\n",
            "766/766 [==============================] - 1s 823us/sample - loss: 0.7311 - accuracy: 0.7648\n",
            "Epoch 646/1000\n",
            "766/766 [==============================] - 1s 824us/sample - loss: 0.7436 - accuracy: 0.7578\n",
            "Epoch 647/1000\n",
            "766/766 [==============================] - 1s 817us/sample - loss: 0.7527 - accuracy: 0.7564\n",
            "Epoch 648/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 0.7466 - accuracy: 0.7591\n",
            "Epoch 649/1000\n",
            "766/766 [==============================] - 1s 821us/sample - loss: 0.7444 - accuracy: 0.7610\n",
            "Epoch 650/1000\n",
            "766/766 [==============================] - 1s 820us/sample - loss: 0.7426 - accuracy: 0.7603\n",
            "Epoch 651/1000\n",
            "766/766 [==============================] - 1s 827us/sample - loss: 0.7344 - accuracy: 0.7630\n",
            "Epoch 652/1000\n",
            "766/766 [==============================] - 1s 825us/sample - loss: 0.7327 - accuracy: 0.7640\n",
            "Epoch 653/1000\n",
            "766/766 [==============================] - 1s 827us/sample - loss: 0.7368 - accuracy: 0.7628\n",
            "Epoch 654/1000\n",
            "766/766 [==============================] - 1s 835us/sample - loss: 0.7435 - accuracy: 0.7592\n",
            "Epoch 655/1000\n",
            "766/766 [==============================] - 1s 822us/sample - loss: 0.7369 - accuracy: 0.7623\n",
            "Epoch 656/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 0.7345 - accuracy: 0.7626\n",
            "Epoch 657/1000\n",
            "766/766 [==============================] - 1s 820us/sample - loss: 0.7325 - accuracy: 0.7647\n",
            "Epoch 658/1000\n",
            "766/766 [==============================] - 1s 825us/sample - loss: 0.7282 - accuracy: 0.7658\n",
            "Epoch 659/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.7295 - accuracy: 0.7650\n",
            "Epoch 660/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 0.7402 - accuracy: 0.7616\n",
            "Epoch 661/1000\n",
            "766/766 [==============================] - 1s 817us/sample - loss: 0.7482 - accuracy: 0.7584\n",
            "Epoch 662/1000\n",
            "766/766 [==============================] - 1s 841us/sample - loss: 0.7450 - accuracy: 0.7580\n",
            "Epoch 663/1000\n",
            "766/766 [==============================] - 1s 823us/sample - loss: 0.7486 - accuracy: 0.7586\n",
            "Epoch 664/1000\n",
            "766/766 [==============================] - 1s 822us/sample - loss: 0.7471 - accuracy: 0.7577\n",
            "Epoch 665/1000\n",
            "766/766 [==============================] - 1s 805us/sample - loss: 0.7416 - accuracy: 0.7609\n",
            "Epoch 666/1000\n",
            "766/766 [==============================] - 1s 816us/sample - loss: 0.7414 - accuracy: 0.7605\n",
            "Epoch 667/1000\n",
            "766/766 [==============================] - 1s 819us/sample - loss: 0.7307 - accuracy: 0.7622\n",
            "Epoch 668/1000\n",
            "766/766 [==============================] - 1s 817us/sample - loss: 0.7314 - accuracy: 0.7642\n",
            "Epoch 669/1000\n",
            "766/766 [==============================] - 1s 805us/sample - loss: 0.7271 - accuracy: 0.7637\n",
            "Epoch 670/1000\n",
            "766/766 [==============================] - 1s 825us/sample - loss: 0.7380 - accuracy: 0.7605\n",
            "Epoch 671/1000\n",
            "766/766 [==============================] - 1s 790us/sample - loss: 0.7325 - accuracy: 0.7638\n",
            "Epoch 672/1000\n",
            "766/766 [==============================] - 1s 817us/sample - loss: 0.7336 - accuracy: 0.7634\n",
            "Epoch 673/1000\n",
            "766/766 [==============================] - 1s 811us/sample - loss: 0.7798 - accuracy: 0.7475\n",
            "Epoch 674/1000\n",
            "766/766 [==============================] - 1s 807us/sample - loss: 0.7737 - accuracy: 0.7490\n",
            "Epoch 675/1000\n",
            "766/766 [==============================] - 1s 811us/sample - loss: 0.8120 - accuracy: 0.7366\n",
            "Epoch 676/1000\n",
            "766/766 [==============================] - 1s 809us/sample - loss: 0.8039 - accuracy: 0.7387\n",
            "Epoch 677/1000\n",
            "766/766 [==============================] - 1s 817us/sample - loss: 0.8081 - accuracy: 0.7380\n",
            "Epoch 678/1000\n",
            "766/766 [==============================] - 1s 809us/sample - loss: 0.7815 - accuracy: 0.7459\n",
            "Epoch 679/1000\n",
            "766/766 [==============================] - 1s 814us/sample - loss: 0.7694 - accuracy: 0.7490\n",
            "Epoch 680/1000\n",
            "766/766 [==============================] - 1s 813us/sample - loss: 0.7529 - accuracy: 0.7560\n",
            "Epoch 681/1000\n",
            "766/766 [==============================] - 1s 816us/sample - loss: 0.7346 - accuracy: 0.7642\n",
            "Epoch 682/1000\n",
            "766/766 [==============================] - 1s 808us/sample - loss: 0.7249 - accuracy: 0.7663\n",
            "Epoch 683/1000\n",
            "766/766 [==============================] - 1s 824us/sample - loss: 0.7129 - accuracy: 0.7702\n",
            "Epoch 684/1000\n",
            "766/766 [==============================] - 1s 822us/sample - loss: 0.7133 - accuracy: 0.7708\n",
            "Epoch 685/1000\n",
            "766/766 [==============================] - 1s 810us/sample - loss: 0.7095 - accuracy: 0.7730\n",
            "Epoch 686/1000\n",
            "766/766 [==============================] - 1s 828us/sample - loss: 0.7087 - accuracy: 0.7714\n",
            "Epoch 687/1000\n",
            "766/766 [==============================] - 1s 810us/sample - loss: 0.7095 - accuracy: 0.7723\n",
            "Epoch 688/1000\n",
            "766/766 [==============================] - 1s 823us/sample - loss: 0.7069 - accuracy: 0.7721\n",
            "Epoch 689/1000\n",
            "766/766 [==============================] - 1s 816us/sample - loss: 0.7042 - accuracy: 0.7741\n",
            "Epoch 690/1000\n",
            "766/766 [==============================] - 1s 824us/sample - loss: 0.7069 - accuracy: 0.7709\n",
            "Epoch 691/1000\n",
            "766/766 [==============================] - 1s 820us/sample - loss: 0.7129 - accuracy: 0.7699\n",
            "Epoch 692/1000\n",
            "766/766 [==============================] - 1s 818us/sample - loss: 0.7166 - accuracy: 0.7692\n",
            "Epoch 693/1000\n",
            "766/766 [==============================] - 1s 822us/sample - loss: 0.7222 - accuracy: 0.7680\n",
            "Epoch 694/1000\n",
            "766/766 [==============================] - 1s 822us/sample - loss: 0.7248 - accuracy: 0.7657\n",
            "Epoch 695/1000\n",
            "766/766 [==============================] - 1s 802us/sample - loss: 0.7220 - accuracy: 0.7659\n",
            "Epoch 696/1000\n",
            "766/766 [==============================] - 1s 821us/sample - loss: 0.7358 - accuracy: 0.7613\n",
            "Epoch 697/1000\n",
            "766/766 [==============================] - 1s 813us/sample - loss: 0.7365 - accuracy: 0.7615\n",
            "Epoch 698/1000\n",
            "766/766 [==============================] - 1s 817us/sample - loss: 0.7484 - accuracy: 0.7581\n",
            "Epoch 699/1000\n",
            "766/766 [==============================] - 1s 813us/sample - loss: 0.7535 - accuracy: 0.7563\n",
            "Epoch 700/1000\n",
            "766/766 [==============================] - 1s 827us/sample - loss: 0.7633 - accuracy: 0.7521\n",
            "Epoch 701/1000\n",
            "766/766 [==============================] - 1s 834us/sample - loss: 0.7706 - accuracy: 0.7501\n",
            "Epoch 702/1000\n",
            "766/766 [==============================] - 1s 815us/sample - loss: 0.7811 - accuracy: 0.7477\n",
            "Epoch 703/1000\n",
            "766/766 [==============================] - 1s 815us/sample - loss: 0.7664 - accuracy: 0.7518\n",
            "Epoch 704/1000\n",
            "766/766 [==============================] - 1s 814us/sample - loss: 0.7448 - accuracy: 0.7586\n",
            "Epoch 705/1000\n",
            "766/766 [==============================] - 1s 808us/sample - loss: 0.7357 - accuracy: 0.7621\n",
            "Epoch 706/1000\n",
            "766/766 [==============================] - 1s 804us/sample - loss: 0.7166 - accuracy: 0.7671\n",
            "Epoch 707/1000\n",
            "766/766 [==============================] - 1s 805us/sample - loss: 0.7171 - accuracy: 0.7677\n",
            "Epoch 708/1000\n",
            "766/766 [==============================] - 1s 807us/sample - loss: 0.7111 - accuracy: 0.7701\n",
            "Epoch 709/1000\n",
            "766/766 [==============================] - 1s 833us/sample - loss: 0.7155 - accuracy: 0.7700\n",
            "Epoch 710/1000\n",
            "766/766 [==============================] - 1s 814us/sample - loss: 0.7114 - accuracy: 0.7709\n",
            "Epoch 711/1000\n",
            "766/766 [==============================] - 1s 818us/sample - loss: 0.7068 - accuracy: 0.7727\n",
            "Epoch 712/1000\n",
            "766/766 [==============================] - 1s 808us/sample - loss: 0.7089 - accuracy: 0.7714\n",
            "Epoch 713/1000\n",
            "766/766 [==============================] - 1s 816us/sample - loss: 0.7059 - accuracy: 0.7730\n",
            "Epoch 714/1000\n",
            "766/766 [==============================] - 1s 826us/sample - loss: 0.7136 - accuracy: 0.7693\n",
            "Epoch 715/1000\n",
            "766/766 [==============================] - 1s 799us/sample - loss: 0.7094 - accuracy: 0.7708\n",
            "Epoch 716/1000\n",
            "766/766 [==============================] - 1s 817us/sample - loss: 0.7104 - accuracy: 0.7702\n",
            "Epoch 717/1000\n",
            "766/766 [==============================] - 1s 815us/sample - loss: 0.7175 - accuracy: 0.7682\n",
            "Epoch 718/1000\n",
            "766/766 [==============================] - 1s 804us/sample - loss: 0.7224 - accuracy: 0.7668\n",
            "Epoch 719/1000\n",
            "766/766 [==============================] - 1s 815us/sample - loss: 0.7282 - accuracy: 0.7652\n",
            "Epoch 720/1000\n",
            "766/766 [==============================] - 1s 829us/sample - loss: 0.7294 - accuracy: 0.7648\n",
            "Epoch 721/1000\n",
            "766/766 [==============================] - 1s 817us/sample - loss: 0.7226 - accuracy: 0.7656\n",
            "Epoch 722/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.7215 - accuracy: 0.7652\n",
            "Epoch 723/1000\n",
            "766/766 [==============================] - 1s 802us/sample - loss: 0.7208 - accuracy: 0.7655\n",
            "Epoch 724/1000\n",
            "766/766 [==============================] - 1s 829us/sample - loss: 0.7198 - accuracy: 0.7688\n",
            "Epoch 725/1000\n",
            "766/766 [==============================] - 1s 820us/sample - loss: 0.7267 - accuracy: 0.7647\n",
            "Epoch 726/1000\n",
            "766/766 [==============================] - 1s 826us/sample - loss: 0.7258 - accuracy: 0.7649\n",
            "Epoch 727/1000\n",
            "766/766 [==============================] - 1s 815us/sample - loss: 0.7270 - accuracy: 0.7657\n",
            "Epoch 728/1000\n",
            "766/766 [==============================] - 1s 811us/sample - loss: 0.7408 - accuracy: 0.7597\n",
            "Epoch 729/1000\n",
            "766/766 [==============================] - 1s 813us/sample - loss: 0.7303 - accuracy: 0.7628\n",
            "Epoch 730/1000\n",
            "766/766 [==============================] - 1s 816us/sample - loss: 0.7274 - accuracy: 0.7650\n",
            "Epoch 731/1000\n",
            "766/766 [==============================] - 1s 820us/sample - loss: 0.7222 - accuracy: 0.7669\n",
            "Epoch 732/1000\n",
            "766/766 [==============================] - 1s 828us/sample - loss: 0.7197 - accuracy: 0.7664\n",
            "Epoch 733/1000\n",
            "766/766 [==============================] - 1s 811us/sample - loss: 0.7132 - accuracy: 0.7692\n",
            "Epoch 734/1000\n",
            "766/766 [==============================] - 1s 814us/sample - loss: 0.7113 - accuracy: 0.7700\n",
            "Epoch 735/1000\n",
            "766/766 [==============================] - 1s 810us/sample - loss: 0.7067 - accuracy: 0.7712\n",
            "Epoch 736/1000\n",
            "766/766 [==============================] - 1s 818us/sample - loss: 0.7029 - accuracy: 0.7727\n",
            "Epoch 737/1000\n",
            "766/766 [==============================] - 1s 812us/sample - loss: 0.7150 - accuracy: 0.7686\n",
            "Epoch 738/1000\n",
            "766/766 [==============================] - 1s 815us/sample - loss: 0.7077 - accuracy: 0.7706\n",
            "Epoch 739/1000\n",
            "766/766 [==============================] - 1s 799us/sample - loss: 0.7232 - accuracy: 0.7666\n",
            "Epoch 740/1000\n",
            "766/766 [==============================] - 1s 814us/sample - loss: 0.7359 - accuracy: 0.7639\n",
            "Epoch 741/1000\n",
            "766/766 [==============================] - 1s 771us/sample - loss: 0.7775 - accuracy: 0.7472\n",
            "Epoch 742/1000\n",
            "766/766 [==============================] - 1s 817us/sample - loss: 0.8126 - accuracy: 0.7367\n",
            "Epoch 743/1000\n",
            "766/766 [==============================] - 1s 830us/sample - loss: 0.8000 - accuracy: 0.7399\n",
            "Epoch 744/1000\n",
            "766/766 [==============================] - 1s 792us/sample - loss: 0.7730 - accuracy: 0.7494\n",
            "Epoch 745/1000\n",
            "766/766 [==============================] - 1s 796us/sample - loss: 0.7639 - accuracy: 0.7526\n",
            "Epoch 746/1000\n",
            "766/766 [==============================] - 1s 795us/sample - loss: 0.7437 - accuracy: 0.7584\n",
            "Epoch 747/1000\n",
            "766/766 [==============================] - 1s 798us/sample - loss: 0.7325 - accuracy: 0.7613\n",
            "Epoch 748/1000\n",
            "766/766 [==============================] - 1s 818us/sample - loss: 0.7237 - accuracy: 0.7648\n",
            "Epoch 749/1000\n",
            "766/766 [==============================] - 1s 798us/sample - loss: 0.7108 - accuracy: 0.7677\n",
            "Epoch 750/1000\n",
            "766/766 [==============================] - 1s 800us/sample - loss: 0.7030 - accuracy: 0.7722\n",
            "Epoch 751/1000\n",
            "766/766 [==============================] - 1s 781us/sample - loss: 0.7069 - accuracy: 0.7695\n",
            "Epoch 752/1000\n",
            "766/766 [==============================] - 1s 795us/sample - loss: 0.7109 - accuracy: 0.7698\n",
            "Epoch 753/1000\n",
            "766/766 [==============================] - 1s 786us/sample - loss: 0.7053 - accuracy: 0.7722\n",
            "Epoch 754/1000\n",
            "766/766 [==============================] - 1s 801us/sample - loss: 0.7100 - accuracy: 0.7704\n",
            "Epoch 755/1000\n",
            "766/766 [==============================] - 1s 797us/sample - loss: 0.6990 - accuracy: 0.7738\n",
            "Epoch 756/1000\n",
            "766/766 [==============================] - 1s 804us/sample - loss: 0.6999 - accuracy: 0.7735\n",
            "Epoch 757/1000\n",
            "766/766 [==============================] - 1s 801us/sample - loss: 0.6907 - accuracy: 0.7774\n",
            "Epoch 758/1000\n",
            "766/766 [==============================] - 1s 801us/sample - loss: 0.6931 - accuracy: 0.7757\n",
            "Epoch 759/1000\n",
            "766/766 [==============================] - 1s 794us/sample - loss: 0.6881 - accuracy: 0.7781\n",
            "Epoch 760/1000\n",
            "766/766 [==============================] - 1s 810us/sample - loss: 0.6999 - accuracy: 0.7750\n",
            "Epoch 761/1000\n",
            "766/766 [==============================] - 1s 782us/sample - loss: 0.7097 - accuracy: 0.7718\n",
            "Epoch 762/1000\n",
            "766/766 [==============================] - 1s 819us/sample - loss: 0.7418 - accuracy: 0.7594\n",
            "Epoch 763/1000\n",
            "766/766 [==============================] - 1s 791us/sample - loss: 0.7405 - accuracy: 0.7597\n",
            "Epoch 764/1000\n",
            "766/766 [==============================] - 1s 810us/sample - loss: 0.7316 - accuracy: 0.7620\n",
            "Epoch 765/1000\n",
            "766/766 [==============================] - 1s 805us/sample - loss: 0.7306 - accuracy: 0.7626\n",
            "Epoch 766/1000\n",
            "766/766 [==============================] - 1s 802us/sample - loss: 0.7384 - accuracy: 0.7614\n",
            "Epoch 767/1000\n",
            "766/766 [==============================] - 1s 803us/sample - loss: 0.7346 - accuracy: 0.7617\n",
            "Epoch 768/1000\n",
            "766/766 [==============================] - 1s 807us/sample - loss: 0.7305 - accuracy: 0.7636\n",
            "Epoch 769/1000\n",
            "766/766 [==============================] - 1s 799us/sample - loss: 0.7317 - accuracy: 0.7630\n",
            "Epoch 770/1000\n",
            "766/766 [==============================] - 1s 810us/sample - loss: 0.7268 - accuracy: 0.7645\n",
            "Epoch 771/1000\n",
            "766/766 [==============================] - 1s 774us/sample - loss: 0.7172 - accuracy: 0.7675\n",
            "Epoch 772/1000\n",
            "766/766 [==============================] - 1s 809us/sample - loss: 0.7098 - accuracy: 0.7695\n",
            "Epoch 773/1000\n",
            "766/766 [==============================] - 1s 802us/sample - loss: 0.7060 - accuracy: 0.7722\n",
            "Epoch 774/1000\n",
            "766/766 [==============================] - 1s 808us/sample - loss: 0.7034 - accuracy: 0.7724\n",
            "Epoch 775/1000\n",
            "766/766 [==============================] - 1s 805us/sample - loss: 0.6955 - accuracy: 0.7745\n",
            "Epoch 776/1000\n",
            "766/766 [==============================] - 1s 807us/sample - loss: 0.6925 - accuracy: 0.7771\n",
            "Epoch 777/1000\n",
            "766/766 [==============================] - 1s 799us/sample - loss: 0.6873 - accuracy: 0.7765\n",
            "Epoch 778/1000\n",
            "766/766 [==============================] - 1s 820us/sample - loss: 0.6877 - accuracy: 0.7791\n",
            "Epoch 779/1000\n",
            "766/766 [==============================] - 1s 789us/sample - loss: 0.6893 - accuracy: 0.7767\n",
            "Epoch 780/1000\n",
            "766/766 [==============================] - 1s 839us/sample - loss: 0.6928 - accuracy: 0.7760\n",
            "Epoch 781/1000\n",
            "766/766 [==============================] - 1s 792us/sample - loss: 0.6929 - accuracy: 0.7766\n",
            "Epoch 782/1000\n",
            "766/766 [==============================] - 1s 813us/sample - loss: 0.6887 - accuracy: 0.7775\n",
            "Epoch 783/1000\n",
            "766/766 [==============================] - 1s 802us/sample - loss: 0.6932 - accuracy: 0.7755\n",
            "Epoch 784/1000\n",
            "766/766 [==============================] - 1s 811us/sample - loss: 0.6943 - accuracy: 0.7764\n",
            "Epoch 785/1000\n",
            "766/766 [==============================] - 1s 803us/sample - loss: 0.7047 - accuracy: 0.7711\n",
            "Epoch 786/1000\n",
            "766/766 [==============================] - 1s 822us/sample - loss: 0.7172 - accuracy: 0.7677\n",
            "Epoch 787/1000\n",
            "766/766 [==============================] - 1s 807us/sample - loss: 0.7298 - accuracy: 0.7648\n",
            "Epoch 788/1000\n",
            "766/766 [==============================] - 1s 818us/sample - loss: 0.7426 - accuracy: 0.7574\n",
            "Epoch 789/1000\n",
            "766/766 [==============================] - 1s 797us/sample - loss: 0.7491 - accuracy: 0.7554\n",
            "Epoch 790/1000\n",
            "766/766 [==============================] - 1s 808us/sample - loss: 0.7487 - accuracy: 0.7567\n",
            "Epoch 791/1000\n",
            "766/766 [==============================] - 1s 845us/sample - loss: 0.7528 - accuracy: 0.7568\n",
            "Epoch 792/1000\n",
            "766/766 [==============================] - 1s 809us/sample - loss: 0.7608 - accuracy: 0.7531\n",
            "Epoch 793/1000\n",
            "766/766 [==============================] - 1s 832us/sample - loss: 0.7550 - accuracy: 0.7532\n",
            "Epoch 794/1000\n",
            "766/766 [==============================] - 1s 844us/sample - loss: 0.7382 - accuracy: 0.7613\n",
            "Epoch 795/1000\n",
            "766/766 [==============================] - 1s 847us/sample - loss: 0.7531 - accuracy: 0.7559\n",
            "Epoch 796/1000\n",
            "766/766 [==============================] - 1s 815us/sample - loss: 0.7486 - accuracy: 0.7574\n",
            "Epoch 797/1000\n",
            "766/766 [==============================] - 1s 808us/sample - loss: 0.7349 - accuracy: 0.7616\n",
            "Epoch 798/1000\n",
            "766/766 [==============================] - 1s 789us/sample - loss: 0.7157 - accuracy: 0.7679\n",
            "Epoch 799/1000\n",
            "766/766 [==============================] - 1s 805us/sample - loss: 0.7052 - accuracy: 0.7701\n",
            "Epoch 800/1000\n",
            "766/766 [==============================] - 1s 793us/sample - loss: 0.6997 - accuracy: 0.7745\n",
            "Epoch 801/1000\n",
            "766/766 [==============================] - 1s 794us/sample - loss: 0.7029 - accuracy: 0.7727\n",
            "Epoch 802/1000\n",
            "766/766 [==============================] - 1s 797us/sample - loss: 0.7088 - accuracy: 0.7699\n",
            "Epoch 803/1000\n",
            "766/766 [==============================] - 1s 814us/sample - loss: 0.6975 - accuracy: 0.7742\n",
            "Epoch 804/1000\n",
            "766/766 [==============================] - 1s 816us/sample - loss: 0.6942 - accuracy: 0.7758\n",
            "Epoch 805/1000\n",
            "766/766 [==============================] - 1s 781us/sample - loss: 0.6951 - accuracy: 0.7755\n",
            "Epoch 806/1000\n",
            "766/766 [==============================] - 1s 805us/sample - loss: 0.6915 - accuracy: 0.7776\n",
            "Epoch 807/1000\n",
            "766/766 [==============================] - 1s 792us/sample - loss: 0.6884 - accuracy: 0.7762\n",
            "Epoch 808/1000\n",
            "766/766 [==============================] - 1s 795us/sample - loss: 0.6823 - accuracy: 0.7782\n",
            "Epoch 809/1000\n",
            "766/766 [==============================] - 1s 791us/sample - loss: 0.6786 - accuracy: 0.7818\n",
            "Epoch 810/1000\n",
            "766/766 [==============================] - 1s 798us/sample - loss: 0.6720 - accuracy: 0.7835\n",
            "Epoch 811/1000\n",
            "766/766 [==============================] - 1s 813us/sample - loss: 0.6728 - accuracy: 0.7830\n",
            "Epoch 812/1000\n",
            "766/766 [==============================] - 1s 818us/sample - loss: 0.6756 - accuracy: 0.7817\n",
            "Epoch 813/1000\n",
            "766/766 [==============================] - 1s 806us/sample - loss: 0.6736 - accuracy: 0.7822\n",
            "Epoch 814/1000\n",
            "766/766 [==============================] - 1s 828us/sample - loss: 0.6712 - accuracy: 0.7842\n",
            "Epoch 815/1000\n",
            "766/766 [==============================] - 1s 795us/sample - loss: 0.6794 - accuracy: 0.7797\n",
            "Epoch 816/1000\n",
            "766/766 [==============================] - 1s 806us/sample - loss: 0.6851 - accuracy: 0.7764\n",
            "Epoch 817/1000\n",
            "766/766 [==============================] - 1s 789us/sample - loss: 0.6925 - accuracy: 0.7756\n",
            "Epoch 818/1000\n",
            "766/766 [==============================] - 1s 803us/sample - loss: 0.7006 - accuracy: 0.7747\n",
            "Epoch 819/1000\n",
            "766/766 [==============================] - 1s 803us/sample - loss: 0.7182 - accuracy: 0.7669\n",
            "Epoch 820/1000\n",
            "766/766 [==============================] - 1s 811us/sample - loss: 0.7272 - accuracy: 0.7625\n",
            "Epoch 821/1000\n",
            "766/766 [==============================] - 1s 797us/sample - loss: 0.7250 - accuracy: 0.7649\n",
            "Epoch 822/1000\n",
            "766/766 [==============================] - 1s 800us/sample - loss: 0.7322 - accuracy: 0.7613\n",
            "Epoch 823/1000\n",
            "766/766 [==============================] - 1s 778us/sample - loss: 0.7332 - accuracy: 0.7627\n",
            "Epoch 824/1000\n",
            "766/766 [==============================] - 1s 815us/sample - loss: 0.7157 - accuracy: 0.7668\n",
            "Epoch 825/1000\n",
            "766/766 [==============================] - 1s 802us/sample - loss: 0.7247 - accuracy: 0.7654\n",
            "Epoch 826/1000\n",
            "766/766 [==============================] - 1s 806us/sample - loss: 0.7118 - accuracy: 0.7698\n",
            "Epoch 827/1000\n",
            "766/766 [==============================] - 1s 784us/sample - loss: 0.7021 - accuracy: 0.7711\n",
            "Epoch 828/1000\n",
            "766/766 [==============================] - 1s 819us/sample - loss: 0.7193 - accuracy: 0.7662\n",
            "Epoch 829/1000\n",
            "766/766 [==============================] - 1s 815us/sample - loss: 0.7236 - accuracy: 0.7642\n",
            "Epoch 830/1000\n",
            "766/766 [==============================] - 1s 789us/sample - loss: 0.7135 - accuracy: 0.7674\n",
            "Epoch 831/1000\n",
            "766/766 [==============================] - 1s 792us/sample - loss: 0.7103 - accuracy: 0.7698\n",
            "Epoch 832/1000\n",
            "766/766 [==============================] - 1s 818us/sample - loss: 0.7142 - accuracy: 0.7681\n",
            "Epoch 833/1000\n",
            "766/766 [==============================] - 1s 788us/sample - loss: 0.7373 - accuracy: 0.7613\n",
            "Epoch 834/1000\n",
            "766/766 [==============================] - 1s 806us/sample - loss: 0.7370 - accuracy: 0.7599\n",
            "Epoch 835/1000\n",
            "766/766 [==============================] - 1s 790us/sample - loss: 0.7215 - accuracy: 0.7660\n",
            "Epoch 836/1000\n",
            "766/766 [==============================] - 1s 807us/sample - loss: 0.7118 - accuracy: 0.7698\n",
            "Epoch 837/1000\n",
            "766/766 [==============================] - 1s 815us/sample - loss: 0.7011 - accuracy: 0.7731\n",
            "Epoch 838/1000\n",
            "766/766 [==============================] - 1s 803us/sample - loss: 0.6936 - accuracy: 0.7747\n",
            "Epoch 839/1000\n",
            "766/766 [==============================] - 1s 808us/sample - loss: 0.6883 - accuracy: 0.7769\n",
            "Epoch 840/1000\n",
            "766/766 [==============================] - 1s 803us/sample - loss: 0.6787 - accuracy: 0.7794\n",
            "Epoch 841/1000\n",
            "766/766 [==============================] - 1s 792us/sample - loss: 0.6779 - accuracy: 0.7802\n",
            "Epoch 842/1000\n",
            "766/766 [==============================] - 1s 817us/sample - loss: 0.6724 - accuracy: 0.7826\n",
            "Epoch 843/1000\n",
            "766/766 [==============================] - 1s 803us/sample - loss: 0.6675 - accuracy: 0.7847\n",
            "Epoch 844/1000\n",
            "766/766 [==============================] - 1s 810us/sample - loss: 0.6670 - accuracy: 0.7844\n",
            "Epoch 845/1000\n",
            "766/766 [==============================] - 1s 774us/sample - loss: 0.6636 - accuracy: 0.7846\n",
            "Epoch 846/1000\n",
            "766/766 [==============================] - 1s 812us/sample - loss: 0.6763 - accuracy: 0.7816\n",
            "Epoch 847/1000\n",
            "766/766 [==============================] - 1s 785us/sample - loss: 0.6791 - accuracy: 0.7794\n",
            "Epoch 848/1000\n",
            "766/766 [==============================] - 1s 794us/sample - loss: 0.6830 - accuracy: 0.7798\n",
            "Epoch 849/1000\n",
            "766/766 [==============================] - 1s 791us/sample - loss: 0.6816 - accuracy: 0.7806\n",
            "Epoch 850/1000\n",
            "766/766 [==============================] - 1s 785us/sample - loss: 0.6934 - accuracy: 0.7749\n",
            "Epoch 851/1000\n",
            "766/766 [==============================] - 1s 791us/sample - loss: 0.6930 - accuracy: 0.7755\n",
            "Epoch 852/1000\n",
            "766/766 [==============================] - 1s 789us/sample - loss: 0.6908 - accuracy: 0.7772\n",
            "Epoch 853/1000\n",
            "766/766 [==============================] - 1s 799us/sample - loss: 0.6916 - accuracy: 0.7753\n",
            "Epoch 854/1000\n",
            "766/766 [==============================] - 1s 802us/sample - loss: 0.7032 - accuracy: 0.7732\n",
            "Epoch 855/1000\n",
            "766/766 [==============================] - 1s 782us/sample - loss: 0.7068 - accuracy: 0.7693\n",
            "Epoch 856/1000\n",
            "766/766 [==============================] - 1s 802us/sample - loss: 0.7122 - accuracy: 0.7679\n",
            "Epoch 857/1000\n",
            "766/766 [==============================] - 1s 801us/sample - loss: 0.7146 - accuracy: 0.7664\n",
            "Epoch 858/1000\n",
            "766/766 [==============================] - 1s 790us/sample - loss: 0.7127 - accuracy: 0.7689\n",
            "Epoch 859/1000\n",
            "766/766 [==============================] - 1s 813us/sample - loss: 0.7273 - accuracy: 0.7637\n",
            "Epoch 860/1000\n",
            "766/766 [==============================] - 1s 807us/sample - loss: 0.7347 - accuracy: 0.7612\n",
            "Epoch 861/1000\n",
            "766/766 [==============================] - 1s 795us/sample - loss: 0.7315 - accuracy: 0.7614\n",
            "Epoch 862/1000\n",
            "766/766 [==============================] - 1s 815us/sample - loss: 0.7630 - accuracy: 0.7529\n",
            "Epoch 863/1000\n",
            "766/766 [==============================] - 1s 807us/sample - loss: 0.7806 - accuracy: 0.7459\n",
            "Epoch 864/1000\n",
            "766/766 [==============================] - 1s 824us/sample - loss: 0.7624 - accuracy: 0.7496\n",
            "Epoch 865/1000\n",
            "766/766 [==============================] - 1s 795us/sample - loss: 0.7297 - accuracy: 0.7620\n",
            "Epoch 866/1000\n",
            "766/766 [==============================] - 1s 821us/sample - loss: 0.7108 - accuracy: 0.7683\n",
            "Epoch 867/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.7034 - accuracy: 0.7702\n",
            "Epoch 868/1000\n",
            "766/766 [==============================] - 1s 795us/sample - loss: 0.7335 - accuracy: 0.7609\n",
            "Epoch 869/1000\n",
            "766/766 [==============================] - 1s 807us/sample - loss: 0.7048 - accuracy: 0.7703\n",
            "Epoch 870/1000\n",
            "766/766 [==============================] - 1s 802us/sample - loss: 0.6929 - accuracy: 0.7739\n",
            "Epoch 871/1000\n",
            "766/766 [==============================] - 1s 786us/sample - loss: 0.6937 - accuracy: 0.7747\n",
            "Epoch 872/1000\n",
            "766/766 [==============================] - 1s 785us/sample - loss: 0.6822 - accuracy: 0.7789\n",
            "Epoch 873/1000\n",
            "766/766 [==============================] - 1s 789us/sample - loss: 0.6719 - accuracy: 0.7822\n",
            "Epoch 874/1000\n",
            "766/766 [==============================] - 1s 816us/sample - loss: 0.6663 - accuracy: 0.7861\n",
            "Epoch 875/1000\n",
            "766/766 [==============================] - 1s 845us/sample - loss: 0.6625 - accuracy: 0.7852\n",
            "Epoch 876/1000\n",
            "766/766 [==============================] - 1s 812us/sample - loss: 0.6605 - accuracy: 0.7867\n",
            "Epoch 877/1000\n",
            "766/766 [==============================] - 1s 815us/sample - loss: 0.6527 - accuracy: 0.7910\n",
            "Epoch 878/1000\n",
            "766/766 [==============================] - 1s 787us/sample - loss: 0.6518 - accuracy: 0.7886\n",
            "Epoch 879/1000\n",
            "766/766 [==============================] - 1s 780us/sample - loss: 0.6539 - accuracy: 0.7881\n",
            "Epoch 880/1000\n",
            "766/766 [==============================] - 1s 803us/sample - loss: 0.6507 - accuracy: 0.7895\n",
            "Epoch 881/1000\n",
            "766/766 [==============================] - 1s 784us/sample - loss: 0.6584 - accuracy: 0.7873\n",
            "Epoch 882/1000\n",
            "766/766 [==============================] - 1s 802us/sample - loss: 0.6661 - accuracy: 0.7841\n",
            "Epoch 883/1000\n",
            "766/766 [==============================] - 1s 800us/sample - loss: 0.6790 - accuracy: 0.7792\n",
            "Epoch 884/1000\n",
            "766/766 [==============================] - 1s 814us/sample - loss: 0.6952 - accuracy: 0.7748\n",
            "Epoch 885/1000\n",
            "766/766 [==============================] - 1s 793us/sample - loss: 0.7228 - accuracy: 0.7660\n",
            "Epoch 886/1000\n",
            "766/766 [==============================] - 1s 804us/sample - loss: 0.7306 - accuracy: 0.7625\n",
            "Epoch 887/1000\n",
            "766/766 [==============================] - 1s 799us/sample - loss: 0.7191 - accuracy: 0.7668\n",
            "Epoch 888/1000\n",
            "766/766 [==============================] - 1s 805us/sample - loss: 0.7320 - accuracy: 0.7633\n",
            "Epoch 889/1000\n",
            "766/766 [==============================] - 1s 793us/sample - loss: 0.7386 - accuracy: 0.7598\n",
            "Epoch 890/1000\n",
            "766/766 [==============================] - 1s 796us/sample - loss: 0.7418 - accuracy: 0.7606\n",
            "Epoch 891/1000\n",
            "766/766 [==============================] - 1s 805us/sample - loss: 0.7498 - accuracy: 0.7563\n",
            "Epoch 892/1000\n",
            "766/766 [==============================] - 1s 786us/sample - loss: 0.7557 - accuracy: 0.7548\n",
            "Epoch 893/1000\n",
            "766/766 [==============================] - 1s 795us/sample - loss: 0.7661 - accuracy: 0.7503\n",
            "Epoch 894/1000\n",
            "766/766 [==============================] - 1s 804us/sample - loss: 0.7447 - accuracy: 0.7564\n",
            "Epoch 895/1000\n",
            "766/766 [==============================] - 1s 784us/sample - loss: 0.7339 - accuracy: 0.7594\n",
            "Epoch 896/1000\n",
            "766/766 [==============================] - 1s 804us/sample - loss: 0.7050 - accuracy: 0.7708\n",
            "Epoch 897/1000\n",
            "766/766 [==============================] - 1s 796us/sample - loss: 0.6967 - accuracy: 0.7731\n",
            "Epoch 898/1000\n",
            "766/766 [==============================] - 1s 800us/sample - loss: 0.6872 - accuracy: 0.7773\n",
            "Epoch 899/1000\n",
            "766/766 [==============================] - 1s 792us/sample - loss: 0.6774 - accuracy: 0.7790\n",
            "Epoch 900/1000\n",
            "766/766 [==============================] - 1s 813us/sample - loss: 0.6667 - accuracy: 0.7844\n",
            "Epoch 901/1000\n",
            "766/766 [==============================] - 1s 792us/sample - loss: 0.6591 - accuracy: 0.7875\n",
            "Epoch 902/1000\n",
            "766/766 [==============================] - 1s 805us/sample - loss: 0.6579 - accuracy: 0.7866\n",
            "Epoch 903/1000\n",
            "766/766 [==============================] - 1s 797us/sample - loss: 0.6512 - accuracy: 0.7897\n",
            "Epoch 904/1000\n",
            "766/766 [==============================] - 1s 807us/sample - loss: 0.6526 - accuracy: 0.7887\n",
            "Epoch 905/1000\n",
            "766/766 [==============================] - 1s 788us/sample - loss: 0.6516 - accuracy: 0.7891\n",
            "Epoch 906/1000\n",
            "766/766 [==============================] - 1s 802us/sample - loss: 0.6443 - accuracy: 0.7924\n",
            "Epoch 907/1000\n",
            "766/766 [==============================] - 1s 802us/sample - loss: 0.6505 - accuracy: 0.7910\n",
            "Epoch 908/1000\n",
            "766/766 [==============================] - 1s 778us/sample - loss: 0.6480 - accuracy: 0.7907\n",
            "Epoch 909/1000\n",
            "766/766 [==============================] - 1s 821us/sample - loss: 0.6524 - accuracy: 0.7888\n",
            "Epoch 910/1000\n",
            "766/766 [==============================] - 1s 795us/sample - loss: 0.6541 - accuracy: 0.7882\n",
            "Epoch 911/1000\n",
            "766/766 [==============================] - 1s 788us/sample - loss: 0.6606 - accuracy: 0.7859\n",
            "Epoch 912/1000\n",
            "766/766 [==============================] - 1s 798us/sample - loss: 0.6758 - accuracy: 0.7805\n",
            "Epoch 913/1000\n",
            "766/766 [==============================] - 1s 815us/sample - loss: 0.6983 - accuracy: 0.7746\n",
            "Epoch 914/1000\n",
            "766/766 [==============================] - 1s 838us/sample - loss: 0.7136 - accuracy: 0.7676\n",
            "Epoch 915/1000\n",
            "766/766 [==============================] - 1s 824us/sample - loss: 0.7271 - accuracy: 0.7629\n",
            "Epoch 916/1000\n",
            "766/766 [==============================] - 1s 837us/sample - loss: 0.7394 - accuracy: 0.7568\n",
            "Epoch 917/1000\n",
            "766/766 [==============================] - 1s 817us/sample - loss: 0.7459 - accuracy: 0.7566\n",
            "Epoch 918/1000\n",
            "766/766 [==============================] - 1s 823us/sample - loss: 0.7626 - accuracy: 0.7515\n",
            "Epoch 919/1000\n",
            "766/766 [==============================] - 1s 816us/sample - loss: 0.7552 - accuracy: 0.7536\n",
            "Epoch 920/1000\n",
            "766/766 [==============================] - 1s 828us/sample - loss: 0.7602 - accuracy: 0.7507\n",
            "Epoch 921/1000\n",
            "766/766 [==============================] - 1s 808us/sample - loss: 0.7493 - accuracy: 0.7568\n",
            "Epoch 922/1000\n",
            "766/766 [==============================] - 1s 825us/sample - loss: 0.7400 - accuracy: 0.7576\n",
            "Epoch 923/1000\n",
            "766/766 [==============================] - 1s 831us/sample - loss: 0.8210 - accuracy: 0.7346\n",
            "Epoch 924/1000\n",
            "766/766 [==============================] - 1s 816us/sample - loss: 0.8303 - accuracy: 0.7308\n",
            "Epoch 925/1000\n",
            "766/766 [==============================] - 1s 817us/sample - loss: 0.7831 - accuracy: 0.7460\n",
            "Epoch 926/1000\n",
            "766/766 [==============================] - 1s 806us/sample - loss: 0.7587 - accuracy: 0.7536\n",
            "Epoch 927/1000\n",
            "766/766 [==============================] - 1s 801us/sample - loss: 0.7567 - accuracy: 0.7530\n",
            "Epoch 928/1000\n",
            "766/766 [==============================] - 1s 795us/sample - loss: 0.7416 - accuracy: 0.7580\n",
            "Epoch 929/1000\n",
            "766/766 [==============================] - 1s 798us/sample - loss: 0.7074 - accuracy: 0.7685\n",
            "Epoch 930/1000\n",
            "766/766 [==============================] - 1s 797us/sample - loss: 0.6886 - accuracy: 0.7761\n",
            "Epoch 931/1000\n",
            "766/766 [==============================] - 1s 798us/sample - loss: 0.6783 - accuracy: 0.7800\n",
            "Epoch 932/1000\n",
            "766/766 [==============================] - 1s 802us/sample - loss: 0.6607 - accuracy: 0.7846\n",
            "Epoch 933/1000\n",
            "766/766 [==============================] - 1s 777us/sample - loss: 0.6646 - accuracy: 0.7864\n",
            "Epoch 934/1000\n",
            "766/766 [==============================] - 1s 781us/sample - loss: 0.6567 - accuracy: 0.7878\n",
            "Epoch 935/1000\n",
            "766/766 [==============================] - 1s 791us/sample - loss: 0.6528 - accuracy: 0.7886\n",
            "Epoch 936/1000\n",
            "766/766 [==============================] - 1s 815us/sample - loss: 0.6459 - accuracy: 0.7912\n",
            "Epoch 937/1000\n",
            "766/766 [==============================] - 1s 790us/sample - loss: 0.6463 - accuracy: 0.7916\n",
            "Epoch 938/1000\n",
            "766/766 [==============================] - 1s 788us/sample - loss: 0.6445 - accuracy: 0.7907\n",
            "Epoch 939/1000\n",
            "766/766 [==============================] - 1s 777us/sample - loss: 0.6394 - accuracy: 0.7916\n",
            "Epoch 940/1000\n",
            "766/766 [==============================] - 1s 795us/sample - loss: 0.6399 - accuracy: 0.7942\n",
            "Epoch 941/1000\n",
            "766/766 [==============================] - 1s 784us/sample - loss: 0.6467 - accuracy: 0.7898\n",
            "Epoch 942/1000\n",
            "766/766 [==============================] - 1s 798us/sample - loss: 0.6439 - accuracy: 0.7910\n",
            "Epoch 943/1000\n",
            "766/766 [==============================] - 1s 792us/sample - loss: 0.6588 - accuracy: 0.7856\n",
            "Epoch 944/1000\n",
            "766/766 [==============================] - 1s 796us/sample - loss: 0.6763 - accuracy: 0.7780\n",
            "Epoch 945/1000\n",
            "766/766 [==============================] - 1s 805us/sample - loss: 0.6852 - accuracy: 0.7800\n",
            "Epoch 946/1000\n",
            "766/766 [==============================] - 1s 793us/sample - loss: 0.6798 - accuracy: 0.7790\n",
            "Epoch 947/1000\n",
            "766/766 [==============================] - 1s 798us/sample - loss: 0.6803 - accuracy: 0.7777\n",
            "Epoch 948/1000\n",
            "766/766 [==============================] - 1s 821us/sample - loss: 0.6892 - accuracy: 0.7758\n",
            "Epoch 949/1000\n",
            "766/766 [==============================] - 1s 804us/sample - loss: 0.6925 - accuracy: 0.7736\n",
            "Epoch 950/1000\n",
            "766/766 [==============================] - 1s 806us/sample - loss: 0.6872 - accuracy: 0.7763\n",
            "Epoch 951/1000\n",
            "766/766 [==============================] - 1s 781us/sample - loss: 0.7045 - accuracy: 0.7699\n",
            "Epoch 952/1000\n",
            "766/766 [==============================] - 1s 814us/sample - loss: 0.7007 - accuracy: 0.7728\n",
            "Epoch 953/1000\n",
            "766/766 [==============================] - 1s 796us/sample - loss: 0.6976 - accuracy: 0.7725\n",
            "Epoch 954/1000\n",
            "766/766 [==============================] - 1s 794us/sample - loss: 0.6819 - accuracy: 0.7783\n",
            "Epoch 955/1000\n",
            "766/766 [==============================] - 1s 788us/sample - loss: 0.6946 - accuracy: 0.7748\n",
            "Epoch 956/1000\n",
            "766/766 [==============================] - 1s 795us/sample - loss: 0.6917 - accuracy: 0.7739\n",
            "Epoch 957/1000\n",
            "766/766 [==============================] - 1s 801us/sample - loss: 0.6853 - accuracy: 0.7772\n",
            "Epoch 958/1000\n",
            "766/766 [==============================] - 1s 799us/sample - loss: 0.6770 - accuracy: 0.7803\n",
            "Epoch 959/1000\n",
            "766/766 [==============================] - 1s 779us/sample - loss: 0.6681 - accuracy: 0.7823\n",
            "Epoch 960/1000\n",
            "766/766 [==============================] - 1s 802us/sample - loss: 0.6581 - accuracy: 0.7870\n",
            "Epoch 961/1000\n",
            "766/766 [==============================] - 1s 783us/sample - loss: 0.6520 - accuracy: 0.7881\n",
            "Epoch 962/1000\n",
            "766/766 [==============================] - 1s 806us/sample - loss: 0.6521 - accuracy: 0.7899\n",
            "Epoch 963/1000\n",
            "766/766 [==============================] - 1s 800us/sample - loss: 0.6510 - accuracy: 0.7889\n",
            "Epoch 964/1000\n",
            "766/766 [==============================] - 1s 795us/sample - loss: 0.6583 - accuracy: 0.7855\n",
            "Epoch 965/1000\n",
            "766/766 [==============================] - 1s 787us/sample - loss: 0.6670 - accuracy: 0.7843\n",
            "Epoch 966/1000\n",
            "766/766 [==============================] - 1s 814us/sample - loss: 0.6646 - accuracy: 0.7844\n",
            "Epoch 967/1000\n",
            "766/766 [==============================] - 1s 814us/sample - loss: 0.6667 - accuracy: 0.7852\n",
            "Epoch 968/1000\n",
            "766/766 [==============================] - 1s 801us/sample - loss: 0.6702 - accuracy: 0.7825\n",
            "Epoch 969/1000\n",
            "766/766 [==============================] - 1s 796us/sample - loss: 0.6703 - accuracy: 0.7824\n",
            "Epoch 970/1000\n",
            "766/766 [==============================] - 1s 816us/sample - loss: 0.6640 - accuracy: 0.7835\n",
            "Epoch 971/1000\n",
            "766/766 [==============================] - 1s 785us/sample - loss: 0.6650 - accuracy: 0.7870\n",
            "Epoch 972/1000\n",
            "766/766 [==============================] - 1s 806us/sample - loss: 0.6548 - accuracy: 0.7882\n",
            "Epoch 973/1000\n",
            "766/766 [==============================] - 1s 793us/sample - loss: 0.6484 - accuracy: 0.7903\n",
            "Epoch 974/1000\n",
            "766/766 [==============================] - 1s 810us/sample - loss: 0.6567 - accuracy: 0.7867\n",
            "Epoch 975/1000\n",
            "766/766 [==============================] - 1s 794us/sample - loss: 0.6619 - accuracy: 0.7854\n",
            "Epoch 976/1000\n",
            "766/766 [==============================] - 1s 786us/sample - loss: 0.6642 - accuracy: 0.7841\n",
            "Epoch 977/1000\n",
            "766/766 [==============================] - 1s 801us/sample - loss: 0.6752 - accuracy: 0.7803\n",
            "Epoch 978/1000\n",
            "766/766 [==============================] - 1s 793us/sample - loss: 0.6846 - accuracy: 0.7774\n",
            "Epoch 979/1000\n",
            "766/766 [==============================] - 1s 785us/sample - loss: 0.6847 - accuracy: 0.7773\n",
            "Epoch 980/1000\n",
            "766/766 [==============================] - 1s 803us/sample - loss: 0.7029 - accuracy: 0.7698\n",
            "Epoch 981/1000\n",
            "766/766 [==============================] - 1s 792us/sample - loss: 0.7170 - accuracy: 0.7665\n",
            "Epoch 982/1000\n",
            "766/766 [==============================] - 1s 803us/sample - loss: 0.7341 - accuracy: 0.7587\n",
            "Epoch 983/1000\n",
            "766/766 [==============================] - 1s 809us/sample - loss: 0.7819 - accuracy: 0.7464\n",
            "Epoch 984/1000\n",
            "766/766 [==============================] - 1s 815us/sample - loss: 0.7915 - accuracy: 0.7418\n",
            "Epoch 985/1000\n",
            "766/766 [==============================] - 1s 808us/sample - loss: 0.7835 - accuracy: 0.7481\n",
            "Epoch 986/1000\n",
            "766/766 [==============================] - 1s 794us/sample - loss: 0.8012 - accuracy: 0.7389\n",
            "Epoch 987/1000\n",
            "766/766 [==============================] - 1s 815us/sample - loss: 0.7797 - accuracy: 0.7463\n",
            "Epoch 988/1000\n",
            "766/766 [==============================] - 1s 798us/sample - loss: 0.7719 - accuracy: 0.7485\n",
            "Epoch 989/1000\n",
            "766/766 [==============================] - 1s 804us/sample - loss: 0.7568 - accuracy: 0.7533\n",
            "Epoch 990/1000\n",
            "766/766 [==============================] - 1s 796us/sample - loss: 0.7273 - accuracy: 0.7614\n",
            "Epoch 991/1000\n",
            "766/766 [==============================] - 1s 800us/sample - loss: 0.7078 - accuracy: 0.7686\n",
            "Epoch 992/1000\n",
            "766/766 [==============================] - 1s 803us/sample - loss: 0.6840 - accuracy: 0.7776\n",
            "Epoch 993/1000\n",
            "766/766 [==============================] - 1s 798us/sample - loss: 0.6651 - accuracy: 0.7842\n",
            "Epoch 994/1000\n",
            "766/766 [==============================] - 1s 790us/sample - loss: 0.6632 - accuracy: 0.7854\n",
            "Epoch 995/1000\n",
            "766/766 [==============================] - 1s 804us/sample - loss: 0.6582 - accuracy: 0.7872\n",
            "Epoch 996/1000\n",
            "766/766 [==============================] - 1s 795us/sample - loss: 0.6508 - accuracy: 0.7904\n",
            "Epoch 997/1000\n",
            "766/766 [==============================] - 1s 790us/sample - loss: 0.6497 - accuracy: 0.7881\n",
            "Epoch 998/1000\n",
            "766/766 [==============================] - 1s 798us/sample - loss: 0.6380 - accuracy: 0.7948\n",
            "Epoch 999/1000\n",
            "766/766 [==============================] - 1s 782us/sample - loss: 0.6329 - accuracy: 0.7957\n",
            "Epoch 1000/1000\n",
            "766/766 [==============================] - 1s 816us/sample - loss: 0.6307 - accuracy: 0.7952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffaf83b0828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Soqzwg8Llssu",
        "colab_type": "code",
        "outputId": "5c82c870-502c-4de9-889a-b9e4e092d776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seed = 'hello'\n",
        "seed = np.array(char_tokenizer.texts_to_sequences(seed)).T[0]\n",
        "print(seed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 9  2 11 11  4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWkCgroiuE8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = seed.reshape(1,5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_Qfigs1upcv",
        "colab_type": "code",
        "outputId": "f7347c75-512e-4637-ccfe-1dc48d9f75d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seed.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oW4Zvck21cC",
        "colab_type": "code",
        "outputId": "995aceec-89b7-4962-86cf-a6c9657d6dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seed[0][seed.shape[1]-1].reshape(1,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9NxQgrcOjD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uJl02b3tzzY",
        "colab_type": "code",
        "outputId": "415c1762-1400-4148-e525-b12b77ae79fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "predictions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=172446, shape=(1, 5, 49), dtype=float32, numpy=\n",
              "array([[[4.27416076e-08, 6.69673309e-02, 6.72277391e-01, 9.55607221e-02,\n",
              "         2.00760737e-03, 3.84445325e-03, 6.00696922e-07, 1.08973354e-01,\n",
              "         2.53442279e-03, 6.03642945e-07, 2.07328718e-04, 3.47583809e-05,\n",
              "         4.51505999e-04, 3.41840750e-05, 1.08152314e-03, 1.43344188e-02,\n",
              "         6.07154698e-06, 9.91225243e-03, 2.11077649e-03, 6.17920232e-05,\n",
              "         2.75258295e-04, 3.68304172e-04, 1.80761572e-02, 3.97519871e-05,\n",
              "         8.12248572e-07, 4.62523985e-06, 1.85449710e-04, 7.72030216e-06,\n",
              "         9.09944283e-05, 5.34409832e-04, 2.48425408e-07, 1.82843269e-08,\n",
              "         1.49653102e-11, 8.99441588e-09, 1.11337602e-06, 1.56662439e-09,\n",
              "         2.06337722e-06, 1.60665992e-09, 1.10562496e-05, 2.91611464e-08,\n",
              "         1.30208747e-07, 1.88802929e-07, 1.95287875e-08, 1.48406594e-08,\n",
              "         2.82168742e-08, 4.37569270e-09, 3.54604225e-07, 1.21732583e-07,\n",
              "         7.61738491e-14],\n",
              "        [9.42701611e-11, 6.85415685e-01, 1.14516600e-03, 7.61492318e-03,\n",
              "         5.18186716e-04, 4.17067204e-04, 3.15135196e-02, 1.75249053e-03,\n",
              "         2.49331206e-01, 6.97895700e-07, 2.07089540e-03, 3.24298348e-03,\n",
              "         3.01365391e-03, 2.01030889e-06, 7.72746716e-06, 9.32188332e-03,\n",
              "         3.37706716e-03, 4.58584509e-06, 1.04258980e-07, 4.71504900e-05,\n",
              "         3.20792569e-05, 6.02636486e-04, 8.73414538e-05, 7.45535872e-05,\n",
              "         4.72380498e-06, 3.65235731e-09, 2.48784886e-06, 1.29249386e-07,\n",
              "         2.04371117e-05, 1.18613665e-04, 2.58698914e-04, 4.60894427e-07,\n",
              "         4.15685653e-10, 8.72345918e-10, 8.22458674e-07, 1.53897001e-12,\n",
              "         7.07932573e-13, 1.51030803e-14, 2.55986149e-10, 4.61378540e-11,\n",
              "         1.66055669e-10, 3.21760418e-09, 1.43582542e-11, 6.70215243e-16,\n",
              "         1.36872721e-10, 5.35277933e-11, 5.68470780e-14, 9.99491559e-14,\n",
              "         5.14736246e-19],\n",
              "        [3.27795263e-10, 4.21441393e-03, 6.56428456e-01, 4.72726971e-02,\n",
              "         3.28900404e-02, 9.07147478e-06, 3.99278946e-07, 1.46235316e-03,\n",
              "         9.58115415e-05, 2.18405578e-08, 1.08290545e-03, 2.52484232e-01,\n",
              "         1.26098021e-04, 1.94540934e-08, 9.25876491e-04, 5.64402808e-06,\n",
              "         8.81148517e-05, 1.01588979e-04, 9.41603901e-07, 2.16938928e-03,\n",
              "         5.72047575e-05, 3.09767383e-05, 1.68471104e-07, 2.49334174e-04,\n",
              "         3.88950411e-06, 4.65136765e-08, 1.03913012e-08, 1.91637605e-06,\n",
              "         2.87327188e-04, 6.83014696e-06, 2.20327979e-06, 6.41840914e-10,\n",
              "         4.07610223e-10, 4.84442382e-11, 1.22012522e-09, 5.61997504e-10,\n",
              "         5.16322586e-07, 1.74739445e-10, 1.42514330e-06, 7.46649270e-13,\n",
              "         1.15815425e-13, 1.42462058e-11, 1.30584057e-10, 1.25565339e-15,\n",
              "         2.50219398e-12, 6.54005600e-11, 9.38170657e-13, 8.88327259e-12,\n",
              "         4.36699505e-13],\n",
              "        [4.74102528e-13, 9.99039948e-01, 2.92852619e-05, 2.14648426e-05,\n",
              "         2.82278961e-05, 6.80914347e-09, 1.29673494e-09, 5.62260652e-07,\n",
              "         1.64981528e-10, 7.50793958e-12, 7.81798793e-04, 8.06328373e-08,\n",
              "         8.93577157e-11, 1.19940694e-06, 1.43248997e-07, 7.62191976e-10,\n",
              "         3.63482468e-05, 1.96279302e-06, 5.21201034e-11, 3.57463449e-07,\n",
              "         9.43174316e-10, 5.94868865e-09, 4.08682499e-05, 1.16443105e-10,\n",
              "         1.92529621e-11, 1.35345546e-11, 7.40761266e-07, 1.84556228e-08,\n",
              "         1.67678518e-05, 2.86167193e-07, 1.80966120e-09, 4.39724144e-14,\n",
              "         1.95207961e-10, 1.20070114e-08, 2.92373547e-14, 1.10299540e-10,\n",
              "         1.53860746e-09, 1.05529955e-18, 4.57537654e-13, 2.85541888e-14,\n",
              "         1.16792603e-13, 3.08028429e-11, 1.54983037e-15, 6.35511033e-15,\n",
              "         2.07160118e-15, 1.23353673e-15, 1.47962252e-12, 4.96610208e-15,\n",
              "         1.81419595e-16],\n",
              "        [7.48421724e-12, 1.01335763e-05, 4.67171458e-06, 5.78870527e-07,\n",
              "         1.01656641e-03, 1.46517596e-06, 1.69050798e-03, 1.34640541e-05,\n",
              "         1.18593278e-04, 3.86292776e-08, 1.19158813e-05, 2.67965479e-05,\n",
              "         1.39292242e-04, 1.33179272e-08, 3.13098809e-07, 2.45710362e-06,\n",
              "         9.94567871e-01, 1.88773056e-03, 6.24343693e-06, 9.98152814e-07,\n",
              "         1.15047042e-05, 1.33560980e-06, 1.03673650e-04, 1.43559606e-04,\n",
              "         2.34840001e-04, 3.16011165e-06, 5.40921663e-09, 1.55313330e-06,\n",
              "         7.54444258e-08, 9.68259606e-09, 3.57347091e-07, 2.11990758e-10,\n",
              "         1.22100084e-12, 5.39915623e-09, 2.09294427e-07, 3.62180702e-10,\n",
              "         1.32450538e-18, 1.44430036e-18, 4.39251418e-13, 5.96106552e-13,\n",
              "         4.14191901e-13, 2.62615537e-12, 1.71496676e-17, 1.64103800e-12,\n",
              "         4.94947846e-14, 9.78298253e-14, 4.35264482e-15, 1.75222174e-12,\n",
              "         1.53026856e-13]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIudUlO1ux68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = tf.squeeze(predictions,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNcaI5dwwShh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temperature = 1.0\n",
        "predictions = predictions / temperature\n",
        "predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "input_eval = tf.expand_dims([predicted_id], 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CcfpsZEw_p_",
        "colab_type": "code",
        "outputId": "63a2726c-ae4d-46a3-fa27-be085157c4cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_eval.numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[30]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a1KLGjzyVGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_pred = model.predict_classes(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKe8nDDOy36M",
        "colab_type": "code",
        "outputId": "7d1b4cdc-b68f-412c-bcb8-64825ae9cdab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "my_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2,  1,  2,  1, 16]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXpCxX4OzCjX",
        "colab_type": "code",
        "outputId": "48aebb7d-6a7a-475b-d1e3-57921675dbcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predicted_id"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZshUGw1zbX6",
        "colab_type": "code",
        "outputId": "3af86821-b947-4ca7-deac-9ba29f3a593d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([5, 49])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmby6fvs0m73",
        "colab_type": "code",
        "outputId": "2ed43278-f9f3-4076-efbf-d191632bab3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.predict_classes([[16]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuV1EgGg3Mvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rev_char_dic = {value:key for key,value in char_tokenizer.word_index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J-u4RJh14bD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_text(seed,num_chars,temperature=1.0):\n",
        "  txt = []\n",
        "  input_eval = np.array(char_tokenizer.texts_to_sequences(seed)).T[0].reshape(1,-1)\n",
        "  print(input_eval)\n",
        "  for _ in range(num_chars):\n",
        "    predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a multinomial distribution to predict the word returned by the model\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "    #print(predicted_id)\n",
        "      # We pass the predicted word as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "    if predicted_id == 0:\n",
        "      predicted_id = 1\n",
        "    txt.append(rev_char_dic[predicted_id])\n",
        "  return (seed + ''.join(txt))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7abyYs5-7KAj",
        "colab_type": "code",
        "outputId": "5ae11f55-b8ba-484a-e6d5-dbe5aaaf7b54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "txt = gen_text(\"come all\",200,0.043)\n",
        "print(txt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[21  4 15  2  1  3 11 11]]\n",
            "come all angon,\n",
            "an the úthe moon the the re the o?112.\n",
            "ango the the ,\n",
            "aingo;\n",
            "ango\n",
            "and the ;\n",
            "bome the the the ! .\n",
            "an fo .\n",
            "ang,\n",
            "any the the o come fo óín ve o o the & fango 812\n",
            "an e the d the pangle an xe : win\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDQnQNeU75X9",
        "colab_type": "code",
        "outputId": "1fbec87b-c73d-47d1-d0a9-153526286a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'t'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzI7gwrW8H69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}